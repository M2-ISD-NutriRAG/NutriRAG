{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "26905175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import snowflake.connector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306de016",
   "metadata": {},
   "source": [
    "**define connexion parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ab2eb4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       \n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import re\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "user = os.getenv(\"USER\")\n",
    "password = os.getenv(\"PASSWORD\")\n",
    "passcode = os.getenv(\"PASSCODE\")\n",
    "account = os.getenv(\"ACCOUNT\")\n",
    "warehouse = os.getenv(\"WAREHOUSE\") \n",
    "database = os.getenv(\"DATABASE\")\n",
    "schema = os.getenv(\"SCHEMA\")\n",
    "table = os.getenv(\"TABLE\")\n",
    "\n",
    "print(user, re.sub(r'.', '*', password), passcode, account, warehouse, database, schema, table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df812b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14203/3409595610.py:11: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(f\"SELECT * FROM {table}\", conn)\n"
     ]
    }
   ],
   "source": [
    "conn = snowflake.connector.connect(\n",
    "    user = user,\n",
    "    password = password,\n",
    "    passcode = passcode,\n",
    "    account = account,\n",
    "    warehouse = warehouse,\n",
    "    database = database,\n",
    "    schema = schema\n",
    ")\n",
    "\n",
    "df = pd.read_sql(f\"SELECT * FROM {table}\", conn)\n",
    "    \n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba17005",
   "metadata": {},
   "source": [
    "**open the config file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1aced527",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_FILE_PATH = os.getenv(\"CONFIG_FILE_PATH\")\n",
    "\n",
    "with open(CONFIG_FILE_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86779950",
   "metadata": {},
   "source": [
    "**write the data locally**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "909c502f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m INPUT_RECIPIES_FILE = config[\u001b[33m'\u001b[39m\u001b[33minput_recipies_file\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mdf\u001b[49m.to_csv(INPUT_RECIPIES_FILE, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      4\u001b[39m df.head()\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "INPUT_RECIPIES_FILE = config['input_recipies_file']\n",
    "\n",
    "df.to_csv(INPUT_RECIPIES_FILE, index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e9a630f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>ID</th>\n",
       "      <th>MINUTES</th>\n",
       "      <th>CONTRIBUTOR_ID</th>\n",
       "      <th>SUBMITTED</th>\n",
       "      <th>TAGS</th>\n",
       "      <th>NUTRITION</th>\n",
       "      <th>N_STEPS</th>\n",
       "      <th>STEPS</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>INGREDIENTS</th>\n",
       "      <th>N_INGREDIENTS</th>\n",
       "      <th>HAS_IMAGE</th>\n",
       "      <th>IMAGE_URL</th>\n",
       "      <th>INGREDIENTS_RAW_STR</th>\n",
       "      <th>SERVING_SIZE</th>\n",
       "      <th>SERVINGS</th>\n",
       "      <th>SEARCH_TERMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>crab filled crescent snacks</td>\n",
       "      <td>94947</td>\n",
       "      <td>70</td>\n",
       "      <td>111448</td>\n",
       "      <td>2004-07-03</td>\n",
       "      <td>[\\n  \"time-to-make\",\\n  \"course\",\\n  \"main-ing...</td>\n",
       "      <td>[\\n  69.2,\\n  3,\\n  9,\\n  6,\\n  5,\\n  4,\\n  3\\n]</td>\n",
       "      <td>16</td>\n",
       "      <td>[\\n  \"heat over to 375 degrees\",\\n  \"spray lar...</td>\n",
       "      <td>found in a crescent roll recipe magazine.</td>\n",
       "      <td>[\\n  \"crabmeat\",\\n  \"cream cheese\",\\n  \"green ...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\\n  \"1 (6   ounce) can   crabmeat, rinsed,wel...</td>\n",
       "      <td>1010</td>\n",
       "      <td>1</td>\n",
       "      <td>[\\n  \"lunch\",\\n  \"snack\"\\n]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>curried bean salad</td>\n",
       "      <td>429010</td>\n",
       "      <td>20</td>\n",
       "      <td>300249</td>\n",
       "      <td>2010-06-08</td>\n",
       "      <td>[\\n  \"curries\",\\n  \"30-minutes-or-less\",\\n  \"t...</td>\n",
       "      <td>[\\n  256,\\n  2,\\n  40,\\n  18,\\n  18,\\n  1,\\n  ...</td>\n",
       "      <td>4</td>\n",
       "      <td>[\\n  \"drain &amp; rinse beans\",\\n  \"stir all ingre...</td>\n",
       "      <td>serve this flavorful and refreshing salad as a...</td>\n",
       "      <td>[\\n  \"garbanzo beans\",\\n  \"black beans\",\\n  \"o...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\\n  \"1 (15   ounce) can   garbanzo beans, dra...</td>\n",
       "      <td>271</td>\n",
       "      <td>8</td>\n",
       "      <td>[\\n  \"low-calorie\",\\n  \"vegetarian\",\\n  \"salad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>delicious steak with onion marinade</td>\n",
       "      <td>277542</td>\n",
       "      <td>25</td>\n",
       "      <td>234062</td>\n",
       "      <td>2008-01-08</td>\n",
       "      <td>[\\n  \"lactose\",\\n  \"30-minutes-or-less\",\\n  \"t...</td>\n",
       "      <td>[\\n  58.6,\\n  5,\\n  19,\\n  0,\\n  0,\\n  2,\\n  2\\n]</td>\n",
       "      <td>6</td>\n",
       "      <td>[\\n  \"heat the oil in a heavy-based pan and co...</td>\n",
       "      <td>another i've not tried, but looks good! times ...</td>\n",
       "      <td>[\\n  \"olive oil\",\\n  \"red onion\",\\n  \"light br...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>https://img.sndimg.com/food/image/upload/c_thu...</td>\n",
       "      <td>[\\n  \"1   tablespoon    olive oil, plus extra ...</td>\n",
       "      <td>152</td>\n",
       "      <td>4</td>\n",
       "      <td>[\\n  \"dinner\",\\n  \"lactose-free\"\\n]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pork tenderloin with hoisin</td>\n",
       "      <td>78450</td>\n",
       "      <td>15</td>\n",
       "      <td>42651</td>\n",
       "      <td>2003-12-10</td>\n",
       "      <td>[\\n  \"15-minutes-or-less\",\\n  \"time-to-make\",\\...</td>\n",
       "      <td>[\\n  241.5,\\n  12,\\n  20,\\n  45,\\n  62,\\n  13,...</td>\n",
       "      <td>7</td>\n",
       "      <td>[\\n  \"cut pork into 1 / 4-inch slices\",\\n  \"in...</td>\n",
       "      <td>another keeper from bonnie stern's heartsmart ...</td>\n",
       "      <td>[\\n  \"pork tenderloin\",\\n  \"soy sauce\",\\n  \"ho...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\\n  \"1 1/4  lbs    pork tenderloin\",\\n  \"3   ...</td>\n",
       "      <td>187</td>\n",
       "      <td>4</td>\n",
       "      <td>[\\n  \"pork\",\\n  \"dinner\"\\n]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mixed baby greens with oranges  grapefruit and...</td>\n",
       "      <td>80012</td>\n",
       "      <td>15</td>\n",
       "      <td>1533</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>[\\n  \"15-minutes-or-less\",\\n  \"time-to-make\",\\...</td>\n",
       "      <td>[\\n  212.8,\\n  24,\\n  30,\\n  0,\\n  4,\\n  11,\\n...</td>\n",
       "      <td>2</td>\n",
       "      <td>[\\n  \"in a salad bowl combine the lettuce with...</td>\n",
       "      <td>i love grapefruit in a salad and this one is p...</td>\n",
       "      <td>[\\n  \"mixed baby greens\",\\n  \"oranges\",\\n  \"gr...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\\n  \"1   lb    mixed baby greens, salad \",\\n ...</td>\n",
       "      <td>199</td>\n",
       "      <td>4</td>\n",
       "      <td>[\\n  \"vegetarian\"\\n]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                NAME      ID  MINUTES  \\\n",
       "0                        crab filled crescent snacks   94947       70   \n",
       "1                                 curried bean salad  429010       20   \n",
       "2                delicious steak with onion marinade  277542       25   \n",
       "3                        pork tenderloin with hoisin   78450       15   \n",
       "4  mixed baby greens with oranges  grapefruit and...   80012       15   \n",
       "\n",
       "   CONTRIBUTOR_ID   SUBMITTED  \\\n",
       "0          111448  2004-07-03   \n",
       "1          300249  2010-06-08   \n",
       "2          234062  2008-01-08   \n",
       "3           42651  2003-12-10   \n",
       "4            1533  2004-01-01   \n",
       "\n",
       "                                                TAGS  \\\n",
       "0  [\\n  \"time-to-make\",\\n  \"course\",\\n  \"main-ing...   \n",
       "1  [\\n  \"curries\",\\n  \"30-minutes-or-less\",\\n  \"t...   \n",
       "2  [\\n  \"lactose\",\\n  \"30-minutes-or-less\",\\n  \"t...   \n",
       "3  [\\n  \"15-minutes-or-less\",\\n  \"time-to-make\",\\...   \n",
       "4  [\\n  \"15-minutes-or-less\",\\n  \"time-to-make\",\\...   \n",
       "\n",
       "                                           NUTRITION  N_STEPS  \\\n",
       "0   [\\n  69.2,\\n  3,\\n  9,\\n  6,\\n  5,\\n  4,\\n  3\\n]       16   \n",
       "1  [\\n  256,\\n  2,\\n  40,\\n  18,\\n  18,\\n  1,\\n  ...        4   \n",
       "2  [\\n  58.6,\\n  5,\\n  19,\\n  0,\\n  0,\\n  2,\\n  2\\n]        6   \n",
       "3  [\\n  241.5,\\n  12,\\n  20,\\n  45,\\n  62,\\n  13,...        7   \n",
       "4  [\\n  212.8,\\n  24,\\n  30,\\n  0,\\n  4,\\n  11,\\n...        2   \n",
       "\n",
       "                                               STEPS  \\\n",
       "0  [\\n  \"heat over to 375 degrees\",\\n  \"spray lar...   \n",
       "1  [\\n  \"drain & rinse beans\",\\n  \"stir all ingre...   \n",
       "2  [\\n  \"heat the oil in a heavy-based pan and co...   \n",
       "3  [\\n  \"cut pork into 1 / 4-inch slices\",\\n  \"in...   \n",
       "4  [\\n  \"in a salad bowl combine the lettuce with...   \n",
       "\n",
       "                                         DESCRIPTION  \\\n",
       "0          found in a crescent roll recipe magazine.   \n",
       "1  serve this flavorful and refreshing salad as a...   \n",
       "2  another i've not tried, but looks good! times ...   \n",
       "3  another keeper from bonnie stern's heartsmart ...   \n",
       "4  i love grapefruit in a salad and this one is p...   \n",
       "\n",
       "                                         INGREDIENTS  N_INGREDIENTS  \\\n",
       "0  [\\n  \"crabmeat\",\\n  \"cream cheese\",\\n  \"green ...              9   \n",
       "1  [\\n  \"garbanzo beans\",\\n  \"black beans\",\\n  \"o...             12   \n",
       "2  [\\n  \"olive oil\",\\n  \"red onion\",\\n  \"light br...              5   \n",
       "3  [\\n  \"pork tenderloin\",\\n  \"soy sauce\",\\n  \"ho...             10   \n",
       "4  [\\n  \"mixed baby greens\",\\n  \"oranges\",\\n  \"gr...              8   \n",
       "\n",
       "   HAS_IMAGE                                          IMAGE_URL  \\\n",
       "0          0                                                NaN   \n",
       "1          0                                                NaN   \n",
       "2          1  https://img.sndimg.com/food/image/upload/c_thu...   \n",
       "3          0                                                NaN   \n",
       "4          0                                                NaN   \n",
       "\n",
       "                                 INGREDIENTS_RAW_STR  SERVING_SIZE  SERVINGS  \\\n",
       "0  [\\n  \"1 (6   ounce) can   crabmeat, rinsed,wel...          1010         1   \n",
       "1  [\\n  \"1 (15   ounce) can   garbanzo beans, dra...           271         8   \n",
       "2  [\\n  \"1   tablespoon    olive oil, plus extra ...           152         4   \n",
       "3  [\\n  \"1 1/4  lbs    pork tenderloin\",\\n  \"3   ...           187         4   \n",
       "4  [\\n  \"1   lb    mixed baby greens, salad \",\\n ...           199         4   \n",
       "\n",
       "                                        SEARCH_TERMS  \n",
       "0                        [\\n  \"lunch\",\\n  \"snack\"\\n]  \n",
       "1  [\\n  \"low-calorie\",\\n  \"vegetarian\",\\n  \"salad...  \n",
       "2                [\\n  \"dinner\",\\n  \"lactose-free\"\\n]  \n",
       "3                        [\\n  \"pork\",\\n  \"dinner\"\\n]  \n",
       "4                               [\\n  \"vegetarian\"\\n]  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#or directly load the file if already exist\n",
    "df_recipes = pd.read_csv(INPUT_RECIPIES_FILE)\n",
    "df_recipes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207db5aa",
   "metadata": {},
   "source": [
    "**clean the columns used for embedding** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "641a1358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_columns_to_embedd(tag_value: any, col_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Format text of the columns used for embedding\n",
    "\n",
    "    Args:\n",
    "        tag_value (any): The input value to clean. Can be a string, list, number, or None.\n",
    "                        Will be converted to string before processing.\n",
    "        col_name (str): The label/prefix to add before the cleaned text \n",
    "                       (e.g., \"NAME\", \"TAGS\", \"INGREDIENTS\").\n",
    "    \n",
    "    Returns:\n",
    "        str: Cleaned and formatted text in the format \"{col_name}: {cleaned_text}.\"\n",
    "             Returns empty string if input is None or empty.\n",
    "    \"\"\"\n",
    "    \n",
    "    if tag_value is None or tag_value == \"\":\n",
    "        return \"\"\n",
    "    \n",
    "    text = str(tag_value)\n",
    "    \n",
    "    # Remove list brackets and quotes\n",
    "    text = re.sub(r\"[\\[\\]'\\\"]\", \"\", text)\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Keep only alphanumeric, spaces, and . , ? !\n",
    "    text = re.sub(r\"[^a-z0-9 .,?!]+\", \"\", text)\n",
    "    \n",
    "    # Remove excess spaces\n",
    "    text = re.sub(r\" +\", \" \", text)\n",
    "    \n",
    "    # Clean up spaces around punctuation\n",
    "    text = text.strip()\n",
    "    \n",
    "    # Return formatted text\n",
    "    return f\"{col_name}: {text}.\"\n",
    "\n",
    "for col in COLUMNS_TO_CLEAN:\n",
    "    col_clean_name = COLUMNS_TO_CLEAN[col]['column_name']\n",
    "    start_text = COLUMNS_TO_CLEAN[col]['start_text']\n",
    "\n",
    "    df_recipes[col_clean_name] = df_recipes[col].apply(clean_columns_to_embedd, args=(start_text, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4c7b0933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME_CLEAND</th>\n",
       "      <th>TAGS_CLEAND</th>\n",
       "      <th>INGREDIENTS_CLEAND</th>\n",
       "      <th>STEPS_CLEAND</th>\n",
       "      <th>DESCRIPTION_CLEAND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>recipe name: crab filled crescent snacks.</td>\n",
       "      <td>recipe tags: timetomake, course, mainingredien...</td>\n",
       "      <td>recipe ingredients: crabmeat, cream cheese, gr...</td>\n",
       "      <td>recipe steps: heat over to 375 degrees, spray ...</td>\n",
       "      <td>recipe description: found in a crescent roll r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recipe name: curried bean salad.</td>\n",
       "      <td>recipe tags: curries, 30minutesorless, timetom...</td>\n",
       "      <td>recipe ingredients: garbanzo beans, black bean...</td>\n",
       "      <td>recipe steps: drain rinse beans, stir all ingr...</td>\n",
       "      <td>recipe description: serve this flavorful and r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recipe name: delicious steak with onion marinade.</td>\n",
       "      <td>recipe tags: lactose, 30minutesorless, timetom...</td>\n",
       "      <td>recipe ingredients: olive oil, red onion, ligh...</td>\n",
       "      <td>recipe steps: heat the oil in a heavybased pan...</td>\n",
       "      <td>recipe description: another ive not tried, but...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>recipe name: pork tenderloin with hoisin.</td>\n",
       "      <td>recipe tags: 15minutesorless, timetomake, cour...</td>\n",
       "      <td>recipe ingredients: pork tenderloin, soy sauce...</td>\n",
       "      <td>recipe steps: cut pork into 1 4inch slices, in...</td>\n",
       "      <td>recipe description: another keeper from bonnie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>recipe name: mixed baby greens with oranges gr...</td>\n",
       "      <td>recipe tags: 15minutesorless, timetomake, cour...</td>\n",
       "      <td>recipe ingredients: mixed baby greens, oranges...</td>\n",
       "      <td>recipe steps: in a salad bowl combine the lett...</td>\n",
       "      <td>recipe description: i love grapefruit in a sal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         NAME_CLEAND  \\\n",
       "0          recipe name: crab filled crescent snacks.   \n",
       "1                   recipe name: curried bean salad.   \n",
       "2  recipe name: delicious steak with onion marinade.   \n",
       "3          recipe name: pork tenderloin with hoisin.   \n",
       "4  recipe name: mixed baby greens with oranges gr...   \n",
       "\n",
       "                                         TAGS_CLEAND  \\\n",
       "0  recipe tags: timetomake, course, mainingredien...   \n",
       "1  recipe tags: curries, 30minutesorless, timetom...   \n",
       "2  recipe tags: lactose, 30minutesorless, timetom...   \n",
       "3  recipe tags: 15minutesorless, timetomake, cour...   \n",
       "4  recipe tags: 15minutesorless, timetomake, cour...   \n",
       "\n",
       "                                  INGREDIENTS_CLEAND  \\\n",
       "0  recipe ingredients: crabmeat, cream cheese, gr...   \n",
       "1  recipe ingredients: garbanzo beans, black bean...   \n",
       "2  recipe ingredients: olive oil, red onion, ligh...   \n",
       "3  recipe ingredients: pork tenderloin, soy sauce...   \n",
       "4  recipe ingredients: mixed baby greens, oranges...   \n",
       "\n",
       "                                        STEPS_CLEAND  \\\n",
       "0  recipe steps: heat over to 375 degrees, spray ...   \n",
       "1  recipe steps: drain rinse beans, stir all ingr...   \n",
       "2  recipe steps: heat the oil in a heavybased pan...   \n",
       "3  recipe steps: cut pork into 1 4inch slices, in...   \n",
       "4  recipe steps: in a salad bowl combine the lett...   \n",
       "\n",
       "                                  DESCRIPTION_CLEAND  \n",
       "0  recipe description: found in a crescent roll r...  \n",
       "1  recipe description: serve this flavorful and r...  \n",
       "2  recipe description: another ive not tried, but...  \n",
       "3  recipe description: another keeper from bonnie...  \n",
       "4  recipe description: i love grapefruit in a sal...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract only required columns for embedding\n",
    "COLUMNS_TO_EMBEDDE = config[\"columns_embedding\"]\n",
    "COLUMNS_TO_CLEAN = config[\"columns_to_clean\"]\n",
    "\n",
    "df_recipes_cleaned = df_recipes[ [col['column_name'] for col in COLUMNS_TO_CLEAN.values()] ]\n",
    "df_recipes_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdcdc5c",
   "metadata": {},
   "source": [
    "**create a column for each combinaison of embedding columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a9581dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamma\\AppData\\Local\\Temp\\ipykernel_9592\\3412494210.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_recipes_cleaned[col_config_name] = \"\"\n",
      "C:\\Users\\hamma\\AppData\\Local\\Temp\\ipykernel_9592\\3412494210.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_recipes_cleaned[col_config_name] += df_recipes_cleaned[f\"{column_name_cleaned}\"] + \" \"\n",
      "C:\\Users\\hamma\\AppData\\Local\\Temp\\ipykernel_9592\\3412494210.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_recipes_cleaned[col_config_name] = \"\"\n",
      "C:\\Users\\hamma\\AppData\\Local\\Temp\\ipykernel_9592\\3412494210.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_recipes_cleaned[col_config_name] += df_recipes_cleaned[f\"{column_name_cleaned}\"] + \" \"\n",
      "C:\\Users\\hamma\\AppData\\Local\\Temp\\ipykernel_9592\\3412494210.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_recipes_cleaned[col_config_name] = \"\"\n",
      "C:\\Users\\hamma\\AppData\\Local\\Temp\\ipykernel_9592\\3412494210.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_recipes_cleaned[col_config_name] += df_recipes_cleaned[f\"{column_name_cleaned}\"] + \" \"\n",
      "C:\\Users\\hamma\\AppData\\Local\\Temp\\ipykernel_9592\\3412494210.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_recipes_cleaned[col_config_name] = \"\"\n",
      "C:\\Users\\hamma\\AppData\\Local\\Temp\\ipykernel_9592\\3412494210.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_recipes_cleaned[col_config_name] += df_recipes_cleaned[f\"{column_name_cleaned}\"] + \" \"\n",
      "C:\\Users\\hamma\\AppData\\Local\\Temp\\ipykernel_9592\\3412494210.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_recipes_cleaned[col_config_name] = \"\"\n",
      "C:\\Users\\hamma\\AppData\\Local\\Temp\\ipykernel_9592\\3412494210.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_recipes_cleaned[col_config_name] += df_recipes_cleaned[f\"{column_name_cleaned}\"] + \" \"\n",
      "C:\\Users\\hamma\\AppData\\Local\\Temp\\ipykernel_9592\\3412494210.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_recipes_cleaned[col_config_name] = \"\"\n",
      "C:\\Users\\hamma\\AppData\\Local\\Temp\\ipykernel_9592\\3412494210.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_recipes_cleaned[col_config_name] += df_recipes_cleaned[f\"{column_name_cleaned}\"] + \" \"\n"
     ]
    }
   ],
   "source": [
    "#initialize a columns for each configuration of columns to embedd\n",
    "for col_config_name, cols_list in COLUMNS_TO_EMBEDDE.items():\n",
    "    df_recipes_cleaned[col_config_name] = \"\"\n",
    "\n",
    "    for col in cols_list:\n",
    "        column_name_cleaned = COLUMNS_TO_CLEAN[col]['column_name']\n",
    "        df_recipes_cleaned[col_config_name] += df_recipes_cleaned[f\"{column_name_cleaned}\"] + \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0e1be183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME_CLEAND</th>\n",
       "      <th>TAGS_CLEAND</th>\n",
       "      <th>INGREDIENTS_CLEAND</th>\n",
       "      <th>STEPS_CLEAND</th>\n",
       "      <th>DESCRIPTION_CLEAND</th>\n",
       "      <th>config_1</th>\n",
       "      <th>config_2</th>\n",
       "      <th>config_3</th>\n",
       "      <th>config_4</th>\n",
       "      <th>config_5</th>\n",
       "      <th>config_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>recipe name: crab filled crescent snacks.</td>\n",
       "      <td>recipe tags: timetomake, course, mainingredien...</td>\n",
       "      <td>recipe ingredients: crabmeat, cream cheese, gr...</td>\n",
       "      <td>recipe steps: heat over to 375 degrees, spray ...</td>\n",
       "      <td>recipe description: found in a crescent roll r...</td>\n",
       "      <td>recipe name: crab filled crescent snacks. reci...</td>\n",
       "      <td>recipe tags: timetomake, course, mainingredien...</td>\n",
       "      <td>recipe tags: timetomake, course, mainingredien...</td>\n",
       "      <td>recipe tags: timetomake, course, mainingredien...</td>\n",
       "      <td>recipe tags: timetomake, course, mainingredien...</td>\n",
       "      <td>recipe tags: timetomake, course, mainingredien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recipe name: curried bean salad.</td>\n",
       "      <td>recipe tags: curries, 30minutesorless, timetom...</td>\n",
       "      <td>recipe ingredients: garbanzo beans, black bean...</td>\n",
       "      <td>recipe steps: drain rinse beans, stir all ingr...</td>\n",
       "      <td>recipe description: serve this flavorful and r...</td>\n",
       "      <td>recipe name: curried bean salad. recipe tags: ...</td>\n",
       "      <td>recipe tags: curries, 30minutesorless, timetom...</td>\n",
       "      <td>recipe tags: curries, 30minutesorless, timetom...</td>\n",
       "      <td>recipe tags: curries, 30minutesorless, timetom...</td>\n",
       "      <td>recipe tags: curries, 30minutesorless, timetom...</td>\n",
       "      <td>recipe tags: curries, 30minutesorless, timetom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recipe name: delicious steak with onion marinade.</td>\n",
       "      <td>recipe tags: lactose, 30minutesorless, timetom...</td>\n",
       "      <td>recipe ingredients: olive oil, red onion, ligh...</td>\n",
       "      <td>recipe steps: heat the oil in a heavybased pan...</td>\n",
       "      <td>recipe description: another ive not tried, but...</td>\n",
       "      <td>recipe name: delicious steak with onion marina...</td>\n",
       "      <td>recipe tags: lactose, 30minutesorless, timetom...</td>\n",
       "      <td>recipe tags: lactose, 30minutesorless, timetom...</td>\n",
       "      <td>recipe tags: lactose, 30minutesorless, timetom...</td>\n",
       "      <td>recipe tags: lactose, 30minutesorless, timetom...</td>\n",
       "      <td>recipe tags: lactose, 30minutesorless, timetom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>recipe name: pork tenderloin with hoisin.</td>\n",
       "      <td>recipe tags: 15minutesorless, timetomake, cour...</td>\n",
       "      <td>recipe ingredients: pork tenderloin, soy sauce...</td>\n",
       "      <td>recipe steps: cut pork into 1 4inch slices, in...</td>\n",
       "      <td>recipe description: another keeper from bonnie...</td>\n",
       "      <td>recipe name: pork tenderloin with hoisin. reci...</td>\n",
       "      <td>recipe tags: 15minutesorless, timetomake, cour...</td>\n",
       "      <td>recipe tags: 15minutesorless, timetomake, cour...</td>\n",
       "      <td>recipe tags: 15minutesorless, timetomake, cour...</td>\n",
       "      <td>recipe tags: 15minutesorless, timetomake, cour...</td>\n",
       "      <td>recipe tags: 15minutesorless, timetomake, cour...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>recipe name: mixed baby greens with oranges gr...</td>\n",
       "      <td>recipe tags: 15minutesorless, timetomake, cour...</td>\n",
       "      <td>recipe ingredients: mixed baby greens, oranges...</td>\n",
       "      <td>recipe steps: in a salad bowl combine the lett...</td>\n",
       "      <td>recipe description: i love grapefruit in a sal...</td>\n",
       "      <td>recipe name: mixed baby greens with oranges gr...</td>\n",
       "      <td>recipe tags: 15minutesorless, timetomake, cour...</td>\n",
       "      <td>recipe tags: 15minutesorless, timetomake, cour...</td>\n",
       "      <td>recipe tags: 15minutesorless, timetomake, cour...</td>\n",
       "      <td>recipe tags: 15minutesorless, timetomake, cour...</td>\n",
       "      <td>recipe tags: 15minutesorless, timetomake, cour...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         NAME_CLEAND  \\\n",
       "0          recipe name: crab filled crescent snacks.   \n",
       "1                   recipe name: curried bean salad.   \n",
       "2  recipe name: delicious steak with onion marinade.   \n",
       "3          recipe name: pork tenderloin with hoisin.   \n",
       "4  recipe name: mixed baby greens with oranges gr...   \n",
       "\n",
       "                                         TAGS_CLEAND  \\\n",
       "0  recipe tags: timetomake, course, mainingredien...   \n",
       "1  recipe tags: curries, 30minutesorless, timetom...   \n",
       "2  recipe tags: lactose, 30minutesorless, timetom...   \n",
       "3  recipe tags: 15minutesorless, timetomake, cour...   \n",
       "4  recipe tags: 15minutesorless, timetomake, cour...   \n",
       "\n",
       "                                  INGREDIENTS_CLEAND  \\\n",
       "0  recipe ingredients: crabmeat, cream cheese, gr...   \n",
       "1  recipe ingredients: garbanzo beans, black bean...   \n",
       "2  recipe ingredients: olive oil, red onion, ligh...   \n",
       "3  recipe ingredients: pork tenderloin, soy sauce...   \n",
       "4  recipe ingredients: mixed baby greens, oranges...   \n",
       "\n",
       "                                        STEPS_CLEAND  \\\n",
       "0  recipe steps: heat over to 375 degrees, spray ...   \n",
       "1  recipe steps: drain rinse beans, stir all ingr...   \n",
       "2  recipe steps: heat the oil in a heavybased pan...   \n",
       "3  recipe steps: cut pork into 1 4inch slices, in...   \n",
       "4  recipe steps: in a salad bowl combine the lett...   \n",
       "\n",
       "                                  DESCRIPTION_CLEAND  \\\n",
       "0  recipe description: found in a crescent roll r...   \n",
       "1  recipe description: serve this flavorful and r...   \n",
       "2  recipe description: another ive not tried, but...   \n",
       "3  recipe description: another keeper from bonnie...   \n",
       "4  recipe description: i love grapefruit in a sal...   \n",
       "\n",
       "                                            config_1  \\\n",
       "0  recipe name: crab filled crescent snacks. reci...   \n",
       "1  recipe name: curried bean salad. recipe tags: ...   \n",
       "2  recipe name: delicious steak with onion marina...   \n",
       "3  recipe name: pork tenderloin with hoisin. reci...   \n",
       "4  recipe name: mixed baby greens with oranges gr...   \n",
       "\n",
       "                                            config_2  \\\n",
       "0  recipe tags: timetomake, course, mainingredien...   \n",
       "1  recipe tags: curries, 30minutesorless, timetom...   \n",
       "2  recipe tags: lactose, 30minutesorless, timetom...   \n",
       "3  recipe tags: 15minutesorless, timetomake, cour...   \n",
       "4  recipe tags: 15minutesorless, timetomake, cour...   \n",
       "\n",
       "                                            config_3  \\\n",
       "0  recipe tags: timetomake, course, mainingredien...   \n",
       "1  recipe tags: curries, 30minutesorless, timetom...   \n",
       "2  recipe tags: lactose, 30minutesorless, timetom...   \n",
       "3  recipe tags: 15minutesorless, timetomake, cour...   \n",
       "4  recipe tags: 15minutesorless, timetomake, cour...   \n",
       "\n",
       "                                            config_4  \\\n",
       "0  recipe tags: timetomake, course, mainingredien...   \n",
       "1  recipe tags: curries, 30minutesorless, timetom...   \n",
       "2  recipe tags: lactose, 30minutesorless, timetom...   \n",
       "3  recipe tags: 15minutesorless, timetomake, cour...   \n",
       "4  recipe tags: 15minutesorless, timetomake, cour...   \n",
       "\n",
       "                                            config_5  \\\n",
       "0  recipe tags: timetomake, course, mainingredien...   \n",
       "1  recipe tags: curries, 30minutesorless, timetom...   \n",
       "2  recipe tags: lactose, 30minutesorless, timetom...   \n",
       "3  recipe tags: 15minutesorless, timetomake, cour...   \n",
       "4  recipe tags: 15minutesorless, timetomake, cour...   \n",
       "\n",
       "                                            config_6  \n",
       "0  recipe tags: timetomake, course, mainingredien...  \n",
       "1  recipe tags: curries, 30minutesorless, timetom...  \n",
       "2  recipe tags: lactose, 30minutesorless, timetom...  \n",
       "3  recipe tags: 15minutesorless, timetomake, cour...  \n",
       "4  recipe tags: 15minutesorless, timetomake, cour...  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_recipes_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a4071057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'recipe name: crab filled crescent snacks. recipe tags: timetomake, course, mainingredient, preparation, occasion, lunch, snacks, seafood, oven, potluck, picnic, crab, dietary, shellfish, togo, equipment, 4hoursorless. recipe ingredients: crabmeat, cream cheese, green onions, garlic salt, refrigerated crescent dinner rolls, egg yolk, water, sesame seeds, sweet and sour sauce. recipe steps: heat over to 375 degrees, spray large cookie sheet with nonstick cooking spray, in small bowl , combine crabmeat , cream cheese , onions and garlic salt and mix well, unroll both cans of dough, separate into 16 triangles, cut each triangle in half lengthwise to make 32 triangles, place 1 teaspoon crab mixture on center of each triangle about 1 inch from short side of triangle, fold short ends of each triangle over filling, pinch sides to seal, roll up, place on sprayed cookie sheet, in small bowl , combine egg yolk and water and mix well, brush egg mixture over snacks, sprinkle with sesame seed, bake at 375 degrees for 15 to 20 minutes or until golden brown, serve warn snacks with sweetandsour sauce. recipe description: found in a crescent roll recipe magazine.. '"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n",
    "df_recipes_cleaned['config_1'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb199cb",
   "metadata": {},
   "source": [
    "**convert each config col to an embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d12ed388",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from torch.nn.functional import normalize\n",
    "\n",
    "MODELS_CONFIG = config[\"models\"]\n",
    "\n",
    "#create a dict {name model : model} \n",
    "MODELS_LIST = [SentenceTransformer(model_id) for model_id in MODELS_CONFIG]\n",
    "MODEL_DICT = dict(zip(MODELS_CONFIG, MODELS_LIST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3de27e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Snowflake/snowflake-arctic-embed-m-v1.5': SentenceTransformer(\n",
       "   (0): Transformer({'max_seq_length': 512, 'do_lower_case': False, 'architecture': 'BertModel'})\n",
       "   (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': True, 'pooling_mode_mean_tokens': False, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "   (2): Normalize()\n",
       " ),\n",
       " 'Snowflake/snowflake-arctic-embed-m': SentenceTransformer(\n",
       "   (0): Transformer({'max_seq_length': 512, 'do_lower_case': False, 'architecture': 'BertModel'})\n",
       "   (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': True, 'pooling_mode_mean_tokens': False, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "   (2): Normalize()\n",
       " ),\n",
       " 'intfloat/e5-base-v2': SentenceTransformer(\n",
       "   (0): Transformer({'max_seq_length': 512, 'do_lower_case': False, 'architecture': 'BertModel'})\n",
       "   (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "   (2): Normalize()\n",
       " ),\n",
       " 'sentence-transformers/all-MiniLM-L6-v2': SentenceTransformer(\n",
       "   (0): Transformer({'max_seq_length': 256, 'do_lower_case': False, 'architecture': 'BertModel'})\n",
       "   (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "   (2): Normalize()\n",
       " ),\n",
       " 'BAAI/bge-base-en-v1.5': SentenceTransformer(\n",
       "   (0): Transformer({'max_seq_length': 512, 'do_lower_case': True, 'architecture': 'BertModel'})\n",
       "   (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': True, 'pooling_mode_mean_tokens': False, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "   (2): Normalize()\n",
       " )}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_DICT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae4614f",
   "metadata": {},
   "source": [
    "**tokenizen count number of token for each config and model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "18b50a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_token_size(text: str, model: SentenceTransformer) -> int:\n",
    "    \"\"\"\n",
    "    Compute the number of tokens in the given text using the specified SentenceTransformer model.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to tokenize.\n",
    "        model (SentenceTransformer): The SentenceTransformer model used for tokenization.\n",
    "\n",
    "    Returns:\n",
    "        int: The number of tokens in the input text.\n",
    "    \"\"\"\n",
    "    # Tokenize the text using the model's tokenizer\n",
    "    tokens = model.tokenizer.tokenize(text)\n",
    "    \n",
    "    # Return the number of tokens\n",
    "    return len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df253a48",
   "metadata": {},
   "source": [
    "**Create embedding dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5f5e0e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIENCE_ID = os.getenv(\"EXPERIENCE_ID\")\n",
    "\n",
    "output_path = config[\"output_recipies_embedding_file\"].format(\n",
    "    experiment_id=EXPERIENCE_ID\n",
    ")\n",
    "\n",
    "df_recipes_embedding = df_recipes_cleaned.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ed981cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "count number token config_1 with Snowflake/snowflake-arctic-embed-m-v1.5:   0%|          | 0/1000 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (560 > 512). Running this sequence through the model will result in indexing errors\n",
      "count number token config_1 with Snowflake/snowflake-arctic-embed-m-v1.5: 100%|██████████| 1000/1000 [00:00<00:00, 1871.43it/s]\n",
      "count number token config_1 with Snowflake/snowflake-arctic-embed-m:   0%|          | 0/1000 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (560 > 512). Running this sequence through the model will result in indexing errors\n",
      "count number token config_1 with Snowflake/snowflake-arctic-embed-m: 100%|██████████| 1000/1000 [00:00<00:00, 1818.12it/s]\n",
      "count number token config_1 with intfloat/e5-base-v2:   0%|          | 0/1000 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (560 > 512). Running this sequence through the model will result in indexing errors\n",
      "count number token config_1 with intfloat/e5-base-v2: 100%|██████████| 1000/1000 [00:00<00:00, 1710.75it/s]\n",
      "count number token config_1 with sentence-transformers/all-MiniLM-L6-v2:   0%|          | 0/1000 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (265 > 256). Running this sequence through the model will result in indexing errors\n",
      "count number token config_1 with sentence-transformers/all-MiniLM-L6-v2: 100%|██████████| 1000/1000 [00:00<00:00, 1888.18it/s]\n",
      "count number token config_1 with BAAI/bge-base-en-v1.5:   0%|          | 0/1000 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (560 > 512). Running this sequence through the model will result in indexing errors\n",
      "count number token config_1 with BAAI/bge-base-en-v1.5: 100%|██████████| 1000/1000 [00:00<00:00, 1878.33it/s]\n",
      "count number token config_2 with Snowflake/snowflake-arctic-embed-m-v1.5: 100%|██████████| 1000/1000 [00:00<00:00, 3478.45it/s]\n",
      "count number token config_2 with Snowflake/snowflake-arctic-embed-m: 100%|██████████| 1000/1000 [00:00<00:00, 3542.61it/s]\n",
      "count number token config_2 with intfloat/e5-base-v2: 100%|██████████| 1000/1000 [00:00<00:00, 3171.89it/s]\n",
      "count number token config_2 with sentence-transformers/all-MiniLM-L6-v2: 100%|██████████| 1000/1000 [00:00<00:00, 3497.24it/s]\n",
      "count number token config_2 with BAAI/bge-base-en-v1.5: 100%|██████████| 1000/1000 [00:00<00:00, 3472.04it/s]\n",
      "count number token config_3 with Snowflake/snowflake-arctic-embed-m-v1.5: 100%|██████████| 1000/1000 [00:00<00:00, 2141.13it/s]\n",
      "count number token config_3 with Snowflake/snowflake-arctic-embed-m: 100%|██████████| 1000/1000 [00:00<00:00, 2143.12it/s]\n",
      "count number token config_3 with intfloat/e5-base-v2: 100%|██████████| 1000/1000 [00:00<00:00, 2043.75it/s]\n",
      "count number token config_3 with sentence-transformers/all-MiniLM-L6-v2: 100%|██████████| 1000/1000 [00:00<00:00, 2190.34it/s]\n",
      "count number token config_3 with BAAI/bge-base-en-v1.5: 100%|██████████| 1000/1000 [00:00<00:00, 2075.55it/s]\n",
      "count number token config_4 with Snowflake/snowflake-arctic-embed-m-v1.5: 100%|██████████| 1000/1000 [00:00<00:00, 5028.82it/s]\n",
      "count number token config_4 with Snowflake/snowflake-arctic-embed-m: 100%|██████████| 1000/1000 [00:00<00:00, 5174.93it/s]\n",
      "count number token config_4 with intfloat/e5-base-v2: 100%|██████████| 1000/1000 [00:00<00:00, 5275.32it/s]\n",
      "count number token config_4 with sentence-transformers/all-MiniLM-L6-v2: 100%|██████████| 1000/1000 [00:00<00:00, 5316.93it/s]\n",
      "count number token config_4 with BAAI/bge-base-en-v1.5: 100%|██████████| 1000/1000 [00:00<00:00, 5341.45it/s]\n",
      "count number token config_5 with Snowflake/snowflake-arctic-embed-m-v1.5: 100%|██████████| 1000/1000 [00:00<00:00, 2706.41it/s]\n",
      "count number token config_5 with Snowflake/snowflake-arctic-embed-m: 100%|██████████| 1000/1000 [00:00<00:00, 2678.48it/s]\n",
      "count number token config_5 with intfloat/e5-base-v2: 100%|██████████| 1000/1000 [00:00<00:00, 2776.87it/s]\n",
      "count number token config_5 with sentence-transformers/all-MiniLM-L6-v2: 100%|██████████| 1000/1000 [00:00<00:00, 2622.11it/s]\n",
      "count number token config_5 with BAAI/bge-base-en-v1.5: 100%|██████████| 1000/1000 [00:00<00:00, 2359.47it/s]\n",
      "count number token config_6 with Snowflake/snowflake-arctic-embed-m-v1.5: 100%|██████████| 1000/1000 [00:00<00:00, 4746.89it/s]\n",
      "count number token config_6 with Snowflake/snowflake-arctic-embed-m: 100%|██████████| 1000/1000 [00:00<00:00, 4130.12it/s]\n",
      "count number token config_6 with intfloat/e5-base-v2: 100%|██████████| 1000/1000 [00:00<00:00, 4573.45it/s]\n",
      "count number token config_6 with sentence-transformers/all-MiniLM-L6-v2: 100%|██████████| 1000/1000 [00:00<00:00, 4390.98it/s]\n",
      "count number token config_6 with BAAI/bge-base-en-v1.5: 100%|██████████| 1000/1000 [00:00<00:00, 4661.35it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "#count number of token for each config and model\n",
    "for col_name, cols_list in COLUMNS_TO_EMBEDDE.items():\n",
    "    for model_id, model in MODEL_DICT.items():\n",
    "\n",
    "        embedding_col = f\"{model_id}/{col_name}_EMB\"\n",
    "        tokens_col = f\"{embedding_col}_NUMBER_TOKEN\" \n",
    "\n",
    "        number_token = []\n",
    "        for text in tqdm(df_recipes_embedding[col_name], desc=f\"count number token {col_name} with {model_id}\"):\n",
    "            num_tokens = compute_token_size(text, model)\n",
    "            number_token.append(num_tokens)\n",
    "\n",
    "        df_recipes_embedding[f\"{embedding_col}_NUMBER_TOKEN\"] = number_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a45f22c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1000.000000\n",
       "mean      293.170000\n",
       "std       107.572873\n",
       "min       101.000000\n",
       "25%       220.000000\n",
       "50%       275.000000\n",
       "75%       341.000000\n",
       "max       989.000000\n",
       "Name: Snowflake/snowflake-arctic-embed-m-v1.5/config_1_EMB_NUMBER_TOKEN, dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_recipes_embedding['Snowflake/snowflake-arctic-embed-m-v1.5/config_1_EMB_NUMBER_TOKEN'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a60a2cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "373"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_recipes_embedding[df_recipes_embedding['Snowflake/snowflake-arctic-embed-m-v1.5/config_3_EMB_NUMBER_TOKEN'] > 256])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2709cdd4",
   "metadata": {},
   "source": [
    "**compute embedding for each config and model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "352421f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embedding(model: SentenceTransformer, texts: list[str]) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute normalized embeddings for a list of texts using the specified model.\n",
    "\n",
    "    Args:\n",
    "        model (SentenceTransformer): The pre-trained sentence transformer model to use.\n",
    "        texts (list[str]): A list of input texts to compute embeddings for.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: A tensor containing the normalized embeddings for the input texts.\n",
    "    \"\"\"\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Compute embeddings\n",
    "    embeddings = model.encode(texts, convert_to_tensor=True)\n",
    "    \n",
    "    # Normalize embeddings to unit length\n",
    "    normalized_embeddings = normalize(embeddings, p=2, dim=1)\n",
    "    \n",
    "    return normalized_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3d590e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding config_1 with Snowflake/snowflake-arctic-embed-m-v1.5:   1%|          | 8/1000 [00:01<03:12,  5.14it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[90]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m embeddings = []\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m tqdm(df_recipes_embedding[col_name], desc=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEmbedding \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     emb = \u001b[43mcompute_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m].cpu().numpy()                         \n\u001b[32m     12\u001b[39m     embeddings.append(emb)\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Save embeddings to new column\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[89]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mcompute_embedding\u001b[39m\u001b[34m(model, texts)\u001b[39m\n\u001b[32m     18\u001b[39m model = model.to(device)\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Compute embeddings\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m embeddings = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Normalize embeddings to unit length\u001b[39;00m\n\u001b[32m     24\u001b[39m normalized_embeddings = normalize(embeddings, p=\u001b[32m2\u001b[39m, dim=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hamma\\Desktop\\RAG exp\\RAG\\.venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hamma\\Desktop\\RAG exp\\RAG\\.venv\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:1094\u001b[39m, in \u001b[36mSentenceTransformer.encode\u001b[39m\u001b[34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, truncate_dim, pool, chunk_size, **kwargs)\u001b[39m\n\u001b[32m   1091\u001b[39m features.update(extra_features)\n\u001b[32m   1093\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m-> \u001b[39m\u001b[32m1094\u001b[39m     out_features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.device.type == \u001b[33m\"\u001b[39m\u001b[33mhpu\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1096\u001b[39m         out_features = copy.deepcopy(out_features)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hamma\\Desktop\\RAG exp\\RAG\\.venv\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:1175\u001b[39m, in \u001b[36mSentenceTransformer.forward\u001b[39m\u001b[34m(self, input, **kwargs)\u001b[39m\n\u001b[32m   1169\u001b[39m             module_kwarg_keys = \u001b[38;5;28mself\u001b[39m.module_kwargs.get(module_name, [])\n\u001b[32m   1170\u001b[39m         module_kwargs = {\n\u001b[32m   1171\u001b[39m             key: value\n\u001b[32m   1172\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs.items()\n\u001b[32m   1173\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module_kwarg_keys \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(module, \u001b[33m\"\u001b[39m\u001b[33mforward_kwargs\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module.forward_kwargs)\n\u001b[32m   1174\u001b[39m         }\n\u001b[32m-> \u001b[39m\u001b[32m1175\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hamma\\Desktop\\RAG exp\\RAG\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hamma\\Desktop\\RAG exp\\RAG\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hamma\\Desktop\\RAG exp\\RAG\\.venv\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:261\u001b[39m, in \u001b[36mTransformer.forward\u001b[39m\u001b[34m(self, features, **kwargs)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    239\u001b[39m \u001b[33;03mForward pass through the transformer model.\u001b[39;00m\n\u001b[32m    240\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    257\u001b[39m \u001b[33;03m        - 'all_layer_embeddings': If the model outputs hidden states, contains embeddings from all layers\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    259\u001b[39m trans_features = {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m features.items() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model_forward_params}\n\u001b[32m--> \u001b[39m\u001b[32m261\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    262\u001b[39m token_embeddings = outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    263\u001b[39m features[\u001b[33m\"\u001b[39m\u001b[33mtoken_embeddings\u001b[39m\u001b[33m\"\u001b[39m] = token_embeddings\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hamma\\Desktop\\RAG exp\\RAG\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hamma\\Desktop\\RAG exp\\RAG\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hamma\\Desktop\\RAG exp\\RAG\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1000\u001b[39m, in \u001b[36mBertModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m    993\u001b[39m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[32m    994\u001b[39m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[32m    995\u001b[39m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[32m    996\u001b[39m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[32m    997\u001b[39m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[32m    998\u001b[39m head_mask = \u001b[38;5;28mself\u001b[39m.get_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers)\n\u001b[32m-> \u001b[39m\u001b[32m1000\u001b[39m encoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m sequence_output = encoder_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1014\u001b[39m pooled_output = \u001b[38;5;28mself\u001b[39m.pooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hamma\\Desktop\\RAG exp\\RAG\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hamma\\Desktop\\RAG exp\\RAG\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hamma\\Desktop\\RAG exp\\RAG\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:650\u001b[39m, in \u001b[36mBertEncoder.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m    646\u001b[39m     all_hidden_states = all_hidden_states + (hidden_states,)\n\u001b[32m    648\u001b[39m layer_head_mask = head_mask[i] \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m650\u001b[39m layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# as a positional argument for gradient checkpointing\u001b[39;49;00m\n\u001b[32m    655\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    659\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    661\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    662\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hamma\\Desktop\\RAG exp\\RAG\\.venv\\Lib\\site-packages\\transformers\\modeling_layers.py:94\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning_once(message)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hamma\\Desktop\\RAG exp\\RAG\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hamma\\Desktop\\RAG exp\\RAG\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hamma\\Desktop\\RAG exp\\RAG\\.venv\\Lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hamma\\Desktop\\RAG exp\\RAG\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:588\u001b[39m, in \u001b[36mBertLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, output_attentions, cache_position)\u001b[39m\n\u001b[32m    585\u001b[39m     attention_output = cross_attention_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    586\u001b[39m     outputs = outputs + cross_attention_outputs[\u001b[32m1\u001b[39m:]  \u001b[38;5;66;03m# add cross attentions if we output attention weights\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m588\u001b[39m layer_output = \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    589\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[32m    590\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m outputs = (layer_output,) + outputs\n\u001b[32m    593\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hamma\\Desktop\\RAG exp\\RAG\\.venv\\Lib\\site-packages\\transformers\\pytorch_utils.py:257\u001b[39m, in \u001b[36mapply_chunking_to_forward\u001b[39m\u001b[34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[39m\n\u001b[32m    254\u001b[39m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[32m    255\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.cat(output_chunks, dim=chunk_dim)\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hamma\\Desktop\\RAG exp\\RAG\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:597\u001b[39m, in \u001b[36mBertLayer.feed_forward_chunk\u001b[39m\u001b[34m(self, attention_output)\u001b[39m\n\u001b[32m    595\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[32m    596\u001b[39m     intermediate_output = \u001b[38;5;28mself\u001b[39m.intermediate(attention_output)\n\u001b[32m--> \u001b[39m\u001b[32m597\u001b[39m     layer_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintermediate_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    598\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hamma\\Desktop\\RAG exp\\RAG\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hamma\\Desktop\\RAG exp\\RAG\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hamma\\Desktop\\RAG exp\\RAG\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:525\u001b[39m, in \u001b[36mBertOutput.forward\u001b[39m\u001b[34m(self, hidden_states, input_tensor)\u001b[39m\n\u001b[32m    524\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch.Tensor, input_tensor: torch.Tensor) -> torch.Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m525\u001b[39m     hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    526\u001b[39m     hidden_states = \u001b[38;5;28mself\u001b[39m.dropout(hidden_states)\n\u001b[32m    527\u001b[39m     hidden_states = \u001b[38;5;28mself\u001b[39m.LayerNorm(hidden_states + input_tensor)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hamma\\Desktop\\RAG exp\\RAG\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hamma\\Desktop\\RAG exp\\RAG\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hamma\\Desktop\\RAG exp\\RAG\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m    131\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m    Runs the forward pass.\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# #create embedding cols \n",
    "from tqdm import tqdm  \n",
    "\n",
    "for col_name, cols_list in COLUMNS_TO_EMBEDDE.items():\n",
    "    for model_id, model in MODEL_DICT.items():\n",
    "\n",
    "        embedding_col = f\"{model_id}/{col_name}_EMB\"\n",
    "                \n",
    "        embeddings = []\n",
    "        for text in tqdm(df_recipes_embedding[col_name], desc=f\"Embedding {col_name} with {model_id}\"):\n",
    "            emb = compute_embedding(model, [text])[0].cpu().numpy()                         \n",
    "            embeddings.append(emb)\n",
    "        \n",
    "        # Save embeddings to new column\n",
    "        df_recipes_embedding[embedding_col] = embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e866787",
   "metadata": {},
   "source": [
    "**write the file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "89217d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recipes_embedding.to_csv(OUTPUT_FILE_EMBEDDING, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
