{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "xaqemxzygyqb3qyfnaik",
   "authorId": "409455501850",
   "authorName": "CATFISH",
   "authorEmail": "",
   "sessionId": "dc5c8b07-9e40-4ea2-9d13-b2be87d5d7a4",
   "lastEditTime": 1767534686715
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "source": "# Import python packages\nimport streamlit as st\nimport pandas as pd\n\n# We can also use Snowpark for our analyses!\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "4f14c9fc-eb80-433b-880c-8ab2f6615124",
   "metadata": {
    "language": "python",
    "name": "cell4"
   },
   "outputs": [],
   "source": "! pip install sentence-transformers",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8475d409-bebb-4225-ad7c-ae913d76de39",
   "metadata": {
    "name": "cell2",
    "collapsed": false
   },
   "source": "**import libraries**"
  },
  {
   "cell_type": "code",
   "id": "f21bd6f9-b4f6-41ae-82c7-7f6c6becefe7",
   "metadata": {
    "language": "python",
    "name": "cell5"
   },
   "outputs": [],
   "source": "from sentence_transformers import SentenceTransformer\nfrom typing import Any, Dict, List, Optional\nimport pandas as pd\nimport re\nimport sys\nfrom tqdm import tqdm\nimport torch",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "47fdc7ce-6af5-4c13-97de-cff810b01cf3",
   "metadata": {
    "language": "python",
    "name": "cell20"
   },
   "outputs": [],
   "source": "print(torch.cuda.get_device_name(0))",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6dff10df-9b84-4eb8-94d3-8e5ea203aa96",
   "metadata": {
    "name": "cell3",
    "collapsed": false
   },
   "source": "**extract call parameters**"
  },
  {
   "cell_type": "code",
   "id": "3323ae8b-5bae-489f-9b79-2b5deb41c450",
   "metadata": {
    "language": "python",
    "name": "cell19"
   },
   "outputs": [],
   "source": "params = sys.argv\n\nsource_table = params[0]\noutput_table = params[1]\nid_column = params[2]\ncolumns_to_clean = params[3].split(',')\nembedding_model = params[4]\n\nprint(\"sys.argv:\", sys.argv)\n\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "36b23baa-795f-4271-942b-bd7db3e8381a",
   "metadata": {
    "name": "cell6",
    "collapsed": false
   },
   "source": "**import the data**"
  },
  {
   "cell_type": "code",
   "id": "99a2a0f2-8987-45a5-94c8-3b99ed8e11df",
   "metadata": {
    "language": "python",
    "name": "cell7"
   },
   "outputs": [],
   "source": "  # Example table\ncolumns = [id_column] + columns_to_clean\n\ninitial_df = session.table(source_table).to_pandas()\ndf_to_embedd = initial_df[columns].copy()\ndf_to_embedd",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "517fd2ca-a8fa-4bd5-ac63-b676e23f678e",
   "metadata": {
    "name": "cell8",
    "collapsed": false
   },
   "source": "**Clean the columns to embedd**"
  },
  {
   "cell_type": "code",
   "id": "e61a7f37-0659-40ea-ba88-caa1d4195bbb",
   "metadata": {
    "language": "python",
    "name": "cell9"
   },
   "outputs": [],
   "source": "#define function to clean text before embedding\n\ndef clean_columns_to_embedd(text_to_clean: str, start_text: str) -> str:\n    \"\"\"\n    Format text of the columns used for embedding and add a prefix to that text.\n\n    Args:\n        text_to_clean (str): The text to be cleaned and formatted.\n        start_text (str): The prefix to add to the cleaned text.\n\n    Returns:\n        str: Cleaned and formatted text in the format \"{start_text}: {cleaned_text}.\"\n             Returns empty string if input is None or empty.\n    \"\"\"\n\n    if text_to_clean is None or text_to_clean == \"\":\n        return \"\"\n\n    text = str(text_to_clean)\n\n    text = re.sub(r\"[\\[\\]'\\\"]\", \"\", text)\n\n    text = text.replace(\"|\", \",\")\n\n    text = text.lower()\n\n    text = re.sub(r\"[^a-z0-9 .,?!]+\", \"\", text)\n\n    text = re.sub(r\" +\", \" \", text)\n\n    text = re.sub(r\" ,\", \",\", text)\n\n    text = text.strip()\n\n    return f\"{start_text}: {text}.\"\n\n\ndef clean_columns_to_embedding(\n    columns_to_clean: List[str], df: pd.DataFrame\n) -> pd.DataFrame:\n    \"\"\"Extract and clean required columns for embedding.\"\"\"\n\n    for col in columns_to_clean:\n        start_text = f\" recipe {col.lower()}\"\n        df[col] = df[col].apply(lambda text: clean_columns_to_embedd(text, start_text))\n\n    return df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6de027b7-ddf3-45a1-9df4-4ab74ffbe15c",
   "metadata": {
    "language": "python",
    "name": "cell10"
   },
   "outputs": [],
   "source": "#cleant the dataframe and concat embedding columns\n\ncleaned_df = clean_columns_to_embedding(columns_to_clean, df_to_embedd)\ncleaned_df[\"TEXT_TO_EMBEDD\"] = cleaned_df[columns_to_clean].agg(\" \".join, axis=1)\ncleaned_df",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "add70eca-d58c-4e67-ac56-0f0f5f78e24c",
   "metadata": {
    "name": "cell11",
    "collapsed": false
   },
   "source": "**embedd the columns TEXT_TO_EMBEDD**"
  },
  {
   "cell_type": "code",
   "id": "1b086b1d-162b-4f85-9ba9-22414f8f7b2e",
   "metadata": {
    "language": "python",
    "name": "cell12"
   },
   "outputs": [],
   "source": "#load the model\nmodel = SentenceTransformer(\n                    embedding_model,\n                    trust_remote_code=True,\n                    device=\"cuda\",\n                )",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4f4ff88f-43f6-4b26-9680-1cba6def6644",
   "metadata": {
    "language": "python",
    "name": "cell13"
   },
   "outputs": [],
   "source": "#define funtion to compute embeddings\ndef compute_embedding_columns(\n    df: pd.DataFrame,\n    embedding_model: SentenceTransformer,\n    name_embedding_column_input: str,\n    name_embedding_column_output: str = \"EMBEDDING\",\n    batch_size: int = 128,\n) -> pd.DataFrame:\n    \"\"\"\n    Create an embedding column by computing embeddings batch by batch.\n\n    Args:\n        df (pd.DataFrame): dataframe containing the data\n        embedding_model (SentenceTransformer): model used to compute the embeddings\n        name_embedding_column_input (str): column used as input text\n        name_embedding_column_output (str): column to store embeddings\n        batch_size (int): batch size for embedding computation\n\n    Returns:\n        pd.DataFrame: dataframe with the new embedding column\n    \"\"\"\n\n    texts = df[name_embedding_column_input].tolist()\n    all_embeddings = []\n\n    # Use tqdm to show progress\n    for start_idx in tqdm(range(0, len(texts), batch_size), desc=\"Computing embeddings\"):\n        batch_texts = texts[start_idx : start_idx + batch_size]\n\n        batch_embeddings = embedding_model.encode(\n            batch_texts,\n            batch_size=batch_size,\n            show_progress_bar=False,  # tqdm will show progress instead\n            normalize_embeddings=True,\n            convert_to_numpy=True,\n        )\n\n        all_embeddings.extend(batch_embeddings)\n\n    # Convert embeddings to lists for Pandas/Snowflake\n    df[name_embedding_column_output] = [emb.tolist() for emb in all_embeddings]\n\n    return df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c120d00a-b7fe-4db5-8938-4a2400d86ceb",
   "metadata": {
    "language": "python",
    "name": "cell14"
   },
   "outputs": [],
   "source": "#compute embeddings\ncleaned_df_with_embedding = compute_embedding_columns(\n                cleaned_df,\n                model,\n                name_embedding_column_input=\"TEXT_TO_EMBEDD\",\n                name_embedding_column_output=\"EMBEDDING\",\n            )",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "07c4baac-9b52-4b79-a3d8-a8a0ae1c531e",
   "metadata": {
    "name": "cell15",
    "collapsed": false
   },
   "source": "**join with initial_df**"
  },
  {
   "cell_type": "code",
   "id": "77e84014-0b19-420c-8e8c-794d2f839ffc",
   "metadata": {
    "language": "python",
    "name": "cell16"
   },
   "outputs": [],
   "source": "# join back the id column\nembedding_df = cleaned_df_with_embedding[\n    [id_column, \"EMBEDDING\"]\n].copy()\n\n\nfinal_df = initial_df.merge(\n    embedding_df[[id_column, \"EMBEDDING\"]], on=id_column, how=\"left\"\n)\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e8d337a5-f5c9-4a72-906c-229d6a06c25d",
   "metadata": {
    "name": "cell17",
    "collapsed": false
   },
   "source": "**convert embedding to vector format**"
  },
  {
   "cell_type": "code",
   "id": "a1d2d80f-8bfc-43b7-a5a1-3e6987b2ebae",
   "metadata": {
    "language": "python",
    "name": "cell18"
   },
   "outputs": [],
   "source": "# Convert embeddings to list format for Snowflake VECTOR type\nfinal_df[\"EMBEDDING\"] = final_df[\"EMBEDDING\"].apply(\n    lambda x: x.tolist() if hasattr(x, \"tolist\") else x\n)\n\n# Get embedding dimension\nembedding_dim = len(final_df[\"EMBEDDING\"].iloc[0])\n\n# Write to a temporary table first\ntemp_table = f\"{output_table}_TEMP\"\nsession.create_dataframe(final_df).write.mode(\n    \"overwrite\"\n).save_as_table(temp_table)\n\n# Create final table with correct types\nsession.sql(\n    f\"\"\"\n    CREATE OR REPLACE TABLE {output_table} AS\n    SELECT \n        {', '.join([col for col in final_df.columns if col != 'EMBEDDING'])},\n        EMBEDDING::VECTOR(FLOAT, {embedding_dim}) as EMBEDDING\n    FROM {temp_table}\n\"\"\"\n).collect()\n\n# Drop temp table\nsession.sql(f\"DROP TABLE {temp_table}\").collect()",
   "execution_count": null
  }
 ]
}