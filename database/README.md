# Database - NutriRAG Data Pipeline

Ce dossier contient tous les scripts pour la gestion de la base de donn√©es Snowflake du projet NutriRAG, incluant la cr√©ation du sch√©ma, le chargement des donn√©es, et leur transformation.

## üìÅ Structure du dossier

```
database/
‚îú‚îÄ‚îÄ README.md                      # Ce fichier
‚îú‚îÄ‚îÄ requirements.txt               # D√©pendances Python pour le pipeline
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ python/                   # Scripts Python pour le pipeline
‚îÇ   ‚îî‚îÄ‚îÄ sql/                      # Scripts SQL pour la cr√©ation du sch√©ma
‚îî‚îÄ‚îÄ dataset/                      # (Donn√©es locales, non versionn√©)
```

## üìù Contenu des sous-dossiers

### `/scripts/python/` - Pipeline Python

Scripts d'orchestration du pipeline de donn√©es :

| Fichier | Description |
|---------|-------------|
| **main.py** | Point d'entr√©e principal - orchestre tout le pipeline |
| **PipelineOrchestrator.py** | Orchestre les phases du pipeline (setup, load, clean, ingest) |
| **SnowflakeConnector.py** | G√®re la connexion √† Snowflake |
| **DataLoader.py** | Charge les donn√©es depuis Google Drive et Kaggle |
| **DataTransformer.py** | Transforme et nettoie les donn√©es |
| **RecipeCleaner.py** | Sp√©cifique au nettoyage des recettes |
| **IngredientParser.py** | Parse et traite les ingr√©dients |
| **SnowFlakeIngestor.py** | Ing√®re les donn√©es dans Snowflake |
| **SqlInsertGenerator.py** | G√©n√®re les requ√™tes SQL INSERT |
| **generate_schema.py** | G√©n√®re le sch√©ma SQL √† partir du template |
| **create_ingredients_quantities_csv.py** | Cr√©e un CSV des quantit√©s d'ingr√©dients |
| **config.py** | Configuration locale |
| **requirements.txt** | D√©pendances Python |

### `/scripts/sql/` - Sch√©mas SQL

Scripts de cr√©ation et configuration du sch√©ma Snowflake :

| Fichier | Description |
|---------|-------------|
| **schema_db_template.sql** | Template du sch√©ma (variables `${DATABASE_NAME}`, `${WAREHOUSE_NAME}`) |
| **schema_db_generated.sql** | Sch√©ma g√©n√©r√© avec les vraies valeurs |
| **schema_db.sql** | Sch√©ma statique (legacy) |
| **ingest_clean_recipes.sql** | SQL pour ing√©rer et nettoyer les recettes |
| **nutri_score.sql** | Calcul du nutri-score |
| **parse_quantity_udf.sql** | UDF Snowflake pour parser les quantit√©s |

## üöÄ D√©marrage rapide

### 1. Installation des d√©pendances

```bash
# Depuis la racine du projet
pip install -r database/requirements.txt
```

### 2. Configuration Snowflake

Cr√©ez ou compl√©tez un fichier `.env` √† la racine du projet :

```bash
# Snowflake credentials
SNOWFLAKE_ACCOUNT=your_account_id
SNOWFLAKE_USER=your_username
SNOWFLAKE_ROLE=your_role
SNOWFLAKE_WAREHOUSE=NUTRIRAG_PROJECT
SNOWFLAKE_DATABASE=NUTRIRAG_PROJECT

# Authentification par cl√© priv√©e (recommand√©)
SNOWFLAKE_PRIVATE_KEY_PATH=/path/to/snowflake_key.pem
SNOWFLAKE_PRIVATE_KEY_PASSPHRASE=your_passphrase  # Optionnel

```

### 3. Lancer le pipeline complet

```bash
# Pipeline complet (setup ‚Üí load ‚Üí clean ‚Üí ingest)
python database/scripts/python/main.py

# Avec un nombre limit√© de lignes (pour test)
python database/scripts/python/main.py --nrows 1000
```

## üéØ Commandes d√©taill√©es

Le script `main.py` supporte plusieurs options pour ex√©cuter partiellement le pipeline :

### Pipeline complet
```bash
python database/scripts/python/main.py
```

### Phase 0 - Setup uniquement (cr√©er le sch√©ma)
```bash
python database/scripts/python/main.py --setup-only
```

### Phase 1 - Load uniquement (charger les donn√©es)
```bash
python database/scripts/python/main.py --load-only
```

### Phase 2 - Clean uniquement (nettoyer les donn√©es)
```bash
python database/scripts/python/main.py --clean-only
```

### Phase 3 - Ingest uniquement (ins√©rer dans Snowflake)
```bash
python database/scripts/python/main.py --ingest-only
```

### Traiter uniquement les ingr√©dients
```bash
python database/scripts/python/main.py --process-ingredients
```

### Limiter √† N lignes (test)
```bash
python database/scripts/python/main.py --nrows 500
```

## üîÑ Phases du pipeline

### Phase 0 : Setup Snowflake
1. G√©n√®re le sch√©ma SQL depuis `schema_db_template.sql`
2. Cr√©e les warehouses, databases et schemas
3. Cr√©e les tables n√©cessaires

### Phase 1 : Load (Chargement)
1. T√©l√©charge les donn√©es depuis les fichiers en local

### Phase 2 : Clean (Nettoyage)
1. Nettoie les recettes
2. Parse les ingr√©dients
3. Calcule les quantit√©s
4. Valide les donn√©es

### Phase 3 : Ingest (Ingestion)
1. Ing√®re les donn√©es dans Snowflake
2. Valide l'int√©grit√©

## üìä Structure du sch√©ma Snowflake

Le sch√©ma cr√©√© contient 4 schemas principaux :

| Schema | Contenu |
|--------|---------|
| **RAW** | Donn√©es brutes (non trait√©es) |
| **CLEANED** | Donn√©es nettoy√©es et valid√©es |
| **DEV_SAMPLE** | √âchantillon de d√©veloppement (moins de donn√©es) |
| **ANALYTICS** | Tables analytiques et r√©sum√©s |

### Tables principales

- `RECIPES_*` : Donn√©es des recettes
- `INGREDIENTS_*` : Donn√©es des ingr√©dients
- `NUTRITION_*` : Donn√©es nutritionnelles
- `*_EMBEDDINGS` : Embeddings vectoriels


## üìù Logs

Les logs sont affich√©s en console et contiennent :
- Timestamp de chaque op√©ration
- Niveau (INFO, WARNING, ERROR)
- Nom du module
- Message d√©taill√©

Exemple :
```
2026-01-03 12:58:00 - PipelineOrchestrator - INFO - ‚úÖ Phase 0: Schema setup completed
2026-01-03 12:59:00 - DataLoader - INFO - Loaded 100000 recipes
```

## üí° Conseils d'utilisation

- Toujours tester avec `--nrows 10000` avant un pipeline complet
- Utiliser `--setup-only` pour v√©rifier la configuration Snowflake
- V√©rifier les logs pour identifier les √©tapes bloquantes
- La phase d'ingestion est la plus longue (peut prendre plusieurs minutes)
- R√©utiliser les donn√©es t√©l√©charg√©es (elles sont cach√©es localement)

## üë§ Support

Pour questions ou probl√®mes, consulter :
- Les logs du pipeline
- Les docstrings des fichiers Python

