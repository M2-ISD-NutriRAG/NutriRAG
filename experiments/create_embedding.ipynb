{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26905175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added backend to sys.path: c:\\Users\\hamma\\Desktop\\project\\NutriRAG\\backend\n",
      "Returned to original working directory: c:\\Users\\hamma\\Desktop\\project\\NutriRAG\\experiments\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "original_cwd = os.getcwd()\n",
    "\n",
    "backend_path = os.path.abspath(os.path.join(original_cwd, \"../backend\"))\n",
    "added_backend = False\n",
    "\n",
    "if not any(\"backend\" in p for p in sys.path):\n",
    "    sys.path.insert(0, backend_path)\n",
    "    added_backend = True\n",
    "    print(f\"Added backend to sys.path: {backend_path}\")\n",
    "else:\n",
    "    print(\"Backend already in sys.path, skipping.\")\n",
    "\n",
    "from shared.snowflake.client import SnowflakeClient\n",
    "\n",
    "os.chdir(original_cwd)\n",
    "print(f\"Returned to original working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5e697a",
   "metadata": {},
   "source": [
    "**read the config file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e93e66d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_FILE_PATH = \"config/base_config.json\"\n",
    "\n",
    "with open(CONFIG_FILE_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306de016",
   "metadata": {},
   "source": [
    "**get the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96b97fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File data/recipes_samples.csv already exists. Skipping save.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>NAME_CLEAND</th>\n",
       "      <th>INGREDIENTS_CLEAND</th>\n",
       "      <th>STEPS_CLEAND</th>\n",
       "      <th>DESCRIPTION_CLEAND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>421766</td>\n",
       "      <td>recipe name: stuffed mussels in spicy tomato s...</td>\n",
       "      <td>recipe ingredients: mussels, ground beef, crus...</td>\n",
       "      <td>recipe steps: beard and clean mussels, open mu...</td>\n",
       "      <td>recipe description: stuffed mussels is a favor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>148350</td>\n",
       "      <td>recipe name: bob s meat.</td>\n",
       "      <td>recipe ingredients: puff pastry, bacon, onion,...</td>\n",
       "      <td>recipe steps: remove package of puff pastry fr...</td>\n",
       "      <td>recipe description: this is a wonderfully tast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>351663</td>\n",
       "      <td>recipe name: grilled turkey breast.</td>\n",
       "      <td>recipe ingredients: cider vinegar, garlic, gro...</td>\n",
       "      <td>recipe steps: in a medium bowl, combine the ci...</td>\n",
       "      <td>recipe description: source cooking with the di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45766</td>\n",
       "      <td>recipe name: raisin banana bread.</td>\n",
       "      <td>recipe ingredients: water, bread flour, banana...</td>\n",
       "      <td>recipe steps: measure carefully, placing all i...</td>\n",
       "      <td>recipe description: sounds like a winner to me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>163701</td>\n",
       "      <td>recipe name: lime pound cake 1968.</td>\n",
       "      <td>recipe ingredients: butter, granulated sugar, ...</td>\n",
       "      <td>recipe steps: grease a ten inch tube pan, line...</td>\n",
       "      <td>recipe description: this pound cake takes baki...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID                                        NAME_CLEAND  \\\n",
       "0  421766  recipe name: stuffed mussels in spicy tomato s...   \n",
       "1  148350                           recipe name: bob s meat.   \n",
       "2  351663                recipe name: grilled turkey breast.   \n",
       "3   45766                  recipe name: raisin banana bread.   \n",
       "4  163701                 recipe name: lime pound cake 1968.   \n",
       "\n",
       "                                  INGREDIENTS_CLEAND  \\\n",
       "0  recipe ingredients: mussels, ground beef, crus...   \n",
       "1  recipe ingredients: puff pastry, bacon, onion,...   \n",
       "2  recipe ingredients: cider vinegar, garlic, gro...   \n",
       "3  recipe ingredients: water, bread flour, banana...   \n",
       "4  recipe ingredients: butter, granulated sugar, ...   \n",
       "\n",
       "                                        STEPS_CLEAND  \\\n",
       "0  recipe steps: beard and clean mussels, open mu...   \n",
       "1  recipe steps: remove package of puff pastry fr...   \n",
       "2  recipe steps: in a medium bowl, combine the ci...   \n",
       "3  recipe steps: measure carefully, placing all i...   \n",
       "4  recipe steps: grease a ten inch tube pan, line...   \n",
       "\n",
       "                                  DESCRIPTION_CLEAND  \n",
       "0  recipe description: stuffed mussels is a favor...  \n",
       "1  recipe description: this is a wonderfully tast...  \n",
       "2  recipe description: source cooking with the di...  \n",
       "3  recipe description: sounds like a winner to me...  \n",
       "4  recipe description: this pound cake takes baki...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_RECIPIES_FILE = config['input_recipies_file']\n",
    "df_recipes = pd.DataFrame()\n",
    "\n",
    "#check if the file already exists read it\n",
    "if os.path.exists(INPUT_RECIPIES_FILE):\n",
    "    print(f\"File {INPUT_RECIPIES_FILE} already exists. Skipping save.\")\n",
    "    df_recipes = pd.read_csv(INPUT_RECIPIES_FILE)\n",
    "else:\n",
    "    print(f\"Saving DataFrame to {INPUT_RECIPIES_FILE}\")\n",
    "    client = SnowflakeClient()\n",
    "\n",
    "    conn = client._conn\n",
    "    table = \"RECIPES_SAMPLE_EVAL_EMBEDDING\"\n",
    "\n",
    "    df_recipes = pd.read_sql(f\"SELECT * FROM {table}\", conn)\n",
    "\n",
    "    client.close()\n",
    "    \n",
    "    df_recipes.to_csv(INPUT_RECIPIES_FILE, index=False)\n",
    "\n",
    "df_recipes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207db5aa",
   "metadata": {},
   "source": [
    "**define a function that clean the columns used for embedding** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "641a1358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_columns_to_embedd(tag_value: any, col_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Format text of the columns used for embedding\n",
    "\n",
    "    Args:\n",
    "        tag_value (any): The input value to clean. Can be a string, list, number, or None.\n",
    "                        Will be converted to string before processing.\n",
    "        col_name (str): The label/prefix to add before the cleaned text \n",
    "                       (e.g., \"NAME\", \"TAGS\", \"INGREDIENTS\").\n",
    "    \n",
    "    Returns:\n",
    "        str: Cleaned and formatted text in the format \"{col_name}: {cleaned_text}.\"\n",
    "             Returns empty string if input is None or empty.\n",
    "    \"\"\"\n",
    "    \n",
    "    if tag_value is None or tag_value == \"\":\n",
    "        return \"\"\n",
    "    \n",
    "    text = str(tag_value)\n",
    "    \n",
    "    # Remove list brackets and quotes\n",
    "    text = re.sub(r\"[\\[\\]'\\\"]\", \"\", text)\n",
    "    \n",
    "    text = text.replace(\"|\", \",\")\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Keep only alphanumeric, spaces, and . , ? !\n",
    "    text = re.sub(r\"[^a-z0-9 .,?!]+\", \"\", text)\n",
    "    \n",
    "    # Remove excess spaces\n",
    "    text = re.sub(r\" +\", \" \", text)\n",
    "    \n",
    "    # Remove spaces before commas\n",
    "    text = re.sub(r\" ,\", \",\", text)\n",
    "    \n",
    "    # Clean up spaces around punctuation\n",
    "    text = text.strip()\n",
    "    \n",
    "    # Return formatted text\n",
    "    return f\"{col_name}: {text}.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3e7430",
   "metadata": {},
   "source": [
    "**extract only required columns for embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c7b0933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME_CLEAND</th>\n",
       "      <th>INGREDIENTS_CLEAND</th>\n",
       "      <th>STEPS_CLEAND</th>\n",
       "      <th>DESCRIPTION_CLEAND</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>recipe name: recipe name stuffed mussels in sp...</td>\n",
       "      <td>recipe ingredients: recipe ingredients mussels...</td>\n",
       "      <td>recipe steps: recipe steps beard and clean mus...</td>\n",
       "      <td>recipe description: recipe description stuffed...</td>\n",
       "      <td>421766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recipe name: recipe name bob s meat..</td>\n",
       "      <td>recipe ingredients: recipe ingredients puff pa...</td>\n",
       "      <td>recipe steps: recipe steps remove package of p...</td>\n",
       "      <td>recipe description: recipe description this is...</td>\n",
       "      <td>148350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recipe name: recipe name grilled turkey breast..</td>\n",
       "      <td>recipe ingredients: recipe ingredients cider v...</td>\n",
       "      <td>recipe steps: recipe steps in a medium bowl, c...</td>\n",
       "      <td>recipe description: recipe description source ...</td>\n",
       "      <td>351663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>recipe name: recipe name raisin banana bread..</td>\n",
       "      <td>recipe ingredients: recipe ingredients water, ...</td>\n",
       "      <td>recipe steps: recipe steps measure carefully, ...</td>\n",
       "      <td>recipe description: recipe description sounds ...</td>\n",
       "      <td>45766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>recipe name: recipe name lime pound cake 1968..</td>\n",
       "      <td>recipe ingredients: recipe ingredients butter,...</td>\n",
       "      <td>recipe steps: recipe steps grease a ten inch t...</td>\n",
       "      <td>recipe description: recipe description this po...</td>\n",
       "      <td>163701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         NAME_CLEAND  \\\n",
       "0  recipe name: recipe name stuffed mussels in sp...   \n",
       "1              recipe name: recipe name bob s meat..   \n",
       "2   recipe name: recipe name grilled turkey breast..   \n",
       "3     recipe name: recipe name raisin banana bread..   \n",
       "4    recipe name: recipe name lime pound cake 1968..   \n",
       "\n",
       "                                  INGREDIENTS_CLEAND  \\\n",
       "0  recipe ingredients: recipe ingredients mussels...   \n",
       "1  recipe ingredients: recipe ingredients puff pa...   \n",
       "2  recipe ingredients: recipe ingredients cider v...   \n",
       "3  recipe ingredients: recipe ingredients water, ...   \n",
       "4  recipe ingredients: recipe ingredients butter,...   \n",
       "\n",
       "                                        STEPS_CLEAND  \\\n",
       "0  recipe steps: recipe steps beard and clean mus...   \n",
       "1  recipe steps: recipe steps remove package of p...   \n",
       "2  recipe steps: recipe steps in a medium bowl, c...   \n",
       "3  recipe steps: recipe steps measure carefully, ...   \n",
       "4  recipe steps: recipe steps grease a ten inch t...   \n",
       "\n",
       "                                  DESCRIPTION_CLEAND      ID  \n",
       "0  recipe description: recipe description stuffed...  421766  \n",
       "1  recipe description: recipe description this is...  148350  \n",
       "2  recipe description: recipe description source ...  351663  \n",
       "3  recipe description: recipe description sounds ...   45766  \n",
       "4  recipe description: recipe description this po...  163701  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract only required columns for embedding\n",
    "COLUMNS_TO_CLEAN = config[\"columns_to_clean\"]\n",
    "\n",
    "for col in COLUMNS_TO_CLEAN:\n",
    "    col_clean_name = COLUMNS_TO_CLEAN[col]['column_name']\n",
    "    start_text = COLUMNS_TO_CLEAN[col]['start_text']\n",
    "\n",
    "    df_recipes[col_clean_name] = df_recipes[col].apply(clean_columns_to_embedd, args=(start_text, ))\n",
    "\n",
    "df_recipes_cleaned = df_recipes[ [col['column_name'] for col in COLUMNS_TO_CLEAN.values()] ]\n",
    "\n",
    "#add the id to keep track of the recepies\n",
    "df_recipes_cleaned['ID'] = df_recipes['ID'] \n",
    "df_recipes_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdcdc5c",
   "metadata": {},
   "source": [
    "**create a column for each combinaison of embedding columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9581dc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME_CLEAND</th>\n",
       "      <th>INGREDIENTS_CLEAND</th>\n",
       "      <th>STEPS_CLEAND</th>\n",
       "      <th>DESCRIPTION_CLEAND</th>\n",
       "      <th>ID</th>\n",
       "      <th>config_1</th>\n",
       "      <th>config_2</th>\n",
       "      <th>config_3</th>\n",
       "      <th>config_4</th>\n",
       "      <th>config_5</th>\n",
       "      <th>config_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>recipe name: recipe name stuffed mussels in sp...</td>\n",
       "      <td>recipe ingredients: recipe ingredients mussels...</td>\n",
       "      <td>recipe steps: recipe steps beard and clean mus...</td>\n",
       "      <td>recipe description: recipe description stuffed...</td>\n",
       "      <td>421766</td>\n",
       "      <td>recipe name: recipe name stuffed mussels in sp...</td>\n",
       "      <td>recipe name: recipe name stuffed mussels in sp...</td>\n",
       "      <td>recipe name: recipe name stuffed mussels in sp...</td>\n",
       "      <td>recipe name: recipe name stuffed mussels in sp...</td>\n",
       "      <td>recipe name: recipe name stuffed mussels in sp...</td>\n",
       "      <td>recipe name: recipe name stuffed mussels in sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recipe name: recipe name bob s meat..</td>\n",
       "      <td>recipe ingredients: recipe ingredients puff pa...</td>\n",
       "      <td>recipe steps: recipe steps remove package of p...</td>\n",
       "      <td>recipe description: recipe description this is...</td>\n",
       "      <td>148350</td>\n",
       "      <td>recipe name: recipe name bob s meat.. recipe i...</td>\n",
       "      <td>recipe name: recipe name bob s meat.. recipe i...</td>\n",
       "      <td>recipe name: recipe name bob s meat.. recipe i...</td>\n",
       "      <td>recipe name: recipe name bob s meat.. recipe s...</td>\n",
       "      <td>recipe name: recipe name bob s meat.. recipe i...</td>\n",
       "      <td>recipe name: recipe name bob s meat.. recipe s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recipe name: recipe name grilled turkey breast..</td>\n",
       "      <td>recipe ingredients: recipe ingredients cider v...</td>\n",
       "      <td>recipe steps: recipe steps in a medium bowl, c...</td>\n",
       "      <td>recipe description: recipe description source ...</td>\n",
       "      <td>351663</td>\n",
       "      <td>recipe name: recipe name grilled turkey breast...</td>\n",
       "      <td>recipe name: recipe name grilled turkey breast...</td>\n",
       "      <td>recipe name: recipe name grilled turkey breast...</td>\n",
       "      <td>recipe name: recipe name grilled turkey breast...</td>\n",
       "      <td>recipe name: recipe name grilled turkey breast...</td>\n",
       "      <td>recipe name: recipe name grilled turkey breast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>recipe name: recipe name raisin banana bread..</td>\n",
       "      <td>recipe ingredients: recipe ingredients water, ...</td>\n",
       "      <td>recipe steps: recipe steps measure carefully, ...</td>\n",
       "      <td>recipe description: recipe description sounds ...</td>\n",
       "      <td>45766</td>\n",
       "      <td>recipe name: recipe name raisin banana bread.....</td>\n",
       "      <td>recipe name: recipe name raisin banana bread.....</td>\n",
       "      <td>recipe name: recipe name raisin banana bread.....</td>\n",
       "      <td>recipe name: recipe name raisin banana bread.....</td>\n",
       "      <td>recipe name: recipe name raisin banana bread.....</td>\n",
       "      <td>recipe name: recipe name raisin banana bread.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>recipe name: recipe name lime pound cake 1968..</td>\n",
       "      <td>recipe ingredients: recipe ingredients butter,...</td>\n",
       "      <td>recipe steps: recipe steps grease a ten inch t...</td>\n",
       "      <td>recipe description: recipe description this po...</td>\n",
       "      <td>163701</td>\n",
       "      <td>recipe name: recipe name lime pound cake 1968....</td>\n",
       "      <td>recipe name: recipe name lime pound cake 1968....</td>\n",
       "      <td>recipe name: recipe name lime pound cake 1968....</td>\n",
       "      <td>recipe name: recipe name lime pound cake 1968....</td>\n",
       "      <td>recipe name: recipe name lime pound cake 1968....</td>\n",
       "      <td>recipe name: recipe name lime pound cake 1968....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         NAME_CLEAND  \\\n",
       "0  recipe name: recipe name stuffed mussels in sp...   \n",
       "1              recipe name: recipe name bob s meat..   \n",
       "2   recipe name: recipe name grilled turkey breast..   \n",
       "3     recipe name: recipe name raisin banana bread..   \n",
       "4    recipe name: recipe name lime pound cake 1968..   \n",
       "\n",
       "                                  INGREDIENTS_CLEAND  \\\n",
       "0  recipe ingredients: recipe ingredients mussels...   \n",
       "1  recipe ingredients: recipe ingredients puff pa...   \n",
       "2  recipe ingredients: recipe ingredients cider v...   \n",
       "3  recipe ingredients: recipe ingredients water, ...   \n",
       "4  recipe ingredients: recipe ingredients butter,...   \n",
       "\n",
       "                                        STEPS_CLEAND  \\\n",
       "0  recipe steps: recipe steps beard and clean mus...   \n",
       "1  recipe steps: recipe steps remove package of p...   \n",
       "2  recipe steps: recipe steps in a medium bowl, c...   \n",
       "3  recipe steps: recipe steps measure carefully, ...   \n",
       "4  recipe steps: recipe steps grease a ten inch t...   \n",
       "\n",
       "                                  DESCRIPTION_CLEAND      ID  \\\n",
       "0  recipe description: recipe description stuffed...  421766   \n",
       "1  recipe description: recipe description this is...  148350   \n",
       "2  recipe description: recipe description source ...  351663   \n",
       "3  recipe description: recipe description sounds ...   45766   \n",
       "4  recipe description: recipe description this po...  163701   \n",
       "\n",
       "                                            config_1  \\\n",
       "0  recipe name: recipe name stuffed mussels in sp...   \n",
       "1  recipe name: recipe name bob s meat.. recipe i...   \n",
       "2  recipe name: recipe name grilled turkey breast...   \n",
       "3  recipe name: recipe name raisin banana bread.....   \n",
       "4  recipe name: recipe name lime pound cake 1968....   \n",
       "\n",
       "                                            config_2  \\\n",
       "0  recipe name: recipe name stuffed mussels in sp...   \n",
       "1  recipe name: recipe name bob s meat.. recipe i...   \n",
       "2  recipe name: recipe name grilled turkey breast...   \n",
       "3  recipe name: recipe name raisin banana bread.....   \n",
       "4  recipe name: recipe name lime pound cake 1968....   \n",
       "\n",
       "                                            config_3  \\\n",
       "0  recipe name: recipe name stuffed mussels in sp...   \n",
       "1  recipe name: recipe name bob s meat.. recipe i...   \n",
       "2  recipe name: recipe name grilled turkey breast...   \n",
       "3  recipe name: recipe name raisin banana bread.....   \n",
       "4  recipe name: recipe name lime pound cake 1968....   \n",
       "\n",
       "                                            config_4  \\\n",
       "0  recipe name: recipe name stuffed mussels in sp...   \n",
       "1  recipe name: recipe name bob s meat.. recipe s...   \n",
       "2  recipe name: recipe name grilled turkey breast...   \n",
       "3  recipe name: recipe name raisin banana bread.....   \n",
       "4  recipe name: recipe name lime pound cake 1968....   \n",
       "\n",
       "                                            config_5  \\\n",
       "0  recipe name: recipe name stuffed mussels in sp...   \n",
       "1  recipe name: recipe name bob s meat.. recipe i...   \n",
       "2  recipe name: recipe name grilled turkey breast...   \n",
       "3  recipe name: recipe name raisin banana bread.....   \n",
       "4  recipe name: recipe name lime pound cake 1968....   \n",
       "\n",
       "                                            config_6  \n",
       "0  recipe name: recipe name stuffed mussels in sp...  \n",
       "1  recipe name: recipe name bob s meat.. recipe s...  \n",
       "2  recipe name: recipe name grilled turkey breast...  \n",
       "3  recipe name: recipe name raisin banana bread.....  \n",
       "4  recipe name: recipe name lime pound cake 1968....  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialize a columns for each configuration of columns to embedd\n",
    "COLUMNS_TO_EMBEDDE = config[\"columns_embedding\"]\n",
    "\n",
    "for col_config_name, cols_list in COLUMNS_TO_EMBEDDE.items():\n",
    "    df_recipes_cleaned[col_config_name] = \"\"\n",
    "\n",
    "    for col in cols_list:\n",
    "        column_name_cleaned = COLUMNS_TO_CLEAN[col]['column_name']\n",
    "        df_recipes_cleaned[col_config_name] += df_recipes_cleaned[f\"{column_name_cleaned}\"] + \" \"\n",
    "        \n",
    "df_recipes_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4071057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'recipe name: recipe name stuffed mussels in spicy tomato sauce.. recipe ingredients: recipe ingredients mussels, ground beef, crusty bread, broth, flat leaf parsley, garlic clove, ground black pepper, parmesan cheese, egg, salt, tomatoes, garlic cloves, chili pepper, olive oil.. recipe steps: recipe steps beard and clean mussels, open mussels over bowl to collect liquid, set aside, cut stale bread up into cubes, place in bowl and moisten with broth, let stand till bread has softened, squeeze bread well of all liquid, mix all the stuffing ingredients well in a bowl, stuff mussels placing a heaping tablespoon of the stuffing on an open shell, press the two shells shut and wipe off the stuffing that squishes out, make the tomato sauce saut garlic, chili pepper and parsley in the oil over medium heat, add the crushed peeled tomatoes, stir and then add the mussel juice youve kept aside, let sauce simmer for about 15 minutes, gently place mussels into pan, cover and let mussels stew for about half an hour or until stuffing has cooked through, serve and garnish with a sprinkling of parsley.. recipe description: recipe description stuffed mussels is a favorite throughout italy. in tuscany alone there are at least three traditional dishes to my knowledge. this is how they cook em up in livorno. see the video for this recipe at the following link httpwww.youtube.comwatch?vu0hsrczklo.. '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n",
    "df_recipes_cleaned['config_1'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb199cb",
   "metadata": {},
   "source": [
    "**load the embedding models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d12ed388",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hamma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#load the models\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from torch.nn.functional import normalize\n",
    "\n",
    "MODELS_CONFIG = config[\"models\"]\n",
    "\n",
    "#create a dict {name model : model} \n",
    "MODELS_LIST = [SentenceTransformer(model_id) for model_id in MODELS_CONFIG]\n",
    "MODEL_DICT = dict(zip(MODELS_CONFIG, MODELS_LIST))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae4614f",
   "metadata": {},
   "source": [
    "**define a function that count number of token for each config and model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18b50a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_token_size(text: str, model: SentenceTransformer) -> int:\n",
    "    \"\"\"\n",
    "    Compute the number of tokens in the given text using the specified SentenceTransformer model.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to tokenize.\n",
    "        model (SentenceTransformer): The SentenceTransformer model used for tokenization.\n",
    "\n",
    "    Returns:\n",
    "        int: The number of tokens in the input text.\n",
    "    \"\"\"\n",
    "\n",
    "    tokens = model.tokenizer.tokenize(text)\n",
    "    \n",
    "    return len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13513d8",
   "metadata": {},
   "source": [
    "**set the experience id**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "626996ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "EXPERIENCE_ID = config[\"experiments_specifique_params\"][\"experiment_id\"]\n",
    "\n",
    "print(EXPERIENCE_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df253a48",
   "metadata": {},
   "source": [
    "**set folder and file path for embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f5e0e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiments/exp1/\n",
      "experiments/exp1/recipies_samples_embeddings.csv\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_EMBEDDING_FOLDER = config[\"output_experiments_dir\"].format(\n",
    "    experiment_id=EXPERIENCE_ID\n",
    ")\n",
    "\n",
    "os.makedirs(OUTPUT_EMBEDDING_FOLDER, exist_ok=True)\n",
    "\n",
    "OUTPUT_EMBEDDING_FILE = config[\"output_recipies_embedding_file\"].format(\n",
    "    experiment_id=EXPERIENCE_ID\n",
    ")\n",
    "\n",
    "print(OUTPUT_EMBEDDING_FOLDER)\n",
    "print(OUTPUT_EMBEDDING_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486bae45",
   "metadata": {},
   "source": [
    "**calculate number of token per recipie for each config and model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed981cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "count number token config_1 with intfloat/e5-small-v2:   0%|          | 0/1000 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (583 > 512). Running this sequence through the model will result in indexing errors\n",
      "count number token config_1 with intfloat/e5-small-v2: 100%|██████████| 1000/1000 [00:00<00:00, 2541.07it/s]\n",
      "count number token config_1 with intfloat/e5-base-v2:   0%|          | 0/1000 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (583 > 512). Running this sequence through the model will result in indexing errors\n",
      "count number token config_1 with intfloat/e5-base-v2: 100%|██████████| 1000/1000 [00:00<00:00, 2582.50it/s]\n",
      "count number token config_1 with sentence-transformers/all-MiniLM-L6-v2:   0%|          | 0/1000 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (331 > 256). Running this sequence through the model will result in indexing errors\n",
      "count number token config_1 with sentence-transformers/all-MiniLM-L6-v2: 100%|██████████| 1000/1000 [00:00<00:00, 2601.14it/s]\n",
      "count number token config_1 with thenlper/gte-small:   0%|          | 0/1000 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (583 > 512). Running this sequence through the model will result in indexing errors\n",
      "count number token config_1 with thenlper/gte-small: 100%|██████████| 1000/1000 [00:00<00:00, 2536.40it/s]\n",
      "count number token config_1 with thenlper/gte-base:   0%|          | 0/1000 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (583 > 512). Running this sequence through the model will result in indexing errors\n",
      "count number token config_1 with thenlper/gte-base: 100%|██████████| 1000/1000 [00:00<00:00, 2568.47it/s]\n",
      "count number token config_1 with BAAI/bge-small-en:   0%|          | 0/1000 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (583 > 512). Running this sequence through the model will result in indexing errors\n",
      "count number token config_1 with BAAI/bge-small-en: 100%|██████████| 1000/1000 [00:00<00:00, 2551.78it/s]\n",
      "count number token config_1 with BAAI/bge-base-en:   0%|          | 0/1000 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (583 > 512). Running this sequence through the model will result in indexing errors\n",
      "count number token config_1 with BAAI/bge-base-en: 100%|██████████| 1000/1000 [00:00<00:00, 2595.69it/s]\n",
      "count number token config_1 with BAAI/llm-embedder:   0%|          | 0/1000 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (583 > 512). Running this sequence through the model will result in indexing errors\n",
      "count number token config_1 with BAAI/llm-embedder: 100%|██████████| 1000/1000 [00:00<00:00, 2571.60it/s]\n",
      "count number token config_1 with Snowflake/snowflake-arctic-embed-m:   0%|          | 0/1000 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (583 > 512). Running this sequence through the model will result in indexing errors\n",
      "count number token config_1 with Snowflake/snowflake-arctic-embed-m: 100%|██████████| 1000/1000 [00:00<00:00, 2606.53it/s]\n",
      "count number token config_1 with Snowflake/snowflake-arctic-embed-m-v1.5:   0%|          | 0/1000 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (583 > 512). Running this sequence through the model will result in indexing errors\n",
      "count number token config_1 with Snowflake/snowflake-arctic-embed-m-v1.5: 100%|██████████| 1000/1000 [00:00<00:00, 2578.47it/s]\n",
      "count number token config_2 with intfloat/e5-small-v2: 100%|██████████| 1000/1000 [00:00<00:00, 5347.74it/s]\n",
      "count number token config_2 with intfloat/e5-base-v2: 100%|██████████| 1000/1000 [00:00<00:00, 5319.08it/s]\n",
      "count number token config_2 with sentence-transformers/all-MiniLM-L6-v2: 100%|██████████| 1000/1000 [00:00<00:00, 5315.35it/s]\n",
      "count number token config_2 with thenlper/gte-small: 100%|██████████| 1000/1000 [00:00<00:00, 5364.11it/s]\n",
      "count number token config_2 with thenlper/gte-base: 100%|██████████| 1000/1000 [00:00<00:00, 5359.49it/s]\n",
      "count number token config_2 with BAAI/bge-small-en: 100%|██████████| 1000/1000 [00:00<00:00, 5311.04it/s]\n",
      "count number token config_2 with BAAI/bge-base-en: 100%|██████████| 1000/1000 [00:00<00:00, 5181.49it/s]\n",
      "count number token config_2 with BAAI/llm-embedder: 100%|██████████| 1000/1000 [00:00<00:00, 5346.88it/s]\n",
      "count number token config_2 with Snowflake/snowflake-arctic-embed-m: 100%|██████████| 1000/1000 [00:00<00:00, 5290.85it/s]\n",
      "count number token config_2 with Snowflake/snowflake-arctic-embed-m-v1.5: 100%|██████████| 1000/1000 [00:00<00:00, 5317.42it/s]\n",
      "count number token config_3 with intfloat/e5-small-v2: 100%|██████████| 1000/1000 [00:00<00:00, 3322.04it/s]\n",
      "count number token config_3 with intfloat/e5-base-v2: 100%|██████████| 1000/1000 [00:00<00:00, 3279.32it/s]\n",
      "count number token config_3 with sentence-transformers/all-MiniLM-L6-v2: 100%|██████████| 1000/1000 [00:00<00:00, 3303.05it/s]\n",
      "count number token config_3 with thenlper/gte-small: 100%|██████████| 1000/1000 [00:00<00:00, 3269.07it/s]\n",
      "count number token config_3 with thenlper/gte-base: 100%|██████████| 1000/1000 [00:00<00:00, 3299.51it/s]\n",
      "count number token config_3 with BAAI/bge-small-en: 100%|██████████| 1000/1000 [00:00<00:00, 3335.95it/s]\n",
      "count number token config_3 with BAAI/bge-base-en: 100%|██████████| 1000/1000 [00:00<00:00, 3321.77it/s]\n",
      "count number token config_3 with BAAI/llm-embedder: 100%|██████████| 1000/1000 [00:00<00:00, 2993.84it/s]\n",
      "count number token config_3 with Snowflake/snowflake-arctic-embed-m: 100%|██████████| 1000/1000 [00:00<00:00, 2557.00it/s]\n",
      "count number token config_3 with Snowflake/snowflake-arctic-embed-m-v1.5: 100%|██████████| 1000/1000 [00:00<00:00, 2666.53it/s]\n",
      "count number token config_4 with intfloat/e5-small-v2: 100%|██████████| 1000/1000 [00:00<00:00, 2373.51it/s]\n",
      "count number token config_4 with intfloat/e5-base-v2: 100%|██████████| 1000/1000 [00:00<00:00, 2715.88it/s]\n",
      "count number token config_4 with sentence-transformers/all-MiniLM-L6-v2: 100%|██████████| 1000/1000 [00:00<00:00, 2257.35it/s]\n",
      "count number token config_4 with thenlper/gte-small: 100%|██████████| 1000/1000 [00:00<00:00, 2710.05it/s]\n",
      "count number token config_4 with thenlper/gte-base: 100%|██████████| 1000/1000 [00:00<00:00, 2195.44it/s]\n",
      "count number token config_4 with BAAI/bge-small-en: 100%|██████████| 1000/1000 [00:00<00:00, 1641.29it/s]\n",
      "count number token config_4 with BAAI/bge-base-en: 100%|██████████| 1000/1000 [00:00<00:00, 1903.70it/s]\n",
      "count number token config_4 with BAAI/llm-embedder: 100%|██████████| 1000/1000 [00:00<00:00, 1884.48it/s]\n",
      "count number token config_4 with Snowflake/snowflake-arctic-embed-m: 100%|██████████| 1000/1000 [00:00<00:00, 1894.61it/s]\n",
      "count number token config_4 with Snowflake/snowflake-arctic-embed-m-v1.5: 100%|██████████| 1000/1000 [00:00<00:00, 1852.01it/s]\n",
      "count number token config_5 with intfloat/e5-small-v2: 100%|██████████| 1000/1000 [00:00<00:00, 5959.82it/s]\n",
      "count number token config_5 with intfloat/e5-base-v2: 100%|██████████| 1000/1000 [00:00<00:00, 5590.46it/s]\n",
      "count number token config_5 with sentence-transformers/all-MiniLM-L6-v2: 100%|██████████| 1000/1000 [00:00<00:00, 5751.86it/s]\n",
      "count number token config_5 with thenlper/gte-small: 100%|██████████| 1000/1000 [00:00<00:00, 6890.86it/s]\n",
      "count number token config_5 with thenlper/gte-base: 100%|██████████| 1000/1000 [00:00<00:00, 5695.43it/s]\n",
      "count number token config_5 with BAAI/bge-small-en: 100%|██████████| 1000/1000 [00:00<00:00, 5386.64it/s]\n",
      "count number token config_5 with BAAI/bge-base-en: 100%|██████████| 1000/1000 [00:00<00:00, 6844.57it/s]\n",
      "count number token config_5 with BAAI/llm-embedder: 100%|██████████| 1000/1000 [00:00<00:00, 5999.16it/s]\n",
      "count number token config_5 with Snowflake/snowflake-arctic-embed-m: 100%|██████████| 1000/1000 [00:00<00:00, 5647.81it/s]\n",
      "count number token config_5 with Snowflake/snowflake-arctic-embed-m-v1.5: 100%|██████████| 1000/1000 [00:00<00:00, 8097.10it/s]\n",
      "count number token config_6 with intfloat/e5-small-v2: 100%|██████████| 1000/1000 [00:00<00:00, 2631.22it/s]\n",
      "count number token config_6 with intfloat/e5-base-v2: 100%|██████████| 1000/1000 [00:00<00:00, 2403.17it/s]\n",
      "count number token config_6 with sentence-transformers/all-MiniLM-L6-v2: 100%|██████████| 1000/1000 [00:00<00:00, 2619.85it/s]\n",
      "count number token config_6 with thenlper/gte-small: 100%|██████████| 1000/1000 [00:00<00:00, 2656.28it/s]\n",
      "count number token config_6 with thenlper/gte-base: 100%|██████████| 1000/1000 [00:00<00:00, 2553.07it/s]\n",
      "count number token config_6 with BAAI/bge-small-en: 100%|██████████| 1000/1000 [00:00<00:00, 2687.35it/s]\n",
      "count number token config_6 with BAAI/bge-base-en: 100%|██████████| 1000/1000 [00:00<00:00, 3042.77it/s]\n",
      "count number token config_6 with BAAI/llm-embedder: 100%|██████████| 1000/1000 [00:00<00:00, 2534.01it/s]\n",
      "count number token config_6 with Snowflake/snowflake-arctic-embed-m: 100%|██████████| 1000/1000 [00:00<00:00, 2744.28it/s]\n",
      "count number token config_6 with Snowflake/snowflake-arctic-embed-m-v1.5: 100%|██████████| 1000/1000 [00:00<00:00, 2879.19it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "df_recipes_embedding = df_recipes_cleaned.copy()\n",
    "\n",
    "#count number of token for each config and model\n",
    "for col_name, cols_list in COLUMNS_TO_EMBEDDE.items():\n",
    "    for model_id, model in MODEL_DICT.items():\n",
    "\n",
    "        embedding_col = f\"{model_id}/{col_name}_EMB\"\n",
    "        tokens_col = f\"{embedding_col}_NUMBER_TOKEN\" \n",
    "\n",
    "        number_token = []\n",
    "        for text in tqdm(df_recipes_embedding[col_name], desc=f\"count number token {col_name} with {model_id}\"):\n",
    "            num_tokens = compute_token_size(text, model)\n",
    "            number_token.append(num_tokens)\n",
    "\n",
    "        df_recipes_embedding[f\"{embedding_col}_NUMBER_TOKEN\"] = number_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a45f22c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1000.000000\n",
       "mean      230.147000\n",
       "std       102.020829\n",
       "min        61.000000\n",
       "25%       158.000000\n",
       "50%       212.000000\n",
       "75%       280.250000\n",
       "max       737.000000\n",
       "Name: intfloat/e5-base-v2/config_1_EMB_NUMBER_TOKEN, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_recipes_embedding['intfloat/e5-base-v2/config_1_EMB_NUMBER_TOKEN'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a60a2cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_recipes_embedding[df_recipes_embedding['intfloat/e5-base-v2/config_1_EMB_NUMBER_TOKEN'] > 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea056e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (405 > 256). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'NAME_CLEAND':\n",
      "count    1000.000000\n",
      "mean       13.164000\n",
      "std         2.518223\n",
      "min         8.000000\n",
      "25%        11.000000\n",
      "50%        13.000000\n",
      "75%        15.000000\n",
      "max        23.000000\n",
      "Name: NAME_CLEAND_token_len, dtype: float64\n",
      "\n",
      "Column 'INGREDIENTS_CLEAND':\n",
      "count    1000.00000\n",
      "mean       37.18700\n",
      "std        13.40805\n",
      "min        10.00000\n",
      "25%        27.00000\n",
      "50%        36.00000\n",
      "75%        45.00000\n",
      "max        90.00000\n",
      "Name: INGREDIENTS_CLEAND_token_len, dtype: float64\n",
      "\n",
      "Column 'STEPS_CLEAND':\n",
      "count    1000.000000\n",
      "mean      128.052000\n",
      "std        79.443443\n",
      "min        12.000000\n",
      "25%        74.000000\n",
      "50%       110.000000\n",
      "75%       165.250000\n",
      "max       633.000000\n",
      "Name: STEPS_CLEAND_token_len, dtype: float64\n",
      "\n",
      "Column 'DESCRIPTION_CLEAND':\n",
      "count    1000.000000\n",
      "mean       51.744000\n",
      "std        41.617502\n",
      "min         8.000000\n",
      "25%        25.000000\n",
      "50%        41.000000\n",
      "75%        64.000000\n",
      "max       319.000000\n",
      "Name: DESCRIPTION_CLEAND_token_len, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "token_lengths = pd.DataFrame(index=df_recipes.index)\n",
    "\n",
    "for col in COLUMNS_TO_CLEAN:\n",
    "\n",
    "    token_lengths[col + \"_token_len\"] = df_recipes[col].fillna(\"\").astype(str).apply(lambda x: compute_token_size(x, model))\n",
    "\n",
    "for col in COLUMNS_TO_CLEAN:\n",
    "    print(f\"Column '{col}':\")\n",
    "    print(token_lengths[col + \"_token_len\"].describe())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2709cdd4",
   "metadata": {},
   "source": [
    "**define function to calculate embedding of a text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "352421f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_embedding(model: SentenceTransformer, texts: list[str]) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute normalized embeddings for a list of texts using the specified model.\n",
    "\n",
    "    Args:\n",
    "        model (SentenceTransformer): The pre-trained sentence transformer model to use.\n",
    "        texts (list[str]): A list of input texts to compute embeddings for.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: A tensor containing the normalized embeddings for the input texts.\n",
    "    \"\"\"\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Compute embeddings\n",
    "    embeddings = model.encode(texts, convert_to_tensor=True, device=device)\n",
    "    \n",
    "    # Normalize embeddings to unit length\n",
    "    normalized_embeddings = normalize(embeddings, p=2, dim=1)\n",
    "    \n",
    "    return normalized_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c033d70",
   "metadata": {},
   "source": [
    "**compute embedding for each config and model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d590e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding config_1 with intfloat/e5-small-v2: 100%|██████████| 1000/1000 [00:13<00:00, 74.97it/s]\n",
      "Embedding config_1 with intfloat/e5-base-v2: 100%|██████████| 1000/1000 [00:18<00:00, 53.89it/s]\n",
      "Embedding config_1 with sentence-transformers/all-MiniLM-L6-v2: 100%|██████████| 1000/1000 [00:06<00:00, 148.92it/s]\n",
      "Embedding config_1 with thenlper/gte-small: 100%|██████████| 1000/1000 [00:11<00:00, 85.95it/s]\n",
      "Embedding config_1 with thenlper/gte-base: 100%|██████████| 1000/1000 [00:18<00:00, 54.27it/s]\n",
      "Embedding config_1 with BAAI/bge-small-en: 100%|██████████| 1000/1000 [00:11<00:00, 86.39it/s]\n",
      "Embedding config_1 with BAAI/bge-base-en: 100%|██████████| 1000/1000 [00:18<00:00, 53.44it/s]\n",
      "Embedding config_1 with BAAI/llm-embedder: 100%|██████████| 1000/1000 [00:18<00:00, 54.38it/s]\n",
      "Embedding config_1 with Snowflake/snowflake-arctic-embed-m: 100%|██████████| 1000/1000 [00:18<00:00, 54.52it/s]\n",
      "Embedding config_1 with Snowflake/snowflake-arctic-embed-m-v1.5: 100%|██████████| 1000/1000 [00:18<00:00, 53.96it/s]\n",
      "Embedding config_2 with intfloat/e5-small-v2: 100%|██████████| 1000/1000 [00:10<00:00, 99.39it/s]\n",
      "Embedding config_2 with intfloat/e5-base-v2: 100%|██████████| 1000/1000 [00:12<00:00, 81.10it/s]\n",
      "Embedding config_2 with sentence-transformers/all-MiniLM-L6-v2: 100%|██████████| 1000/1000 [00:06<00:00, 156.28it/s]\n",
      "Embedding config_2 with thenlper/gte-small: 100%|██████████| 1000/1000 [00:10<00:00, 98.95it/s]\n",
      "Embedding config_2 with thenlper/gte-base: 100%|██████████| 1000/1000 [00:12<00:00, 81.30it/s]\n",
      "Embedding config_2 with BAAI/bge-small-en: 100%|██████████| 1000/1000 [00:10<00:00, 97.91it/s]\n",
      "Embedding config_2 with BAAI/bge-base-en: 100%|██████████| 1000/1000 [00:12<00:00, 82.72it/s]\n",
      "Embedding config_2 with BAAI/llm-embedder: 100%|██████████| 1000/1000 [00:12<00:00, 82.36it/s]\n",
      "Embedding config_2 with Snowflake/snowflake-arctic-embed-m: 100%|██████████| 1000/1000 [00:12<00:00, 82.46it/s]\n",
      "Embedding config_2 with Snowflake/snowflake-arctic-embed-m-v1.5: 100%|██████████| 1000/1000 [00:12<00:00, 82.50it/s]\n",
      "Embedding config_3 with intfloat/e5-small-v2: 100%|██████████| 1000/1000 [00:10<00:00, 91.66it/s]\n",
      "Embedding config_3 with intfloat/e5-base-v2: 100%|██████████| 1000/1000 [00:15<00:00, 63.20it/s]\n",
      "Embedding config_3 with sentence-transformers/all-MiniLM-L6-v2: 100%|██████████| 1000/1000 [00:06<00:00, 156.96it/s]\n",
      "Embedding config_3 with thenlper/gte-small: 100%|██████████| 1000/1000 [00:11<00:00, 89.99it/s]\n",
      "Embedding config_3 with thenlper/gte-base: 100%|██████████| 1000/1000 [00:16<00:00, 62.28it/s]\n",
      "Embedding config_3 with BAAI/bge-small-en: 100%|██████████| 1000/1000 [00:11<00:00, 90.91it/s]\n",
      "Embedding config_3 with BAAI/bge-base-en: 100%|██████████| 1000/1000 [00:16<00:00, 62.48it/s]\n",
      "Embedding config_3 with BAAI/llm-embedder: 100%|██████████| 1000/1000 [00:15<00:00, 62.69it/s]\n",
      "Embedding config_3 with Snowflake/snowflake-arctic-embed-m: 100%|██████████| 1000/1000 [00:15<00:00, 64.32it/s]\n",
      "Embedding config_3 with Snowflake/snowflake-arctic-embed-m-v1.5: 100%|██████████| 1000/1000 [00:15<00:00, 64.01it/s]\n",
      "Embedding config_4 with intfloat/e5-small-v2: 100%|██████████| 1000/1000 [00:10<00:00, 92.41it/s]\n",
      "Embedding config_4 with intfloat/e5-base-v2: 100%|██████████| 1000/1000 [00:16<00:00, 61.26it/s]\n",
      "Embedding config_4 with sentence-transformers/all-MiniLM-L6-v2: 100%|██████████| 1000/1000 [00:06<00:00, 155.42it/s]\n",
      "Embedding config_4 with thenlper/gte-small: 100%|██████████| 1000/1000 [00:10<00:00, 92.17it/s]\n",
      "Embedding config_4 with thenlper/gte-base: 100%|██████████| 1000/1000 [00:16<00:00, 61.33it/s]\n",
      "Embedding config_4 with BAAI/bge-small-en: 100%|██████████| 1000/1000 [00:10<00:00, 92.70it/s]\n",
      "Embedding config_4 with BAAI/bge-base-en: 100%|██████████| 1000/1000 [00:16<00:00, 61.38it/s]\n",
      "Embedding config_4 with BAAI/llm-embedder: 100%|██████████| 1000/1000 [00:16<00:00, 61.53it/s]\n",
      "Embedding config_4 with Snowflake/snowflake-arctic-embed-m: 100%|██████████| 1000/1000 [00:16<00:00, 61.18it/s]\n",
      "C:\\Users\\hamma\\AppData\\Local\\Temp\\ipykernel_18140\\293133030.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_recipes_embedding[embedding_col] = embeddings\n",
      "Embedding config_4 with Snowflake/snowflake-arctic-embed-m-v1.5: 100%|██████████| 1000/1000 [00:16<00:00, 60.38it/s]\n",
      "C:\\Users\\hamma\\AppData\\Local\\Temp\\ipykernel_18140\\293133030.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_recipes_embedding[embedding_col] = embeddings\n",
      "Embedding config_5 with intfloat/e5-small-v2: 100%|██████████| 1000/1000 [00:10<00:00, 98.37it/s]\n",
      "C:\\Users\\hamma\\AppData\\Local\\Temp\\ipykernel_18140\\293133030.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_recipes_embedding[embedding_col] = embeddings\n",
      "Embedding config_5 with intfloat/e5-base-v2: 100%|██████████| 1000/1000 [00:10<00:00, 99.17it/s]\n",
      "C:\\Users\\hamma\\AppData\\Local\\Temp\\ipykernel_18140\\293133030.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_recipes_embedding[embedding_col] = embeddings\n",
      "Embedding config_5 with sentence-transformers/all-MiniLM-L6-v2: 100%|██████████| 1000/1000 [00:06<00:00, 157.34it/s]\n",
      "C:\\Users\\hamma\\AppData\\Local\\Temp\\ipykernel_18140\\293133030.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_recipes_embedding[embedding_col] = embeddings\n",
      "Embedding config_5 with thenlper/gte-small: 100%|██████████| 1000/1000 [00:10<00:00, 98.45it/s]\n",
      "C:\\Users\\hamma\\AppData\\Local\\Temp\\ipykernel_18140\\293133030.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_recipes_embedding[embedding_col] = embeddings\n",
      "Embedding config_5 with thenlper/gte-base: 100%|██████████| 1000/1000 [00:10<00:00, 99.66it/s]\n",
      "C:\\Users\\hamma\\AppData\\Local\\Temp\\ipykernel_18140\\293133030.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_recipes_embedding[embedding_col] = embeddings\n",
      "Embedding config_5 with BAAI/bge-small-en: 100%|██████████| 1000/1000 [00:10<00:00, 99.56it/s]\n",
      "C:\\Users\\hamma\\AppData\\Local\\Temp\\ipykernel_18140\\293133030.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_recipes_embedding[embedding_col] = embeddings\n",
      "Embedding config_5 with BAAI/bge-base-en: 100%|██████████| 1000/1000 [00:10<00:00, 98.97it/s]\n",
      "C:\\Users\\hamma\\AppData\\Local\\Temp\\ipykernel_18140\\293133030.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_recipes_embedding[embedding_col] = embeddings\n",
      "Embedding config_5 with BAAI/llm-embedder: 100%|██████████| 1000/1000 [00:10<00:00, 99.89it/s]\n",
      "C:\\Users\\hamma\\AppData\\Local\\Temp\\ipykernel_18140\\293133030.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_recipes_embedding[embedding_col] = embeddings\n",
      "Embedding config_5 with Snowflake/snowflake-arctic-embed-m: 100%|██████████| 1000/1000 [00:09<00:00, 100.93it/s]\n",
      "C:\\Users\\hamma\\AppData\\Local\\Temp\\ipykernel_18140\\293133030.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_recipes_embedding[embedding_col] = embeddings\n",
      "Embedding config_5 with Snowflake/snowflake-arctic-embed-m-v1.5: 100%|██████████| 1000/1000 [00:10<00:00, 98.54it/s]\n",
      "C:\\Users\\hamma\\AppData\\Local\\Temp\\ipykernel_18140\\293133030.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_recipes_embedding[embedding_col] = embeddings\n",
      "Embedding config_6 with intfloat/e5-small-v2: 100%|██████████| 1000/1000 [00:10<00:00, 96.20it/s]\n",
      "C:\\Users\\hamma\\AppData\\Local\\Temp\\ipykernel_18140\\293133030.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_recipes_embedding[embedding_col] = embeddings\n",
      "Embedding config_6 with intfloat/e5-base-v2: 100%|██████████| 1000/1000 [00:13<00:00, 72.00it/s]\n",
      "C:\\Users\\hamma\\AppData\\Local\\Temp\\ipykernel_18140\\293133030.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_recipes_embedding[embedding_col] = embeddings\n",
      "Embedding config_6 with sentence-transformers/all-MiniLM-L6-v2: 100%|██████████| 1000/1000 [00:06<00:00, 154.20it/s]\n",
      "C:\\Users\\hamma\\AppData\\Local\\Temp\\ipykernel_18140\\293133030.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_recipes_embedding[embedding_col] = embeddings\n",
      "Embedding config_6 with thenlper/gte-small: 100%|██████████| 1000/1000 [00:10<00:00, 94.37it/s]\n",
      "C:\\Users\\hamma\\AppData\\Local\\Temp\\ipykernel_18140\\293133030.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_recipes_embedding[embedding_col] = embeddings\n",
      "Embedding config_6 with thenlper/gte-base: 100%|██████████| 1000/1000 [00:13<00:00, 71.92it/s]\n",
      "C:\\Users\\hamma\\AppData\\Local\\Temp\\ipykernel_18140\\293133030.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_recipes_embedding[embedding_col] = embeddings\n",
      "Embedding config_6 with BAAI/bge-small-en: 100%|██████████| 1000/1000 [00:10<00:00, 96.23it/s]\n",
      "C:\\Users\\hamma\\AppData\\Local\\Temp\\ipykernel_18140\\293133030.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_recipes_embedding[embedding_col] = embeddings\n",
      "Embedding config_6 with BAAI/bge-base-en: 100%|██████████| 1000/1000 [00:13<00:00, 71.96it/s]\n",
      "C:\\Users\\hamma\\AppData\\Local\\Temp\\ipykernel_18140\\293133030.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_recipes_embedding[embedding_col] = embeddings\n",
      "Embedding config_6 with BAAI/llm-embedder: 100%|██████████| 1000/1000 [00:13<00:00, 71.96it/s]\n",
      "C:\\Users\\hamma\\AppData\\Local\\Temp\\ipykernel_18140\\293133030.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_recipes_embedding[embedding_col] = embeddings\n",
      "Embedding config_6 with Snowflake/snowflake-arctic-embed-m: 100%|██████████| 1000/1000 [00:13<00:00, 72.75it/s]\n",
      "C:\\Users\\hamma\\AppData\\Local\\Temp\\ipykernel_18140\\293133030.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_recipes_embedding[embedding_col] = embeddings\n",
      "Embedding config_6 with Snowflake/snowflake-arctic-embed-m-v1.5: 100%|██████████| 1000/1000 [00:13<00:00, 72.39it/s]\n",
      "C:\\Users\\hamma\\AppData\\Local\\Temp\\ipykernel_18140\\293133030.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_recipes_embedding[embedding_col] = embeddings\n"
     ]
    }
   ],
   "source": [
    "# #create embedding cols \n",
    "from tqdm import tqdm  \n",
    "\n",
    "for col_name, cols_list in COLUMNS_TO_EMBEDDE.items():\n",
    "    for model_id, model in MODEL_DICT.items():\n",
    "\n",
    "        embedding_col = f\"{model_id}/{col_name}_EMB\"\n",
    "                \n",
    "        embeddings = []\n",
    "        for text in tqdm(df_recipes_embedding[col_name], desc=f\"Embedding {col_name} with {model_id}\"):\n",
    "            emb = compute_embedding(model, [text])[0].cpu().numpy()                         \n",
    "            embeddings.append(emb)\n",
    "        \n",
    "        # Save embeddings to new column\n",
    "        df_recipes_embedding[embedding_col] = embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e866787",
   "metadata": {},
   "source": [
    "**write the file of embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89217d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(OUTPUT_EMBEDDING_FOLDER, exist_ok=True)\n",
    "\n",
    "df_recipes_embedding.to_csv(OUTPUT_EMBEDDING_FILE, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
