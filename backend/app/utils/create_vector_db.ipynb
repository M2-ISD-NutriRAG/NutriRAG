{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "\n",
    "# We can also use Snowpark for our analyses!\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f14c9fc-eb80-433b-880c-8ab2f6615124",
   "metadata": {
    "language": "python",
    "name": "cell4"
   },
   "outputs": [],
   "source": [
    "! pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8475d409-bebb-4225-ad7c-ae913d76de39",
   "metadata": {
    "collapsed": false,
    "name": "cell2"
   },
   "source": [
    "**import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21bd6f9-b4f6-41ae-82c7-7f6c6becefe7",
   "metadata": {
    "language": "python",
    "name": "cell5"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from typing import Any, Dict, List, Optional\n",
    "import pandas as pd\n",
    "import json \n",
    "import numpy as np \n",
    "import re\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dff10df-9b84-4eb8-94d3-8e5ea203aa96",
   "metadata": {
    "collapsed": false,
    "name": "cell3"
   },
   "source": [
    "**extract call parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3323ae8b-5bae-489f-9b79-2b5deb41c450",
   "metadata": {
    "language": "python",
    "name": "cell19"
   },
   "outputs": [],
   "source": [
    "params = sys.argv\n",
    "\n",
    "source_table = params[0]\n",
    "output_table = params[1]\n",
    "id_column = params[2]\n",
    "columns_to_clean = params[3].split(',')\n",
    "embedding_model = params[4]\n",
    "\n",
    "print(\"sys.argv:\", sys.argv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b23baa-795f-4271-942b-bd7db3e8381a",
   "metadata": {
    "collapsed": false,
    "name": "cell6"
   },
   "source": [
    "**import the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a2a0f2-8987-45a5-94c8-3b99ed8e11df",
   "metadata": {
    "language": "python",
    "name": "cell7"
   },
   "outputs": [],
   "source": [
    "  # Example table\n",
    "columns = [id_column] + columns_to_clean\n",
    "\n",
    "initial_df = session.table(source_table).to_pandas()\n",
    "df_to_embed = initial_df[columns].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517fd2ca-a8fa-4bd5-ac63-b676e23f678e",
   "metadata": {
    "collapsed": false,
    "name": "cell8"
   },
   "source": [
    "**Clean the columns to embed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61a7f37-0659-40ea-ba88-caa1d4195bbb",
   "metadata": {
    "language": "python",
    "name": "cell9"
   },
   "outputs": [],
   "source": [
    "#define function to clean text before embedding\n",
    "\n",
    "def clean_columns_to_embed(text_to_clean: str, start_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Format text of the columns used for embedding and add a prefix to that text.\n",
    "\n",
    "    Args:\n",
    "        text_to_clean (str): The text to be cleaned and formatted.\n",
    "        start_text (str): The prefix to add to the cleaned text.\n",
    "\n",
    "    Returns:\n",
    "        str: Cleaned and formatted text in the format \"{start_text}: {cleaned_text}.\"\n",
    "             Returns empty string if input is None or empty.\n",
    "    \"\"\"\n",
    "\n",
    "    if text_to_clean is None or text_to_clean == \"\":\n",
    "        return \"\"\n",
    "\n",
    "    text = str(text_to_clean)\n",
    "\n",
    "    text = re.sub(r\"[\\[\\]'\\\"]\", \"\", text)\n",
    "\n",
    "    text = text.replace(\"|\", \",\")\n",
    "\n",
    "    text = text.lower()\n",
    "\n",
    "    text = re.sub(r\"[^a-z0-9 .,?!]+\", \"\", text)\n",
    "\n",
    "    text = re.sub(r\" +\", \" \", text)\n",
    "\n",
    "    text = re.sub(r\" ,\", \",\", text)\n",
    "\n",
    "    text = text.strip()\n",
    "\n",
    "    return f\"{start_text}: {text}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de027b7-ddf3-45a1-9df4-4ab74ffbe15c",
   "metadata": {
    "language": "python",
    "name": "cell10"
   },
   "outputs": [],
   "source": [
    "#cleant the dataframe and concat embedding columns\n",
    "\n",
    "cleaned_df = df_to_embed.copy()\n",
    "\n",
    "for col in columns_to_clean:\n",
    "        start_text = f\" recipe {col.lower()}\"\n",
    "        cleaned_df[col] = df_to_embed[col].apply(lambda text: clean_columns_to_embed(text, start_text))\n",
    "        \n",
    "cleaned_df[\"TEXT_TO_EMBED\"] = cleaned_df[columns_to_clean].agg(\" \".join, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add70eca-d58c-4e67-ac56-0f0f5f78e24c",
   "metadata": {
    "collapsed": false,
    "name": "cell11"
   },
   "source": [
    "**embed the columns TEXT_TO_EMBED**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b086b1d-162b-4f85-9ba9-22414f8f7b2e",
   "metadata": {
    "language": "python",
    "name": "cell12"
   },
   "outputs": [],
   "source": [
    "#load the model\n",
    "model = SentenceTransformer(\n",
    "                    embedding_model,\n",
    "                    trust_remote_code=True,\n",
    "                    device=\"cuda\",\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4ff88f-43f6-4b26-9680-1cba6def6644",
   "metadata": {
    "language": "python",
    "name": "cell13"
   },
   "outputs": [],
   "source": [
    "#define function to compute embeddings\n",
    "def compute_embedding_columns(\n",
    "    df: pd.DataFrame,\n",
    "    embedding_model: SentenceTransformer,\n",
    "    name_embedding_column_input: str,\n",
    "    name_embedding_column_output: str = \"EMBEDDING\",\n",
    "    batch_size: int = 128,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create an embedding column by computing embeddings batch by batch.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): dataframe containing the data\n",
    "        embedding_model (SentenceTransformer): model used to compute the embeddings\n",
    "        name_embedding_column_input (str): column used as input text\n",
    "        name_embedding_column_output (str): column to store embeddings\n",
    "        batch_size (int): batch size for embedding computation\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: dataframe with the new embedding column\n",
    "    \"\"\"\n",
    "\n",
    "    texts = df[name_embedding_column_input].tolist()\n",
    "    all_embeddings = []\n",
    "\n",
    "    # Use tqdm to show progress\n",
    "    for start_idx in tqdm(range(0, len(texts), batch_size), desc=\"Computing embeddings\"):\n",
    "        batch_texts = texts[start_idx : start_idx + batch_size]\n",
    "\n",
    "        batch_embeddings = embedding_model.encode(\n",
    "            batch_texts,\n",
    "            batch_size=batch_size,\n",
    "            show_progress_bar=False,  # tqdm will show progress instead\n",
    "            normalize_embeddings=True,\n",
    "            convert_to_numpy=True,\n",
    "        )\n",
    "\n",
    "        all_embeddings.extend(batch_embeddings)\n",
    "\n",
    "    # Convert embeddings to lists for Pandas/Snowflake\n",
    "    df[name_embedding_column_output] = [emb.tolist() for emb in all_embeddings]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c120d00a-b7fe-4db5-8938-4a2400d86ceb",
   "metadata": {
    "language": "python",
    "name": "cell14"
   },
   "outputs": [],
   "source": [
    "#compute embeddings\n",
    "cleaned_df_with_embedding = compute_embedding_columns(\n",
    "                cleaned_df,\n",
    "                model,\n",
    "                name_embedding_column_input=\"TEXT_TO_EMBED\",\n",
    "                name_embedding_column_output=\"EMBEDDING\",\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c4baac-9b52-4b79-a3d8-a8a0ae1c531e",
   "metadata": {
    "collapsed": false,
    "name": "cell15"
   },
   "source": [
    "**join with initial_df**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e84014-0b19-420c-8e8c-794d2f839ffc",
   "metadata": {
    "language": "python",
    "name": "cell16"
   },
   "outputs": [],
   "source": [
    "# join back the id column\n",
    "embedding_df = cleaned_df_with_embedding[\n",
    "    [id_column, \"TEXT_TO_EMBED\", \"EMBEDDING\"]\n",
    "].copy()\n",
    "\n",
    "\n",
    "final_df = initial_df.merge(\n",
    "    embedding_df[[id_column, \"TEXT_TO_EMBED\", \"EMBEDDING\"]], \n",
    "    on=id_column, \n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0810e7-5e61-4ed7-a092-f11248467110",
   "metadata": {
    "language": "python",
    "name": "cell22"
   },
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec62ed9-603e-41b2-a2e3-7b5193e2b60f",
   "metadata": {
    "language": "python",
    "name": "cell20"
   },
   "outputs": [],
   "source": [
    "final_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3c7329-6688-4f03-ac3f-2db879e50997",
   "metadata": {
    "language": "python",
    "name": "cell23"
   },
   "outputs": [],
   "source": [
    "# Create a copy of the dataframe\n",
    "df_for_snowflake = final_df.copy()\n",
    "\n",
    "# Function to check if a value looks like an array\n",
    "def is_array_like(val):\n",
    "    if isinstance(val, (list, np.ndarray)):\n",
    "        return True\n",
    "    if val is None:\n",
    "        return False\n",
    "    try:\n",
    "        if pd.isna(val):\n",
    "            return False\n",
    "    except (TypeError, ValueError):\n",
    "        return isinstance(val, (list, np.ndarray))\n",
    "    \n",
    "    if isinstance(val, str):\n",
    "        val_stripped = val.strip()\n",
    "        return val_stripped.startswith('[') and val_stripped.endswith(']')\n",
    "    return False\n",
    "\n",
    "# Function to convert to proper array format\n",
    "def convert_to_array(val):\n",
    "    if val is None:\n",
    "        return None\n",
    "    if isinstance(val, (list, np.ndarray)):\n",
    "        return list(val) if isinstance(val, np.ndarray) else val\n",
    "    try:\n",
    "        if pd.isna(val):\n",
    "            return None\n",
    "    except (TypeError, ValueError):\n",
    "        pass\n",
    "    \n",
    "    if isinstance(val, str):\n",
    "        try:\n",
    "            parsed = json.loads(val)\n",
    "            return parsed if isinstance(parsed, list) else None\n",
    "        except:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "# Get embedding dimension\n",
    "embedding_dim = None\n",
    "if 'EMBEDDING' in df_for_snowflake.columns:\n",
    "    for val in df_for_snowflake['EMBEDDING'].dropna().head(1):\n",
    "        try:\n",
    "            if isinstance(val, (list, np.ndarray)):\n",
    "                embedding_dim = len(val)\n",
    "            elif isinstance(val, str):\n",
    "                parsed = json.loads(val)\n",
    "                embedding_dim = len(parsed)\n",
    "            break\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "if embedding_dim:\n",
    "    print(f\"Detected EMBEDDING dimension: {embedding_dim}\")\n",
    "\n",
    "# Detect array columns\n",
    "array_columns = []\n",
    "for col in df_for_snowflake.columns:\n",
    "    if col == 'EMBEDDING':  # Skip EMBEDDING, handle it separately\n",
    "        continue\n",
    "        \n",
    "    sample_values = df_for_snowflake[col].head(10)\n",
    "    \n",
    "    if len(sample_values) > 0:\n",
    "        array_count = 0\n",
    "        valid_samples = 0\n",
    "        \n",
    "        for val in sample_values:\n",
    "            try:\n",
    "                if is_array_like(val):\n",
    "                    array_count += 1\n",
    "                valid_samples += 1\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        if valid_samples > 0 and array_count > valid_samples / 2:\n",
    "            print(f\"Detected '{col}' as ARRAY type\")\n",
    "            array_columns.append(col)\n",
    "            df_for_snowflake[col] = df_for_snowflake[col].apply(convert_to_array)\n",
    "\n",
    "# Convert EMBEDDING column\n",
    "if 'EMBEDDING' in df_for_snowflake.columns:\n",
    "    df_for_snowflake['EMBEDDING'] = df_for_snowflake['EMBEDDING'].apply(convert_to_array)\n",
    "\n",
    "# Build CREATE TABLE statement dynamically\n",
    "column_definitions = []\n",
    "for col in df_for_snowflake.columns:\n",
    "    col_upper = col.upper()\n",
    "    \n",
    "    if col == 'EMBEDDING' and embedding_dim:\n",
    "        col_type = f\"VECTOR(FLOAT, {embedding_dim})\"\n",
    "    elif col in array_columns:\n",
    "        col_type = \"ARRAY\"\n",
    "    elif df_for_snowflake[col].dtype == 'object':\n",
    "        col_type = \"VARCHAR(16777216)\"\n",
    "    elif df_for_snowflake[col].dtype in ['int8', 'int16', 'int32', 'int64']:\n",
    "        col_type = \"NUMBER(38,0)\"\n",
    "    elif df_for_snowflake[col].dtype in ['float32', 'float64']:\n",
    "        col_type = \"FLOAT\"\n",
    "    elif 'date' in str(df_for_snowflake[col].dtype).lower():\n",
    "        col_type = \"DATE\"\n",
    "    else:\n",
    "        col_type = \"VARCHAR(16777216)\"\n",
    "    \n",
    "    column_definitions.append(f\"{col_upper} {col_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d337a5-f5c9-4a72-906c-229d6a06c25d",
   "metadata": {
    "collapsed": false,
    "name": "cell17"
   },
   "source": [
    "**convert embedding to vector format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1173986-2462-4eca-b4db-5f7bfbd93869",
   "metadata": {
    "language": "python",
    "name": "cell21"
   },
   "outputs": [],
   "source": [
    "# Drop table if exists and create with proper schema\n",
    "session.sql(f\"DROP TABLE IF EXISTS {output_table}\").collect()\n",
    "\n",
    "create_table_sql = f\"\"\"\n",
    "CREATE TABLE {output_table} (\n",
    "    {', '.join(column_definitions)}\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nCreating table with schema:\")\n",
    "print(create_table_sql)\n",
    "\n",
    "session.sql(create_table_sql).collect()\n",
    "\n",
    "# Create a temporary table without VECTOR column\n",
    "temp_table = f\"{output_table}_TEMP\"\n",
    "df_temp = df_for_snowflake.drop(columns=['EMBEDDING'])\n",
    "\n",
    "snowpark_df_temp = session.create_dataframe(df_temp)\n",
    "snowpark_df_temp.write.mode(\"overwrite\").save_as_table(temp_table)\n",
    "\n",
    "# Insert data with VECTOR casting\n",
    "insert_sql = f\"\"\"\n",
    "INSERT INTO {output_table}\n",
    "SELECT \n",
    "    {', '.join([col.upper() if col != 'EMBEDDING' else f\"TO_VECTOR(EMBEDDING)::{embedding_dim}::VECTOR(FLOAT, {embedding_dim})\" for col in df_for_snowflake.columns])}\n",
    "FROM (\n",
    "    SELECT t.*, e.EMBEDDING\n",
    "    FROM {temp_table} t\n",
    "    JOIN (SELECT ROW_NUMBER() OVER (ORDER BY (SELECT NULL)) as rn, * FROM TABLE(FLATTEN(PARSE_JSON(?))))\n",
    ") \n",
    "\"\"\"\n",
    "\n",
    "# Alternative: Use simple column-by-column insert\n",
    "cols_without_embedding = [col.upper() for col in df_for_snowflake.columns if col != 'EMBEDDING']\n",
    "\n",
    "insert_sql = f\"\"\"\n",
    "INSERT INTO {output_table} ({', '.join([col.upper() for col in df_for_snowflake.columns])})\n",
    "SELECT {', '.join(cols_without_embedding)}, \n",
    "       {', '.join([col.upper() for col in df_for_snowflake.columns])}::VECTOR(FLOAT, {embedding_dim}) as EMBEDDING\n",
    "FROM {temp_table}\n",
    "\"\"\"\n",
    "\n",
    "# Simpler approach: Write all data to temp, then copy with casting\n",
    "session.sql(f\"DROP TABLE IF EXISTS {temp_table}\").collect()\n",
    "\n",
    "# Write full dataframe to temp table\n",
    "snowpark_df = session.create_dataframe(df_for_snowflake)\n",
    "snowpark_df.write.mode(\"overwrite\").save_as_table(temp_table)\n",
    "\n",
    "# Copy data with proper VECTOR casting\n",
    "all_cols = [col.upper() for col in df_for_snowflake.columns]\n",
    "select_cols = [f\"{col}::VECTOR(FLOAT, {embedding_dim})\" if col == 'EMBEDDING' else col for col in all_cols]\n",
    "\n",
    "insert_sql = f\"\"\"\n",
    "INSERT INTO {output_table}\n",
    "SELECT {', '.join(select_cols)}\n",
    "FROM {temp_table}\n",
    "\"\"\"\n",
    "\n",
    "print(f\"\\nInserting data with VECTOR casting...\")\n",
    "session.sql(insert_sql).collect()\n",
    "\n",
    "# Clean up temp table\n",
    "session.sql(f\"DROP TABLE IF EXISTS {temp_table}\").collect()\n",
    "\n",
    "print(f\"\\nTable {output_table} created successfully!\")\n",
    "\n",
    "# Show the schema to verify\n",
    "print(\"\\nTable Schema:\")\n",
    "session.sql(f\"DESCRIBE TABLE {output_table}\").show()\n",
    "\n",
    "# Verify row count\n",
    "result = session.sql(f\"SELECT COUNT(*) as row_count FROM {output_table}\").collect()\n",
    "print(f\"\\nRows inserted: {result[0]['ROW_COUNT']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "authorEmail": "",
   "authorId": "409455501850",
   "authorName": "CATFISH",
   "lastEditTime": 1768038146637,
   "notebookId": "ijjkhle6xmdr3f43f3xm",
   "sessionId": "426536d5-6721-43bd-b844-f2eab67fa33e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
