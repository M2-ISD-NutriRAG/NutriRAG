{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26905175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import snowflake.connector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306de016",
   "metadata": {},
   "source": [
    "**define connexion parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2eb4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import re\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "user = os.getenv(\"USER\")\n",
    "password = os.getenv(\"PASSWORD\")\n",
    "passcode = os.getenv(\"PASSCODE\")\n",
    "account = os.getenv(\"ACCOUNT\")\n",
    "warehouse = os.getenv(\"WAREHOUSE\") \n",
    "database = os.getenv(\"DATABASE\")\n",
    "schema = os.getenv(\"SCHEMA\")\n",
    "table = os.getenv(\"TABLE\")\n",
    "\n",
    "print(user, re.sub(r'.', '*', password), passcode, account, warehouse, database, schema, table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a8cfd0",
   "metadata": {},
   "source": [
    "**get the data from snowflake**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df812b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = snowflake.connector.connect(\n",
    "    user = user,\n",
    "    password = password,\n",
    "    passcode = passcode,\n",
    "    account = account,\n",
    "    warehouse = warehouse,\n",
    "    database = database,\n",
    "    schema = schema\n",
    ")\n",
    "\n",
    "df = pd.read_sql(f\"SELECT * FROM {table}\", conn)\n",
    "    \n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba17005",
   "metadata": {},
   "source": [
    "**open the config file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aced527",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_FILE_PATH = os.getenv(\"CONFIG_FILE_PATH\")\n",
    "\n",
    "with open(CONFIG_FILE_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86779950",
   "metadata": {},
   "source": [
    "**write the data locally**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909c502f",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_RECIPIES_FILE = config['input_recipies_file']\n",
    "\n",
    "df.to_csv(INPUT_RECIPIES_FILE, index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025cdd84",
   "metadata": {},
   "source": [
    "**read the data if already exist locally**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a630f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#or directly load the file if already exist\n",
    "df_recipes = pd.read_csv(INPUT_RECIPIES_FILE)\n",
    "df_recipes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207db5aa",
   "metadata": {},
   "source": [
    "**define a function that clean the columns used for embedding** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641a1358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_columns_to_embedd(tag_value: any, col_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Format text of the columns used for embedding\n",
    "\n",
    "    Args:\n",
    "        tag_value (any): The input value to clean. Can be a string, list, number, or None.\n",
    "                        Will be converted to string before processing.\n",
    "        col_name (str): The label/prefix to add before the cleaned text \n",
    "                       (e.g., \"NAME\", \"TAGS\", \"INGREDIENTS\").\n",
    "    \n",
    "    Returns:\n",
    "        str: Cleaned and formatted text in the format \"{col_name}: {cleaned_text}.\"\n",
    "             Returns empty string if input is None or empty.\n",
    "    \"\"\"\n",
    "    \n",
    "    if tag_value is None or tag_value == \"\":\n",
    "        return \"\"\n",
    "    \n",
    "    text = str(tag_value)\n",
    "    \n",
    "    # Remove list brackets and quotes\n",
    "    text = re.sub(r\"[\\[\\]'\\\"]\", \"\", text)\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Keep only alphanumeric, spaces, and . , ? !\n",
    "    text = re.sub(r\"[^a-z0-9 .,?!]+\", \"\", text)\n",
    "    \n",
    "    # Remove excess spaces\n",
    "    text = re.sub(r\" +\", \" \", text)\n",
    "    \n",
    "    # Clean up spaces around punctuation\n",
    "    text = text.strip()\n",
    "    \n",
    "    # Return formatted text\n",
    "    return f\"{col_name}: {text}.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3e7430",
   "metadata": {},
   "source": [
    "**extract only required columns for embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7b0933",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract only required columns for embedding\n",
    "COLUMNS_TO_CLEAN = config[\"columns_to_clean\"]\n",
    "\n",
    "for col in COLUMNS_TO_CLEAN:\n",
    "    col_clean_name = COLUMNS_TO_CLEAN[col]['column_name']\n",
    "    start_text = COLUMNS_TO_CLEAN[col]['start_text']\n",
    "\n",
    "    df_recipes[col_clean_name] = df_recipes[col].apply(clean_columns_to_embedd, args=(start_text, ))\n",
    "\n",
    "df_recipes_cleaned = df_recipes[ [col['column_name'] for col in COLUMNS_TO_CLEAN.values()] ]\n",
    "\n",
    "#add the id to keep track of the recepies\n",
    "df_recipes_cleaned['ID'] = df_recipes['ID'] \n",
    "df_recipes_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdcdc5c",
   "metadata": {},
   "source": [
    "**create a column for each combinaison of embedding columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9581dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize a columns for each configuration of columns to embedd\n",
    "COLUMNS_TO_EMBEDDE = config[\"columns_embedding\"]\n",
    "\n",
    "for col_config_name, cols_list in COLUMNS_TO_EMBEDDE.items():\n",
    "    df_recipes_cleaned[col_config_name] = \"\"\n",
    "\n",
    "    for col in cols_list:\n",
    "        column_name_cleaned = COLUMNS_TO_CLEAN[col]['column_name']\n",
    "        df_recipes_cleaned[col_config_name] += df_recipes_cleaned[f\"{column_name_cleaned}\"] + \" \"\n",
    "        \n",
    "df_recipes_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4071057",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "df_recipes_cleaned['config_1'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb199cb",
   "metadata": {},
   "source": [
    "**load the embedding models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12ed388",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the models\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from torch.nn.functional import normalize\n",
    "\n",
    "MODELS_CONFIG = config[\"models\"]\n",
    "\n",
    "#create a dict {name model : model} \n",
    "MODELS_LIST = [SentenceTransformer(model_id) for model_id in MODELS_CONFIG]\n",
    "MODEL_DICT = dict(zip(MODELS_CONFIG, MODELS_LIST))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae4614f",
   "metadata": {},
   "source": [
    "**define a function that count number of token for each config and model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b50a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_token_size(text: str, model: SentenceTransformer) -> int:\n",
    "    \"\"\"\n",
    "    Compute the number of tokens in the given text using the specified SentenceTransformer model.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to tokenize.\n",
    "        model (SentenceTransformer): The SentenceTransformer model used for tokenization.\n",
    "\n",
    "    Returns:\n",
    "        int: The number of tokens in the input text.\n",
    "    \"\"\"\n",
    "\n",
    "    tokens = model.tokenizer.tokenize(text)\n",
    "    \n",
    "    return len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13513d8",
   "metadata": {},
   "source": [
    "**set the experience id**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626996ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIENCE_ID = config[\"experiments_specifique_params\"][\"experiment_id\"]\n",
    "\n",
    "print(EXPERIENCE_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df253a48",
   "metadata": {},
   "source": [
    "**set folder and file path for embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5e0e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_EMBEDDING_FOLDER = config[\"output_embedding_dir\"].format(\n",
    "    experiment_id=EXPERIENCE_ID\n",
    ")\n",
    "\n",
    "os.makedirs(OUTPUT_EMBEDDING_FOLDER, exist_ok=True)\n",
    "\n",
    "OUTPUT_EMBEDDING_FILE = config[\"output_recipies_embedding_file\"].format(\n",
    "    experiment_id=EXPERIENCE_ID\n",
    ")\n",
    "\n",
    "print(OUTPUT_EMBEDDING_FOLDER)\n",
    "print(OUTPUT_EMBEDDING_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486bae45",
   "metadata": {},
   "source": [
    "**calculate number of token per recipie for each config and model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed981cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "df_recipes_embedding = df_recipes_cleaned.copy()\n",
    "\n",
    "#count number of token for each config and model\n",
    "for col_name, cols_list in COLUMNS_TO_EMBEDDE.items():\n",
    "    for model_id, model in MODEL_DICT.items():\n",
    "\n",
    "        embedding_col = f\"{model_id}/{col_name}_EMB\"\n",
    "        tokens_col = f\"{embedding_col}_NUMBER_TOKEN\" \n",
    "\n",
    "        number_token = []\n",
    "        for text in tqdm(df_recipes_embedding[col_name], desc=f\"count number token {col_name} with {model_id}\"):\n",
    "            num_tokens = compute_token_size(text, model)\n",
    "            number_token.append(num_tokens)\n",
    "\n",
    "        df_recipes_embedding[f\"{embedding_col}_NUMBER_TOKEN\"] = number_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45f22c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recipes_embedding['intfloat/e5-base-v2/config_1_EMB_NUMBER_TOKEN'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60a2cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_recipes_embedding[df_recipes_embedding['intfloat/e5-base-v2/config_1_EMB_NUMBER_TOKEN'] > 512])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2709cdd4",
   "metadata": {},
   "source": [
    "**define function to calculate embedding of a text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352421f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embedding(model: SentenceTransformer, texts: list[str]) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute normalized embeddings for a list of texts using the specified model.\n",
    "\n",
    "    Args:\n",
    "        model (SentenceTransformer): The pre-trained sentence transformer model to use.\n",
    "        texts (list[str]): A list of input texts to compute embeddings for.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: A tensor containing the normalized embeddings for the input texts.\n",
    "    \"\"\"\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Compute embeddings\n",
    "    embeddings = model.encode(texts, convert_to_tensor=True)\n",
    "    \n",
    "    # Normalize embeddings to unit length\n",
    "    normalized_embeddings = normalize(embeddings, p=2, dim=1)\n",
    "    \n",
    "    return normalized_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c033d70",
   "metadata": {},
   "source": [
    "**compute embedding for each config and model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d590e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #create embedding cols \n",
    "from tqdm import tqdm  \n",
    "\n",
    "for col_name, cols_list in COLUMNS_TO_EMBEDDE.items():\n",
    "    for model_id, model in MODEL_DICT.items():\n",
    "\n",
    "        embedding_col = f\"{model_id}/{col_name}_EMB\"\n",
    "                \n",
    "        embeddings = []\n",
    "        for text in tqdm(df_recipes_embedding[col_name], desc=f\"Embedding {col_name} with {model_id}\"):\n",
    "            emb = compute_embedding(model, [text])[0].cpu().numpy()                         \n",
    "            embeddings.append(emb)\n",
    "        \n",
    "        # Save embeddings to new column\n",
    "        df_recipes_embedding[embedding_col] = embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e866787",
   "metadata": {},
   "source": [
    "**write the file of embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89217d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(OUTPUT_EMBEDDING_FOLDER, exist_ok=True)\n",
    "\n",
    "df_recipes_embedding.to_csv(OUTPUT_EMBEDDING_FILE, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
