{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96029620",
   "metadata": {},
   "source": [
    "# Imports and utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1ef47b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb8b4279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from shared.snowflake.client import SnowflakeClient\n",
    "\n",
    "sf_client = SnowflakeClient()\n",
    "session = sf_client.get_snowpark_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02a4607",
   "metadata": {},
   "source": [
    "# Main code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ed9af5",
   "metadata": {},
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6ed62e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients = [\n",
    "    \"crabmeat\",\n",
    "    \"cream cheese\",\n",
    "    \"green onions\",\n",
    "    \"garlic salt\",\n",
    "    \"refrigerated crescent dinner rolls\",\n",
    "    \"egg yolk\",\n",
    "    \"water\",\n",
    "    \"sesame seeds\",\n",
    "    \"sweet and sour sauce\",\n",
    "]\n",
    "steps = [\n",
    "    \"heat over to 375 degrees\",\n",
    "    \"spray large cookie sheet with non-stick cooking spray\",\n",
    "    \"in small bowl , combine crabmeat , cream cheese , onions and garlic salt and mix well\",\n",
    "    \"unroll both cans of dough\",\n",
    "    \"separate into 16 triangles\",\n",
    "    \"cut each triangle in half lengthwise to make 32 triangles\",\n",
    "    \"place 1 teaspoon crab mixture on center of each triangle about 1 inch from short side of triangle\",\n",
    "    \"fold short ends of each triangle over filling\",\n",
    "    \"pinch sides to seal\",\n",
    "    \"roll up\",\n",
    "    \"place on sprayed cookie sheet\",\n",
    "    \"in small bowl , combine egg yolk and water and mix well\",\n",
    "    \"brush egg mixture over snacks\",\n",
    "    \"sprinkle with sesame seed\",\n",
    "    \"bake at 375 degrees for 15 to 20 minutes or until golden brown\",\n",
    "    \"serve warn snacks with sweet-and-sour sauce\",\n",
    "]\n",
    "\n",
    "recipe = {\n",
    "    \"id\": 94947,\n",
    "    \"name\": \"crab filled crescent snacks\",\n",
    "    \"serving_size\": 1,\n",
    "    \"servings\": 4,\n",
    "    \"ingredients\": ingredients,\n",
    "    \"quantity_ingredients\": [\"1\"] * len(ingredients),\n",
    "    \"minutes\": 70.0,\n",
    "    \"steps\": steps,\n",
    "    \"health_score\": 57,\n",
    "}\n",
    "\n",
    "ingredients_to_remove = [\"cream cheese\"]\n",
    "\n",
    "constraints = {\n",
    "    \"transformation\": 2,\n",
    "    \"no_lactose\": False,\n",
    "    \"no_gluten\": False,\n",
    "    \"no_nuts\": False,\n",
    "    \"vegetarian\": False,\n",
    "    \"vegan\": False,\n",
    "    \"increase_protein\": False,\n",
    "    \"decrease_sugar\": False,\n",
    "    \"decrease_protein\": False,\n",
    "    \"decrease_carbs\": False,\n",
    "    \"decrease_calories\": False,\n",
    "    \"decrease_sodium\": False,\n",
    "}\n",
    "\n",
    "request = {\n",
    "    \"recipe\": recipe,\n",
    "    \"ingredients_to_remove\": ingredients_to_remove,\n",
    "    \"constraints\": constraints,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20a8277",
   "metadata": {},
   "source": [
    "## Design code and execute it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d960083",
   "metadata": {},
   "source": [
    "### Python file definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f5a9c90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################\n",
    "\n",
    "#                                        Transform service interface\n",
    "\n",
    "################################################################################################################\n",
    "import json\n",
    "import traceback\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import threading\n",
    "import logging\n",
    "\n",
    "from enum import Enum\n",
    "from typing import Optional, List, Dict, Any, Tuple\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from snowflake.snowpark.functions import col, lower, trim, row_number\n",
    "from snowflake.snowpark.window import Window\n",
    "from snowflake.snowpark import Session\n",
    "\n",
    "\n",
    "class TransformationType(Enum):\n",
    "    ADD = 0\n",
    "    DELETE = 1\n",
    "    SUBSTITUTION = 2\n",
    "\n",
    "\n",
    "class TransformConstraints(BaseModel):\n",
    "    # Constraints for recipe transformation\n",
    "    transformation: TransformationType\n",
    "    no_lactose: bool = False\n",
    "    no_gluten: bool = False\n",
    "    no_nuts: bool = False\n",
    "    vegetarian: bool = False\n",
    "    vegan: bool = False\n",
    "    increase_protein: bool = False\n",
    "    decrease_sugar: bool = False\n",
    "    decrease_protein: bool = False\n",
    "    decrease_carbs: bool = False\n",
    "    decrease_calories: bool = False\n",
    "    decrease_sodium: bool = False\n",
    "    decrease_satfat: bool = False\n",
    "\n",
    "\n",
    "class Recipe(BaseModel):\n",
    "    id: int\n",
    "    name: str\n",
    "    serving_size: float\n",
    "    servings: float\n",
    "    health_score: float\n",
    "    ingredients: List[str]\n",
    "    quantity_ingredients: List[str]\n",
    "    minutes: float\n",
    "    steps: List[str]\n",
    "\n",
    "\n",
    "class TransformRequest(BaseModel):\n",
    "    # Transform request body\n",
    "    recipe: Recipe\n",
    "    ingredients_to_remove: Optional[List[str]] = None\n",
    "    constraints: Optional[TransformConstraints] = None\n",
    "\n",
    "\n",
    "class Substitution(BaseModel):\n",
    "    # Single ingredient substitution\n",
    "    original_ingredient: str\n",
    "    substitute_ingredient: str\n",
    "    original_quantity: Optional[float] = None\n",
    "    substitute_quantity: Optional[float] = None\n",
    "    reason: str = \"\"\n",
    "\n",
    "\n",
    "class NutritionDelta(BaseModel):\n",
    "    # Changes in nutrition values\n",
    "    calories: float = 0.0\n",
    "    protein_g: float = 0.0\n",
    "    saturated_fats_g: float = 0.0\n",
    "    fat_g: float = 0.0\n",
    "    carb_g: float = 0.0\n",
    "    fiber_g: float = 0.0\n",
    "    sodium_mg: float = 0.0\n",
    "    sugar_g: float = 0.0\n",
    "    iron_mg: float = 0.0\n",
    "    calcium_mg: float = 0.0\n",
    "    magnesium_mg: float = 0.0\n",
    "    potassium_mg: float = 0.0\n",
    "    vitamin_c_mg: float = 0.0\n",
    "    health_score: float = 0.0\n",
    "\n",
    "\n",
    "class TransformResponse(BaseModel):\n",
    "    # Transform response\n",
    "    recipe: Recipe\n",
    "    original_name: str\n",
    "    transformed_name: str\n",
    "    substitutions: Optional[List[Substitution]] = None\n",
    "    nutrition_before: Optional[NutritionDelta] = None\n",
    "    nutrition_after: Optional[NutritionDelta] = None\n",
    "    success: bool = True\n",
    "    message: Optional[str] = None\n",
    "\n",
    "\n",
    "################################################################################################################\n",
    "\n",
    "#                                               Utilitaires\n",
    "\n",
    "################################################################################################################\n",
    "\n",
    "\n",
    "def parse_procedure_result(query_result, proc_name) -> Any:\n",
    "    \"\"\"\n",
    "    Parse a procedure result parsed with query result to be usable.\n",
    "    Args:\n",
    "        query_result: query result parsed\n",
    "        proc_name: procedure name\n",
    "\n",
    "    Returns:\n",
    "        output: Any\n",
    "    \"\"\"\n",
    "    value = query_result[0][proc_name]\n",
    "    output = json.loads(value)\n",
    "    return output\n",
    "\n",
    "\n",
    "def parse_query_result(query_result) -> List[Dict[str, float]]:\n",
    "    \"\"\"\n",
    "    Collect query result and return as dict list\n",
    "    Args:\n",
    "        query_result : result of a query call (session.sql(query))\n",
    "\n",
    "    Returns:\n",
    "        List[Dict[str, float]]: formatted output\n",
    "    \"\"\"\n",
    "    collected_result = query_result.collect()\n",
    "    return [row.as_dict() for row in collected_result]\n",
    "\n",
    "\n",
    "def format_output(input: Any) -> str:\n",
    "    \"\"\"\n",
    "    Dumps output in json format to be usable.\n",
    "    Args:\n",
    "        input: Any type of data\n",
    "    Returns:\n",
    "        str: json result of the formatted output\n",
    "    \"\"\"\n",
    "    # Convertir les Decimal en float pour la sérialisation JSON\n",
    "    if (\n",
    "        isinstance(input, list)\n",
    "        and len(input) > 0\n",
    "        and isinstance(input[0], dict)\n",
    "    ):\n",
    "        from decimal import Decimal\n",
    "\n",
    "        for item in input:\n",
    "            for key, value in item.items():\n",
    "                if isinstance(value, Decimal):\n",
    "                    item[key] = float(value)\n",
    "\n",
    "    # Retourner en JSON\n",
    "    return json.dumps(input, indent=2)\n",
    "\n",
    "\n",
    "def to_dict(obj):\n",
    "    \"\"\"Recursively convert an object and its nested objects to dictionaries\"\"\"\n",
    "    if isinstance(obj, (str, int, float, bool, type(None))):\n",
    "        return obj\n",
    "    elif isinstance(obj, list):\n",
    "        return [to_dict(item) for item in obj]\n",
    "    elif isinstance(obj, dict):\n",
    "        return {key: to_dict(value) for key, value in obj.items()}\n",
    "    elif hasattr(obj, \"__dict__\"):\n",
    "        return {key: to_dict(value) for key, value in vars(obj).items()}\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "\n",
    "################################################################################################################\n",
    "\n",
    "#                                        Transform service logic\n",
    "\n",
    "################################################################################################################\n",
    "\n",
    "\n",
    "NUTRIENT_BASIS_GRAMS = 100\n",
    "NUTRITION_COLS = [\n",
    "    \"ENERGY_KCAL\",\n",
    "    \"PROTEIN_G\",\n",
    "    \"FAT_G\",\n",
    "    \"SATURATED_FATS_G\",\n",
    "    \"CARB_G\",\n",
    "    \"FIBER_G\",\n",
    "    \"SUGAR_G\",\n",
    "    \"SODIUM_MG\",\n",
    "    \"CALCIUM_MG\",\n",
    "    \"IRON_MG\",\n",
    "    \"MAGNESIUM_MG\",\n",
    "    \"POTASSIUM_MG\",\n",
    "    \"VITC_MG\",\n",
    "]\n",
    "INGREDIENTS_QUANTITY_TABLE_NAME = \"NUTRIRAG_PROJECT.RAW.INGREDIENTS_QUANTITY\"\n",
    "INGREDIENTS_CLUSTERING_TABLE_NAME = \"NUTRIRAG_PROJECT.ENRICHED.INGREDIENTS\"\n",
    "INGREDIENTS_MATCHED_TABLE_NAME = \"NUTRIRAG_PROJECT.RAW.INGREDIENTS_MATCHING\"\n",
    "INGREDIENTS_NUTRIMENTS_TABLE_NAME = \"NUTRIRAG_PROJECT.RAW.CLEANED_INGREDIENTS\"\n",
    "INGREDIENTS_TAGGED_TABLE_NAME = \"NUTRIRAG_PROJECT.CLEANED.INGREDIENTS_TAGGED\"\n",
    "\n",
    "\n",
    "class TransformService:\n",
    "    _pca_data_cache = None\n",
    "    _pca_lock = threading.Lock()\n",
    "\n",
    "    # check if async necessary for the constructor\n",
    "    def __init__(self, session: Optional[Session] = None):\n",
    "        self.session = session\n",
    "        self.matched_ingredients_cache: Dict[str, Optional[Dict]] = {}\n",
    "        self.recipe_qty_cache: Dict[str, List[Tuple[str, Optional[float]]]] = {}\n",
    "        self.recipe_nutrition_cache: Dict[\n",
    "            str, Dict[str, Optional[Dict[str, Any]]]\n",
    "        ] = {}\n",
    "        self.pca_data = None  # ingredient coordinates for clustering\n",
    "        # self.load_pca_data()\n",
    "        self.recipe_tags_cache: Dict[\n",
    "            str, Dict[str, Optional[Dict[str, Any]]]\n",
    "        ] = {}\n",
    "\n",
    "    def _zero_nutrition(self) -> NutritionDelta:\n",
    "        return NutritionDelta(\n",
    "            calories=0.0,\n",
    "            protein_g=0.0,\n",
    "            fat_g=0.0,\n",
    "            saturated_fats_g=0.0,\n",
    "            carb_g=0.0,\n",
    "            fiber_g=0.0,\n",
    "            sugar_g=0.0,\n",
    "            sodium_mg=0.0,\n",
    "            calcium_mg=0.0,\n",
    "            iron_mg=0.0,\n",
    "            magnesium_mg=0.0,\n",
    "            potassium_mg=0.0,\n",
    "            vitamin_c_mg=0.0,\n",
    "            health_score=0.0,\n",
    "        )\n",
    "\n",
    "    def clean_ingredient_name(self, ingredient_name: str) -> str:\n",
    "        return ingredient_name.lower().strip().replace(\"'\", \"''\")\n",
    "\n",
    "    def get_ingredient_matched(\n",
    "        self, ingredient_name_list: List[str]\n",
    "    ) -> List[Optional[Dict]]:\n",
    "        \"\"\"\n",
    "        Récupère les informations nutritionnelles d'un seul ingrédient depuis la base\n",
    "\n",
    "        Args:\n",
    "            ingredient_name: Nom de l'ingrédient à chercher\n",
    "\n",
    "        Returns:\n",
    "            Dict avec les infos nutritionnelles ou None si pas trouvé\n",
    "        \"\"\"\n",
    "        ingredient_clean_name_list = list(\n",
    "            map(self.clean_ingredient_name, ingredient_name_list)\n",
    "        )\n",
    "        ingredient_matched = []\n",
    "        ingredient_to_match = []\n",
    "        for i, ingr_name in enumerate(ingredient_clean_name_list):\n",
    "            if ingr_name in self.matched_ingredients_cache:\n",
    "                ingredient_matched.append(\n",
    "                    self.matched_ingredients_cache[ingr_name]\n",
    "                )\n",
    "            else:\n",
    "                ingredient_to_match.append(ingr_name)\n",
    "\n",
    "        if len(ingredient_to_match) > 0:\n",
    "            # Build the WHERE conditions for each ingredient\n",
    "            conditions = []\n",
    "            for safe_ingredient in ingredient_to_match:\n",
    "                condition = f\"\"\"(LOWER(ci.\"DESCRIP\") LIKE '%{safe_ingredient.lower()}%'\n",
    "                    OR LOWER(im.\"INGREDIENT_FROM_RECIPE_NAME\") LIKE '%{safe_ingredient.lower()}%')\"\"\"\n",
    "                conditions.append(condition)\n",
    "\n",
    "            # Join conditions with OR\n",
    "            where_clause = \" OR \".join(conditions)\n",
    "\n",
    "            query = f\"\"\"\n",
    "            SELECT DISTINCT\n",
    "                \"DESCRIP\",\n",
    "                \"PROTEIN_G\",\n",
    "                \"SATURATED_FATS_G\",\n",
    "                \"FAT_G\",\n",
    "                \"CARB_G\",\n",
    "                \"SODIUM_MG\",\n",
    "                \"FIBER_G\",\n",
    "                \"SUGAR_G\",\n",
    "                \"ENERGY_KCAL\",\n",
    "                \"INGREDIENT_FROM_RECIPE_NAME\" as matched_ingredient\n",
    "            FROM (\n",
    "                SELECT\n",
    "                    ci.\"DESCRIP\",\n",
    "                    ci.\"PROTEIN_G\",\n",
    "                    ci.\"SATURATED_FATS_G\",\n",
    "                    ci.\"FAT_G\",\n",
    "                    ci.\"CARB_G\",\n",
    "                    ci.\"SODIUM_MG\",\n",
    "                    ci.\"FIBER_G\",\n",
    "                    ci.\"SUGAR_G\",\n",
    "                    ci.\"ENERGY_KCAL\",\n",
    "                    ci.\"NDB_NO\",\n",
    "                    im.\"INGREDIENT_FROM_RECIPE_NAME\"\n",
    "                FROM {INGREDIENTS_NUTRIMENTS_TABLE_NAME} ci\n",
    "                FULL OUTER JOIN {INGREDIENTS_MATCHED_TABLE_NAME} im\n",
    "                    ON im.\"INGREDIENT_ID\" = ci.\"NDB_NO\"\n",
    "                WHERE\n",
    "                            {where_clause}\n",
    "            ) AS result\n",
    "            \"\"\"\n",
    "\n",
    "            result_sql = self.session.sql(query)\n",
    "            result = parse_query_result(result_sql)\n",
    "\n",
    "            if result:\n",
    "                for ingredient_key in ingredient_to_match:\n",
    "                    # Prendre le meilleur match (correspondance exacte prioritaire)\n",
    "                    best_match = None\n",
    "                    exact_match = None\n",
    "\n",
    "                    for row in result:\n",
    "                        matched_ingredient = row[\"MATCHED_INGREDIENT\"]\n",
    "                        descrip = row[\"DESCRIP\"]\n",
    "\n",
    "                        # Utiliser safe_float pour toutes les conversions\n",
    "                        nutrition_data = {\n",
    "                            \"name\": descrip,\n",
    "                            \"matched_ingredient\": matched_ingredient,\n",
    "                            \"protein\": float(row[\"PROTEIN_G\"]),\n",
    "                            \"saturated_fats\": float(row[\"SATURATED_FATS_G\"]),\n",
    "                            \"fat\": float(row[\"FAT_G\"]),\n",
    "                            \"carbs\": float(row[\"CARB_G\"]),\n",
    "                            \"sodium\": float(row[\"SODIUM_MG\"]),\n",
    "                            \"fiber\": float(row[\"FIBER_G\"]),\n",
    "                            \"sugar\": float(row[\"SUGAR_G\"]),\n",
    "                            \"calories\": float(row[\"ENERGY_KCAL\"]),\n",
    "                        }\n",
    "                        if matched_ingredient is not None:\n",
    "                            # Correspondance exacte avec l'ingrédient matché\n",
    "                            if matched_ingredient == ingredient_key:\n",
    "                                exact_match = nutrition_data\n",
    "                                break\n",
    "                            # Meilleur match partiel\n",
    "                            elif ingredient_key in matched_ingredient or any(\n",
    "                                word in matched_ingredient\n",
    "                                for word in ingredient_key.split()\n",
    "                            ):\n",
    "                                if best_match is None:\n",
    "                                    best_match = nutrition_data\n",
    "\n",
    "                    result_data = exact_match or best_match\n",
    "\n",
    "                    if result_data:\n",
    "                        # Mettre en cache\n",
    "                        self.matched_ingredients_cache[ingredient_key] = (\n",
    "                            result_data\n",
    "                        )\n",
    "                        ingredient_matched.append(result_data)\n",
    "                    else:\n",
    "                        # Pas trouvé - mettre en cache négatif\n",
    "                        self.matched_ingredients_cache[ingredient_key] = None\n",
    "                        ingredient_matched.append(None)\n",
    "            else:\n",
    "                logging.error(\n",
    "                    \"Failure: Getting matched ingredient query failed.\"\n",
    "                )\n",
    "\n",
    "        if None in ingredient_matched:\n",
    "            logging.warning(\n",
    "                \"Failure: Some ingredients doesn't have matched ingredient.\"\n",
    "            )\n",
    "        return ingredient_matched\n",
    "\n",
    "    def fetch_recipe_quantities(\n",
    "        self, recipe_id: str\n",
    "    ) -> Dict[str, Optional[float]]:\n",
    "        \"\"\"\n",
    "        Returns list of (ingredient_string, qty_g_or_none) from INGREDIENTS_QUANTITY.\n",
    "        Cached per recipe.\n",
    "        \"\"\"\n",
    "        if recipe_id in self.recipe_qty_cache:\n",
    "            return self.recipe_qty_cache[recipe_id]\n",
    "\n",
    "        sdf = (\n",
    "            self.session.table(INGREDIENTS_QUANTITY_TABLE_NAME)\n",
    "            .filter(col(\"ID\") == recipe_id)\n",
    "            .select(col(\"INGREDIENTS\"), col(\"QTY_G\"))\n",
    "        )\n",
    "\n",
    "        rows = sdf.collect()  # <-- materialize results\n",
    "        out: Dict[str, Optional[float]] = {}\n",
    "\n",
    "        for r in rows:\n",
    "            ing = r[\"INGREDIENTS\"]\n",
    "            qty = r[\"QTY_G\"]\n",
    "            if ing is None:\n",
    "                continue\n",
    "            out[(ing or \"\").strip().lower()] = (\n",
    "                float(qty) if qty is not None else None\n",
    "            )\n",
    "\n",
    "        self.recipe_qty_cache[recipe_id] = out\n",
    "        return out\n",
    "\n",
    "    def fetch_ingredients_nutrition(\n",
    "        self, recipe_id: str, ingredients: List[str]\n",
    "    ) -> Dict[str, Optional[Dict[str, Any]]]:\n",
    "        \"\"\"\n",
    "         Returns mapping:\n",
    "          key = LOWER(TRIM(ingredient_from_recipe_name))\n",
    "          val = dict of nutrition columns per 100g (or None if not found)\n",
    "        Cached per recipe+ingredient key.\n",
    "        \"\"\"\n",
    "        if recipe_id not in self.recipe_nutrition_cache:\n",
    "            self.recipe_nutrition_cache[recipe_id] = {}\n",
    "\n",
    "        keys = [(s or \"\").strip().lower() for s in ingredients]\n",
    "        keys = [k for k in keys if k]\n",
    "        unique_keys = sorted(set(keys))\n",
    "\n",
    "        missing = [\n",
    "            k\n",
    "            for k in unique_keys\n",
    "            if k not in self.recipe_nutrition_cache[recipe_id]\n",
    "        ]\n",
    "        if not missing:\n",
    "            return self.recipe_nutrition_cache[recipe_id]\n",
    "\n",
    "        # Default missing keys to None so we don't re-query forever\n",
    "        for k in missing:\n",
    "            self.recipe_nutrition_cache[recipe_id][k] = None\n",
    "\n",
    "        im = self.session.table(INGREDIENTS_MATCHED_TABLE_NAME)\n",
    "        ci = self.session.table(INGREDIENTS_NUTRIMENTS_TABLE_NAME)\n",
    "\n",
    "        ing_key_expr = lower(trim(col(\"INGREDIENT_FROM_RECIPE_NAME\")))\n",
    "\n",
    "        joined = (\n",
    "            im.filter(col(\"RECIPE_ID\") == recipe_id)\n",
    "            .with_column(\"ING_KEY\", ing_key_expr)\n",
    "            .filter(col(\"ING_KEY\").isin(missing))\n",
    "            .join(ci, col(\"INGREDIENT_ID\") == col(\"NDB_NO\"), how=\"left\")\n",
    "            .select(\n",
    "                col(\"ING_KEY\"),\n",
    "                col(\"ENERGY_KCAL\"),\n",
    "                col(\"PROTEIN_G\"),\n",
    "                col(\"FAT_G\"),\n",
    "                col(\"SATURATED_FATS_G\"),\n",
    "                col(\"CARB_G\"),\n",
    "                col(\"FIBER_G\"),\n",
    "                col(\"SUGAR_G\"),\n",
    "                col(\"SODIUM_MG\"),\n",
    "                col(\"CALCIUM_MG\"),\n",
    "                col(\"IRON_MG\"),\n",
    "                col(\"MAGNESIUM_MG\"),\n",
    "                col(\"POTASSIUM_MG\"),\n",
    "                col(\"VITC_MG\"),\n",
    "                col(\"SCORE_SANTE\"),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        w = Window.partition_by(col(\"ING_KEY\")).order_by(\n",
    "            col(\"SCORE_SANTE\").desc_nulls_last()\n",
    "        )\n",
    "        ranked = joined.with_column(\"RN\", row_number().over(w)).filter(\n",
    "            col(\"RN\") == 1\n",
    "        )\n",
    "\n",
    "        rows = ranked.select(\n",
    "            \"ING_KEY\",\n",
    "            \"ENERGY_KCAL\",\n",
    "            \"PROTEIN_G\",\n",
    "            \"FAT_G\",\n",
    "            \"SATURATED_FATS_G\",\n",
    "            \"CARB_G\",\n",
    "            \"FIBER_G\",\n",
    "            \"SUGAR_G\",\n",
    "            \"SODIUM_MG\",\n",
    "            \"CALCIUM_MG\",\n",
    "            \"IRON_MG\",\n",
    "            \"MAGNESIUM_MG\",\n",
    "            \"POTASSIUM_MG\",\n",
    "            \"VITC_MG\",\n",
    "        ).collect()\n",
    "\n",
    "        for r in rows:\n",
    "            ing_key = r[\"ING_KEY\"]\n",
    "            vals = [r[c] for c in NUTRITION_COLS]\n",
    "            self.recipe_nutrition_cache[recipe_id][ing_key] = dict(\n",
    "                zip(NUTRITION_COLS, vals)\n",
    "            )\n",
    "\n",
    "        return self.recipe_nutrition_cache[recipe_id]\n",
    "\n",
    "    def compute_recipe_nutrition_totals(\n",
    "        self,\n",
    "        recipe_id: str,\n",
    "        ingredients: List[str],\n",
    "        serving_size: float,\n",
    "        servings: float,\n",
    "    ) -> NutritionDelta:\n",
    "        \"\"\"\n",
    "        Compute recipe nutrition information for all ingredients\n",
    "        Returns:\n",
    "        NutritionDelta\n",
    "            Total nutrients for the  recipe\n",
    "        \"\"\"\n",
    "        total_weight = (serving_size or 0.0) * (servings or 0.0)\n",
    "        ingredients_quantity = self.fetch_recipe_quantities(recipe_id)\n",
    "        ingredients_nutrition = self.fetch_ingredients_nutrition(\n",
    "            recipe_id, ingredients\n",
    "        )\n",
    "\n",
    "        known_weight = 0.0\n",
    "        unknown_count = 0\n",
    "\n",
    "        for _, qty in ingredients_quantity.items():\n",
    "            if qty is None:\n",
    "                unknown_count += 1\n",
    "            else:\n",
    "                known_weight += float(qty)\n",
    "\n",
    "        if unknown_count > 0:\n",
    "            fill_qty = (\n",
    "                max(total_weight - known_weight, 0.0) / unknown_count * 0.5\n",
    "            )  # 0.5 to follow group 1 logic appended to db\n",
    "        else:\n",
    "            fill_qty = 0.0\n",
    "\n",
    "        recipe_nutrition = NutritionDelta(\n",
    "            calories=0.0,\n",
    "            protein_g=0.0,\n",
    "            fat_g=0.0,\n",
    "            saturated_fats_g=0.0,\n",
    "            carb_g=0.0,\n",
    "            fiber_g=0.0,\n",
    "            sugar_g=0.0,\n",
    "            sodium_mg=0.0,\n",
    "            calcium_mg=0.0,\n",
    "            iron_mg=0.0,\n",
    "            magnesium_mg=0.0,\n",
    "            potassium_mg=0.0,\n",
    "            vitamin_c_mg=0.0,\n",
    "            health_score=0.0,\n",
    "        )\n",
    "        for name, nutrition in ingredients_nutrition.items():\n",
    "            if nutrition is None:\n",
    "                continue\n",
    "            quantity = ingredients_quantity.get(name)\n",
    "            if quantity is None:\n",
    "                quantity = fill_qty\n",
    "            factor = float(quantity) / NUTRIENT_BASIS_GRAMS\n",
    "\n",
    "            recipe_nutrition.calories += nutrition[\"ENERGY_KCAL\"] * factor\n",
    "            recipe_nutrition.protein_g += nutrition[\"PROTEIN_G\"] * factor\n",
    "            recipe_nutrition.fat_g += nutrition[\"FAT_G\"] * factor\n",
    "            recipe_nutrition.saturated_fats_g += (\n",
    "                nutrition[\"SATURATED_FATS_G\"] * factor\n",
    "            )\n",
    "            recipe_nutrition.carb_g += nutrition[\"CARB_G\"] * factor\n",
    "            recipe_nutrition.fiber_g += nutrition[\"FIBER_G\"] * factor\n",
    "            recipe_nutrition.sugar_g += nutrition[\"SUGAR_G\"] * factor\n",
    "            recipe_nutrition.sodium_mg += nutrition[\"SODIUM_MG\"] * factor\n",
    "\n",
    "            recipe_nutrition.calcium_mg += nutrition[\"CALCIUM_MG\"] * factor\n",
    "            recipe_nutrition.iron_mg += nutrition[\"IRON_MG\"] * factor\n",
    "            recipe_nutrition.magnesium_mg += nutrition[\"MAGNESIUM_MG\"] * factor\n",
    "            recipe_nutrition.potassium_mg += nutrition[\"POTASSIUM_MG\"] * factor\n",
    "            recipe_nutrition.vitamin_c_mg += nutrition[\"VITC_MG\"] * factor\n",
    "\n",
    "        return recipe_nutrition\n",
    "\n",
    "    def scale_nutrition(\n",
    "        self, n: NutritionDelta, factor: float\n",
    "    ) -> NutritionDelta:\n",
    "        \"\"\"\n",
    "        Scales nutrition value for 100g = a portion of the recipe, to represent the score per portion\n",
    "        Separate from total nutrition calculation to send totals for full recipe if asked\n",
    "        \"\"\"\n",
    "        return NutritionDelta(\n",
    "            calories=n.calories * factor,\n",
    "            protein_g=n.protein_g * factor,\n",
    "            fat_g=n.fat_g * factor,\n",
    "            saturated_fats_g=n.saturated_fats_g * factor,\n",
    "            carb_g=n.carb_g * factor,\n",
    "            fiber_g=n.fiber_g * factor,\n",
    "            sugar_g=n.sugar_g * factor,\n",
    "            sodium_mg=n.sodium_mg * factor,\n",
    "            calcium_mg=n.calcium_mg * factor,\n",
    "            iron_mg=n.iron_mg * factor,\n",
    "            magnesium_mg=n.magnesium_mg * factor,\n",
    "            potassium_mg=n.potassium_mg * factor,\n",
    "            vitamin_c_mg=n.vitamin_c_mg * factor,\n",
    "        )\n",
    "\n",
    "    def compute_benefit_score(self, protein_g: float, fiber_g: float) -> float:\n",
    "        \"\"\"\n",
    "        Compute the benefit score of a recipe based on total protein and fiber.\n",
    "        Returns a value in [0, 1].\n",
    "        \"\"\"\n",
    "        protein_ref = 50.0\n",
    "        fiber_ref = 30.0\n",
    "\n",
    "        s_protein = min(protein_g / protein_ref, 1.0)\n",
    "        s_fiber = min((fiber_g or 0.0) / fiber_ref, 1.0)\n",
    "\n",
    "        benefit_score = (s_protein + s_fiber) / 2.0\n",
    "\n",
    "        return benefit_score\n",
    "\n",
    "    def compute_risk_score(\n",
    "        self,\n",
    "        sugar_g: float,\n",
    "        saturated_fats_g: float,\n",
    "        sodium_mg: float,\n",
    "        alpha_sugar: float = 1.2,\n",
    "        alpha_satfat: float = 1.0,\n",
    "        alpha_sodium: float = 1.5,\n",
    "    ) -> float:\n",
    "        \"\"\"\n",
    "        Compute risk score where exceeding nutrient limits creates negative scores proportional to how badly limits are exceeded.\n",
    "        Returns float between -inf and 1.0\n",
    "        \"\"\"\n",
    "\n",
    "        sugar_limit = 50.0\n",
    "        satfat_limit = 20.0\n",
    "        sodium_limit = 2000.0\n",
    "\n",
    "        def subscore(x, L, alpha):\n",
    "            x = max(x, 0.0)\n",
    "            if x <= L:\n",
    "                return 1.0 - (x / L)\n",
    "            else:\n",
    "                return -alpha * ((x / L) - 1.0)\n",
    "\n",
    "        h_sugar = subscore(sugar_g, sugar_limit, alpha_sugar)\n",
    "        h_satfat = subscore(saturated_fats_g, satfat_limit, alpha_satfat)\n",
    "        h_sodium = subscore(sodium_mg, sodium_limit, alpha_sodium)\n",
    "\n",
    "        risk_control_score = (h_sugar + h_satfat + h_sodium) / 3.0\n",
    "        return risk_control_score\n",
    "\n",
    "    def compute_micronutrient_density_score(\n",
    "        self,\n",
    "        calcium_mg: float,\n",
    "        iron_mg: float,\n",
    "        magnesium_mg: float,\n",
    "        potassium_mg: float,\n",
    "        vitamin_c_mg: float,\n",
    "    ) -> float:\n",
    "        \"\"\"\n",
    "        Compute a micronutrient density score in [0, 1] based on totals for the recipe.\n",
    "        \"\"\"\n",
    "\n",
    "        calcium_ref = 1000.0\n",
    "        iron_ref = 18.0\n",
    "        magnesium_ref = 350.0\n",
    "        potassium_ref = 3500.0\n",
    "        vitamin_c_ref = 90.0\n",
    "\n",
    "        m_ca = min(max(calcium_mg, 0.0) / calcium_ref, 1.0)\n",
    "        m_fe = min(max(iron_mg, 0.0) / iron_ref, 1.0)\n",
    "        m_mg = min(max(magnesium_mg, 0.0) / magnesium_ref, 1.0)\n",
    "        m_k = min(max(potassium_mg, 0.0) / potassium_ref, 1.0)\n",
    "        m_c = min(max(vitamin_c_mg, 0.0) / vitamin_c_ref, 1.0)\n",
    "\n",
    "        micronutrient_score = (m_ca + m_fe + m_mg + m_k + m_c) / 5.0\n",
    "\n",
    "        return micronutrient_score\n",
    "\n",
    "    def compute_rhi(self, nutrition: NutritionDelta) -> float:\n",
    "        \"\"\"\n",
    "        Compute the Recipe Health Index (RHI) on [0, 100] for a whole recipe.\n",
    "        Uses:\n",
    "          - benefit score (protein + fiber, vs daily references)\n",
    "          - risk score (sugar, saturated fat, sodium vs daily limits, with penalties above limits)\n",
    "          - micronutrient density score (Ca, Fe, Mg, K, Vit C vs daily references)\n",
    "\n",
    "        RHI = max(0, 0.4 * risk + 0.4 * benefit + 0.2 * micro) * 100\n",
    "        \"\"\"\n",
    "\n",
    "        benefit = self.compute_benefit_score(\n",
    "            protein_g=nutrition.protein_g, fiber_g=nutrition.fiber_g\n",
    "        )\n",
    "        risk = self.compute_risk_score(\n",
    "            sugar_g=nutrition.sugar_g,\n",
    "            saturated_fats_g=nutrition.saturated_fats_g,\n",
    "            sodium_mg=nutrition.sodium_mg,\n",
    "        )\n",
    "        micro = self.compute_micronutrient_density_score(\n",
    "            calcium_mg=nutrition.calcium_mg,\n",
    "            iron_mg=nutrition.iron_mg,\n",
    "            magnesium_mg=nutrition.magnesium_mg,\n",
    "            potassium_mg=nutrition.potassium_mg,\n",
    "            vitamin_c_mg=nutrition.vitamin_c_mg,\n",
    "        )\n",
    "\n",
    "        rhi_raw = 0.4 * risk + 0.4 * benefit + 0.2 * micro\n",
    "\n",
    "        rhi_0_1 = max(0.0, rhi_raw)\n",
    "        rhi = rhi_0_1 * 100.0\n",
    "\n",
    "        return rhi\n",
    "\n",
    "    def ensure_pca_loaded(self):\n",
    "        if TransformService._pca_data_cache is None:\n",
    "            with TransformService._pca_lock:\n",
    "                if TransformService._pca_data_cache is None:\n",
    "                    TransformService._pca_data_cache = (\n",
    "                        self.load_pca_data_from_snowflake()\n",
    "                    )\n",
    "        self.pca_data = TransformService._pca_data_cache\n",
    "\n",
    "    def load_pca_data(self):\n",
    "        \"\"\"Load PCA data from Snowflake or CSV as fallback\"\"\"\n",
    "        if self.pca_data is None:\n",
    "            try:\n",
    "                # Charger le fichier CSV\n",
    "                csv_path = \"ingredients_with_clusters.csv\"\n",
    "                df = pd.read_csv(csv_path)\n",
    "\n",
    "                # query = f\"\"\"\n",
    "                # SELECT\n",
    "                #     NDB_No,\n",
    "                #     Descrip,\n",
    "                #     ENERGY_KCAL,\n",
    "                #     PROTEIN_G,\n",
    "                #     SATURATED_FATS_G,\n",
    "                #     FAT_G,CARB_G,\n",
    "                #     SODIUM_MG,SUGAR_G,\n",
    "                #     PCA_macro_1,\n",
    "                #     PCA_macro_2,\n",
    "                #     PCA_macro_3,\n",
    "                #     PCA_micro_1,\n",
    "                #     PCA_micro_2,\n",
    "                #     Cluster_macro,\n",
    "                #     Cluster_micro\n",
    "                # FROM {INGREDIENTS_CLUSTERING_TABLE_NAME}\n",
    "                # LIMIT 100;\n",
    "                # \"\"\"\n",
    "\n",
    "                # Parse query result\n",
    "                # result_cluster = self.session.sql(query)\n",
    "                # df = pd.DataFrame(parse_query_result(result_cluster))\n",
    "                # Parse column values to float\n",
    "                # for col in list(df.columns[2:-2]):\n",
    "                #     df[col] = df[col].apply(float)\n",
    "\n",
    "                # Adapter les noms de colonnes pour correspondre au format attendu\n",
    "                self.pca_data = df.rename(\n",
    "                    columns={\n",
    "                        \"NDB_No\": \"NDB_No\",\n",
    "                        \"DESCRIP\": \"Descrip\",\n",
    "                        \"Energy_kcal\": \"ENERGY_KCAL\",\n",
    "                        \"Protein_g\": \"PROTEIN_G\",\n",
    "                        \"Saturated_fats_g\": \"SATURATED_FATS_G\",\n",
    "                        \"Fat_g\": \"FAT_G\",\n",
    "                        \"Carb_g\": \"CARB_G\",\n",
    "                        \"Sodium_mg\": \"SODIUM_MG\",\n",
    "                        \"Sugar_g\": \"SUGAR_G\",\n",
    "                        \"PCA_MACRO_1\": \"PCA_macro_1\",\n",
    "                        \"PCA_MACRO_2\": \"PCA_macro_2\",\n",
    "                        \"PCA_MACRO_3\": \"PCA_macro_3\",\n",
    "                        \"PCA_MICRO_1\": \"PCA_micro_1\",\n",
    "                        \"PCA_MICRO_2\": \"PCA_micro_2\",\n",
    "                        \"Cluster_macro\": \"Cluster_macro\",\n",
    "                        \"Cluster_micro\": \"Cluster_micro\",\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                # Ajouter des colonnes de contraintes par défaut (pas disponibles dans le CSV)\n",
    "                self.pca_data[\"is_lactose\"] = 0\n",
    "                self.pca_data[\"is_gluten\"] = 0\n",
    "                self.pca_data[\"contains_nuts\"] = 0\n",
    "                self.pca_data[\"is_vegetarian\"] = 0\n",
    "                self.pca_data[\"is_vegetable\"] = 0\n",
    "\n",
    "                # Logique simple pour définir quelques contraintes basées sur le nom\n",
    "                for idx, row in self.pca_data.iterrows():\n",
    "                    descrip_lower = str(row[\"Descrip\"]).lower()\n",
    "\n",
    "                    # Détection lactose (produits laitiers)\n",
    "                    if any(\n",
    "                        word in descrip_lower\n",
    "                        for word in [\n",
    "                            \"milk\",\n",
    "                            \"cheese\",\n",
    "                            \"butter\",\n",
    "                            \"cream\",\n",
    "                            \"yogurt\",\n",
    "                        ]\n",
    "                    ):\n",
    "                        self.pca_data.at[idx, \"is_lactose\"] = 1\n",
    "\n",
    "                    # Détection gluten (céréales, pain, etc.)\n",
    "                    if any(\n",
    "                        word in descrip_lower\n",
    "                        for word in [\n",
    "                            \"wheat\",\n",
    "                            \"bread\",\n",
    "                            \"flour\",\n",
    "                            \"pasta\",\n",
    "                            \"cereal\",\n",
    "                        ]\n",
    "                    ):\n",
    "                        self.pca_data.at[idx, \"is_gluten\"] = 1\n",
    "\n",
    "                    # Détection noix\n",
    "                    if any(\n",
    "                        word in descrip_lower\n",
    "                        for word in [\n",
    "                            \"nut\",\n",
    "                            \"almond\",\n",
    "                            \"peanut\",\n",
    "                            \"walnut\",\n",
    "                            \"pecan\",\n",
    "                        ]\n",
    "                    ):\n",
    "                        self.pca_data.at[idx, \"contains_nuts\"] = 1\n",
    "\n",
    "                    # Détection végétarien (pas de viande/poisson)\n",
    "                    if not any(\n",
    "                        word in descrip_lower\n",
    "                        for word in [\n",
    "                            \"beef\",\n",
    "                            \"pork\",\n",
    "                            \"chicken\",\n",
    "                            \"fish\",\n",
    "                            \"meat\",\n",
    "                            \"turkey\",\n",
    "                            \"lamb\",\n",
    "                        ]\n",
    "                    ):\n",
    "                        self.pca_data.at[idx, \"is_vegetarian\"] = 1\n",
    "\n",
    "                    # Détection végétal (fruits, légumes, etc.)\n",
    "                    if any(\n",
    "                        word in descrip_lower\n",
    "                        for word in [\n",
    "                            \"vegetable\",\n",
    "                            \"fruit\",\n",
    "                            \"bean\",\n",
    "                            \"pea\",\n",
    "                            \"lentil\",\n",
    "                            \"spinach\",\n",
    "                            \"carrot\",\n",
    "                            \"tomato\",\n",
    "                        ]\n",
    "                    ):\n",
    "                        self.pca_data.at[idx, \"is_vegetable\"] = 1\n",
    "\n",
    "                logging.info(\n",
    "                    \"Success: PCA ingredients coordinates successfully loaded.\"\n",
    "                )\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.error(\n",
    "                    f\"Failure: PCA ingredients coordinates loading error. Error: {str(e)}. Traceback: {traceback.format_exc()}\"\n",
    "                )\n",
    "                self.pca_data = None\n",
    "\n",
    "    def get_neighbors_pca(\n",
    "        self,\n",
    "        ingredient_name: str,\n",
    "        constraints: TransformConstraints = None,\n",
    "        micro_weight: float = 0.3,\n",
    "        macro_weight: float = 0.7,\n",
    "        k: int = 5,\n",
    "    ) -> Dict:\n",
    "        \"\"\"\n",
    "        Find the k best substitutes for an ingredient using PCA macro/micro\n",
    "\n",
    "        Args:\n",
    "            ingredient_name: ingredient to substitute\n",
    "            constraints: transformation constraints\n",
    "            micro_weight: weight of micronutrients\n",
    "            macro_weight: weight of macronutrients\n",
    "            k: number of substitutes to return\n",
    "\n",
    "        Returns:\n",
    "            Dict with the best substitutes\n",
    "        \"\"\"\n",
    "        if self.pca_data is None:\n",
    "            logging.warning(\"Failure: PCA ingredients coordinates missing.\")\n",
    "            return None\n",
    "\n",
    "        # Clean ingredient name\n",
    "        ingredient_clean = ingredient_name.lower().strip()\n",
    "\n",
    "        # Search for ingredient in PCA Data\n",
    "        matching_rows = self.pca_data[\n",
    "            self.pca_data[\"Descrip\"]\n",
    "            .str.lower()\n",
    "            .str.contains(ingredient_clean, na=False)\n",
    "        ]\n",
    "\n",
    "        if matching_rows.empty:\n",
    "            logging.warning(\n",
    "                f\"Failure:  Ingredient '{ingredient_name}' not found in PCA data\"\n",
    "            )\n",
    "            return None\n",
    "\n",
    "        # Take the first match\n",
    "        row = matching_rows.iloc[0]\n",
    "        logging.info(\n",
    "            f\"Success: Ingredient found: {ingredient_name} → {row['Descrip']}\"\n",
    "        )\n",
    "\n",
    "        # Copy data for filtering based on constraints\n",
    "        df_filtered = self.pca_data.copy()\n",
    "\n",
    "        # Apply constraint filters\n",
    "        if constraints:\n",
    "            CONSTRAINT_TO_COLUMN = {\n",
    "                \"no_lactose\": (\"is_lactose\", 0),\n",
    "                \"no_gluten\": (\"is_gluten\", 0),\n",
    "                \"no_nuts\": (\"contains_nuts\", 0),\n",
    "                \"vegetarian\": (\"is_vegetarian\", 1),\n",
    "                \"vegan\": (\"is_vegetable\", 1),\n",
    "            }\n",
    "\n",
    "            for constraint_name, (\n",
    "                col,\n",
    "                allowed_val,\n",
    "            ) in CONSTRAINT_TO_COLUMN.items():\n",
    "                if getattr(constraints, constraint_name, False):\n",
    "                    # Keep only ingredients that meet the constraint OR the original ingredient\n",
    "                    if col in df_filtered.columns:\n",
    "                        df_filtered = df_filtered[\n",
    "                            (df_filtered[col] == allowed_val)\n",
    "                            | (\n",
    "                                df_filtered[\"Descrip\"].str.lower()\n",
    "                                == ingredient_clean\n",
    "                            )\n",
    "                        ]\n",
    "\n",
    "        # PCA columns\n",
    "        macro_cols = [\"PCA_macro_1\", \"PCA_macro_2\", \"PCA_macro_3\"]\n",
    "        micro_cols = [\"PCA_micro_1\", \"PCA_micro_2\"]\n",
    "\n",
    "        # Check that columns exist\n",
    "        available_macro_cols = [\n",
    "            col for col in macro_cols if col in df_filtered.columns\n",
    "        ]\n",
    "        available_micro_cols = [\n",
    "            col for col in micro_cols if col in df_filtered.columns\n",
    "        ]\n",
    "\n",
    "        if not available_macro_cols and not available_micro_cols:\n",
    "            logging.warning(\n",
    "                f\"Failure:  No pca coordinates available in pca dataframe.\"\n",
    "            )\n",
    "            return None\n",
    "\n",
    "        macro_vec = (\n",
    "            row[available_macro_cols].values\n",
    "            if available_macro_cols\n",
    "            else np.array([])\n",
    "        )\n",
    "        micro_vec = (\n",
    "            row[available_micro_cols].values\n",
    "            if available_micro_cols\n",
    "            else np.array([])\n",
    "        )\n",
    "\n",
    "        def euclidean_distance(a, b):\n",
    "            return np.linalg.norm(a - b) if len(a) > 0 and len(b) > 0 else 0\n",
    "\n",
    "        # Exclude the original ingredient\n",
    "        df_filtered = df_filtered[df_filtered[\"Descrip\"] != row[\"Descrip\"]]\n",
    "\n",
    "        if df_filtered.empty:\n",
    "            logging.warning(\n",
    "                \"Failure: No substitute found after applying constraints\"\n",
    "            )\n",
    "            return None\n",
    "\n",
    "        # Calculate global distances (macro + micro combination)\n",
    "        df_filtered = df_filtered.copy()\n",
    "\n",
    "        # Calculate macro distance\n",
    "        if available_macro_cols:\n",
    "            df_filtered[\"dist_macro\"] = df_filtered[available_macro_cols].apply(\n",
    "                lambda x: euclidean_distance(macro_vec, x.values), axis=1\n",
    "            )\n",
    "        else:\n",
    "            df_filtered[\"dist_macro\"] = 0\n",
    "\n",
    "        # Calculate micro distance\n",
    "        if available_micro_cols:\n",
    "            df_filtered[\"dist_micro\"] = df_filtered[available_micro_cols].apply(\n",
    "                lambda x: euclidean_distance(micro_vec, x.values), axis=1\n",
    "            )\n",
    "        else:\n",
    "            df_filtered[\"dist_micro\"] = 0\n",
    "\n",
    "        # Combined global score\n",
    "        df_filtered[\"global_score\"] = (\n",
    "            macro_weight * df_filtered[\"dist_macro\"]\n",
    "            + micro_weight * df_filtered[\"dist_micro\"]\n",
    "        )\n",
    "\n",
    "        # -------------------------\n",
    "        # Filter similarities (not regex after all), 30/12/25\n",
    "        # -------------------------\n",
    "        main_word = ingredient_clean.split()[0]  # only the first word for now\n",
    "\n",
    "        def filter_similar_df(df, k):\n",
    "            filtered_rows = []\n",
    "            for _, row_ in df.iterrows():\n",
    "                name_lower = row_[\"Descrip\"].lower()\n",
    "                if not name_lower.startswith(main_word):\n",
    "                    filtered_rows.append(row_)\n",
    "                if len(filtered_rows) >= k:\n",
    "                    break\n",
    "            return pd.DataFrame(filtered_rows)\n",
    "\n",
    "        # Sort by global score and take the top k\n",
    "        best_substitutes = df_filtered.nsmallest(k, \"global_score\")\n",
    "        # Filter ingredients with the same base name\n",
    "        best_substitutes = filter_similar_df(best_substitutes, k)\n",
    "\n",
    "        result = {\"input_ingredient\": row[\"Descrip\"], \"best_substitutes\": []}\n",
    "\n",
    "        for _, substitute_row in best_substitutes.iterrows():\n",
    "            result[\"best_substitutes\"].append(\n",
    "                {\n",
    "                    \"name\": substitute_row[\"Descrip\"],\n",
    "                    \"global_score\": substitute_row[\"global_score\"],\n",
    "                    \"macro_distance\": substitute_row[\"dist_macro\"],\n",
    "                    \"micro_distance\": substitute_row[\"dist_micro\"],\n",
    "                    \"nutrition\": {\n",
    "                        \"calories\": substitute_row[\"ENERGY_KCAL\"],\n",
    "                        \"protein\": substitute_row[\"PROTEIN_G\"],\n",
    "                        \"saturated_fat\": substitute_row[\"SATURATED_FATS_G\"],\n",
    "                        \"sodium\": substitute_row[\"SODIUM_MG\"],\n",
    "                        \"sugar\": substitute_row[\"SUGAR_G\"],\n",
    "                    },\n",
    "                }\n",
    "            )\n",
    "\n",
    "        return result\n",
    "\n",
    "    def get_health_score(\n",
    "        self,\n",
    "        new_ingredients: List[str],\n",
    "        recipe_id: int,\n",
    "        serving_size: float,\n",
    "        servings: float,\n",
    "    ) -> NutritionDelta:\n",
    "        \"\"\"\n",
    "        Calculates health score for a recipe based on give ingredients\n",
    "        \"\"\"\n",
    "        new_recipe_nutrition = self.compute_recipe_nutrition_totals(\n",
    "            recipe_id=recipe_id,\n",
    "            ingredients=new_ingredients,\n",
    "            serving_size=serving_size,\n",
    "            servings=servings,\n",
    "        )\n",
    "        denom = (serving_size or 0) * (servings or 0)\n",
    "        if denom > 0:\n",
    "            scaled_nutrition = self.scale_nutrition(\n",
    "                new_recipe_nutrition, factor=100.0 / denom\n",
    "            )\n",
    "        else:\n",
    "            scaled_nutrition = new_recipe_nutrition  ## fallback servings null\n",
    "        rhi_score = self.compute_rhi(scaled_nutrition)\n",
    "        new_recipe_nutrition.health_score = rhi_score\n",
    "        return new_recipe_nutrition\n",
    "\n",
    "    def judge_substitute(\n",
    "        self,\n",
    "        candidates,\n",
    "        recipe_ingredients: List[str],\n",
    "        recipe_id: int,\n",
    "        serving_size: float,\n",
    "        servings: float,\n",
    "    ) -> Tuple[str, NutritionDelta]:\n",
    "        \"\"\"\n",
    "        Final ingredient choice between list of candidates\n",
    "\n",
    "        Args:\n",
    "            candidates: list of possible ingredients to substitute with (extracted from get_neighbors_pca() )\n",
    "            recipe_id, serving_size, servings, recipe_ingredients: recipe information\n",
    "        Returns:\n",
    "            ingredient_id\n",
    "        \"\"\"\n",
    "        if not candidates:\n",
    "            logging.warning(\"Failure: No candidatee found.\")\n",
    "            return None, self._zero_nutrition()\n",
    "        best_ing = None\n",
    "        best_nutrition = self._zero_nutrition()\n",
    "        for cand in candidates:\n",
    "            if best_ing is None:\n",
    "                best_ing = cand\n",
    "            else:\n",
    "                candidat_nutrition = self.get_health_score(\n",
    "                    recipe_ingredients + [cand[\"name\"]],\n",
    "                    recipe_id,\n",
    "                    serving_size,\n",
    "                    servings,\n",
    "                )\n",
    "                best_current_score = self.get_health_score(\n",
    "                    recipe_ingredients + [best_ing[\"name\"]],\n",
    "                    recipe_id,\n",
    "                    serving_size,\n",
    "                    servings,\n",
    "                )\n",
    "                if (\n",
    "                    candidat_nutrition.health_score\n",
    "                    > best_current_score.health_score\n",
    "                ):\n",
    "                    best_ing = cand\n",
    "                    best_nutrition = candidat_nutrition\n",
    "        return best_ing, best_nutrition\n",
    "\n",
    "    def substitute_ingr(\n",
    "        self,\n",
    "        ingredient: str,\n",
    "        contraintes: TransformConstraints,\n",
    "        recipe_ingredients: List[str],\n",
    "        recipe_id: int,\n",
    "        serving_size: float,\n",
    "        servings: float,\n",
    "    ) -> Tuple[str, bool, NutritionDelta]:\n",
    "        \"\"\"\n",
    "        Finds a substitute for the given ingredient using PCA in priority\n",
    "\n",
    "        Args:\n",
    "            ingredient: ingredient to substitute\n",
    "            contraintes: nutritional constraints\n",
    "\n",
    "        Returns:\n",
    "            Tuple (substituted_ingredient, substitution_performed)\n",
    "        \"\"\"\n",
    "        result = self.get_neighbors_pca(ingredient, contraintes)\n",
    "\n",
    "        if not result or not result.get(\"best_substitutes\"):\n",
    "            return ingredient, False, self._zero_nutrition()\n",
    "\n",
    "        candidates = result[\"best_substitutes\"]\n",
    "        substitute, nutrition = self.judge_substitute(\n",
    "            candidates, recipe_ingredients, recipe_id, serving_size, servings\n",
    "        )\n",
    "\n",
    "        if substitute:\n",
    "            substitute_name = substitute[\"name\"]\n",
    "            logging.info(\n",
    "                f\"Success: Found substitute for {ingredient} → {substitute_name} (PCA score: {substitute['global_score']:.3f})\"\n",
    "            )\n",
    "            return substitute_name, True, nutrition\n",
    "\n",
    "        return ingredient, False, self._zero_nutrition()\n",
    "\n",
    "    def fetch_ingredients_tags(\n",
    "        self, recipe_id: str, ingredients: List[str]\n",
    "    ) -> Dict[str, Optional[Dict[str, Any]]]:\n",
    "        \"\"\"\n",
    "        Returns mapping:\n",
    "          key = LOWER(TRIM(ingredient_from_recipe_name))\n",
    "          val = dict of tag columns (or None if not found)\n",
    "        Cached per recipe+ingredient key.\n",
    "        \"\"\"\n",
    "        if recipe_id not in self.recipe_tags_cache:\n",
    "            self.recipe_tags_cache[recipe_id] = {}\n",
    "\n",
    "        keys = [(s or \"\").strip().lower() for s in ingredients]\n",
    "        keys = [k for k in keys if k]\n",
    "        unique_keys = sorted(set(keys))\n",
    "\n",
    "        missing = [\n",
    "            k for k in unique_keys if k not in self.recipe_tags_cache[recipe_id]\n",
    "        ]\n",
    "        if not missing:\n",
    "            return self.recipe_tags_cache[recipe_id]\n",
    "\n",
    "        # Default missing keys to None so we don't re-query forever\n",
    "        for k in missing:\n",
    "            self.recipe_tags_cache[recipe_id][k] = None\n",
    "\n",
    "        im = self.session.table(INGREDIENTS_MATCHED_TABLE_NAME)\n",
    "        it = self.session.table(INGREDIENTS_TAGGED_TABLE_NAME)\n",
    "\n",
    "        ing_key_expr = lower(trim(col(\"INGREDIENT_FROM_RECIPE_NAME\")))\n",
    "\n",
    "        joined = (\n",
    "            im.filter(col(\"RECIPE_ID\") == recipe_id)\n",
    "            .with_column(\"ING_KEY\", ing_key_expr)\n",
    "            .filter(col(\"ING_KEY\").isin(missing))\n",
    "            .join(it, col(\"INGREDIENT_ID\") == col(\"NDB_NO\"), how=\"left\")\n",
    "            .select(\n",
    "                col(\"ING_KEY\"),\n",
    "                col(\"NDB_NO\"),\n",
    "                col(\"DESCRIP\"),\n",
    "                col(\"FOODON_LABEL\"),\n",
    "                col(\"IS_DAIRY\"),\n",
    "                col(\"IS_GLUTEN\"),\n",
    "                col(\"CONTAINS_NUTS\"),\n",
    "                col(\"IS_GRAIN\"),\n",
    "                col(\"IS_SEAFOOD\"),\n",
    "                col(\"IS_SWEETENER\"),\n",
    "                col(\"IS_VEGETABLE\"),\n",
    "                col(\"IS_VEGETARIAN\"),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # If multiple rows exist per ING_KEY, just take the first one deterministically\n",
    "        w = Window.partition_by(col(\"ING_KEY\")).order_by(\n",
    "            col(\"NDB_NO\").asc_nulls_last()\n",
    "        )\n",
    "        ranked = joined.with_column(\"RN\", row_number().over(w)).filter(\n",
    "            col(\"RN\") == 1\n",
    "        )\n",
    "\n",
    "        rows = ranked.collect()\n",
    "\n",
    "        for r in rows:\n",
    "            ing_key = r[\"ING_KEY\"]\n",
    "            self.recipe_tags_cache[recipe_id][ing_key] = {\n",
    "                \"NDB_NO\": r[\"NDB_NO\"],\n",
    "                \"DESCRIP\": r[\"DESCRIP\"],\n",
    "                \"FOODON_LABEL\": r[\"FOODON_LABEL\"],\n",
    "                \"IS_DAIRY\": r[\"IS_DAIRY\"],\n",
    "                \"IS_GLUTEN\": r[\"IS_GLUTEN\"],\n",
    "                \"CONTAINS_NUTS\": r[\"CONTAINS_NUTS\"],\n",
    "                \"IS_GRAIN\": r[\"IS_GRAIN\"],\n",
    "                \"IS_SEAFOOD\": r[\"IS_SEAFOOD\"],\n",
    "                \"IS_SWEETENER\": r[\"IS_SWEETENER\"],\n",
    "                \"IS_VEGETABLE\": r[\"IS_VEGETABLE\"],\n",
    "                \"IS_VEGETARIAN\": r[\"IS_VEGETARIAN\"],\n",
    "            }\n",
    "\n",
    "        return self.recipe_tags_cache[recipe_id]\n",
    "\n",
    "    def identify_ingredients_to_remove_by_algo(\n",
    "        self, recipe: Recipe, constraints: TransformConstraints\n",
    "    ) -> List[str]:\n",
    "        \"\"\"\n",
    "        Algorithm to identify ingredients to remove based on nutritional constraints.\n",
    "\n",
    "        Args:\n",
    "            recipe: Recipe object\n",
    "            constraints: TransformConstraints with nutritional goals\n",
    "\n",
    "        Returns:\n",
    "            List of ingredient names to remove\n",
    "        \"\"\"\n",
    "        ingredients_to_remove = []\n",
    "\n",
    "        try:\n",
    "            # Fetch nutritional data for all ingredients\n",
    "            ingredients_nutrition = self.fetch_ingredients_nutrition(\n",
    "                recipe.id, recipe.ingredients\n",
    "            )\n",
    "            ingredients_tags = self.fetch_ingredients_tags(\n",
    "                recipe.id, recipe.ingredients\n",
    "            )\n",
    "\n",
    "            allergy_constraints = [\n",
    "                \"no_lactose\",\n",
    "                \"no_gluten\",\n",
    "                \"no_nuts\",\n",
    "                \"vegetarian\",\n",
    "                \"vegan\",\n",
    "            ]\n",
    "            reduction_constraints = [\n",
    "                \"decrease_sugar\",\n",
    "                \"decrease_sodium\",\n",
    "                \"decrease_calories\",\n",
    "                \"decrease_carbs\",\n",
    "                \"increase_protein\",\n",
    "                \"decrease_protein\",\n",
    "            ]\n",
    "\n",
    "            active_allergy = any(\n",
    "                getattr(constraints, c, False) for c in allergy_constraints\n",
    "            )\n",
    "            active_reduction = any(\n",
    "                getattr(constraints, c, False) for c in reduction_constraints\n",
    "            )\n",
    "\n",
    "            max_items = 3 if active_allergy else (1 if active_reduction else 0)\n",
    "\n",
    "            # Define thresholds to identify \"bad\" ingredients\n",
    "            SUGAR_THRESHOLD = 10.0  # g per 100g\n",
    "            SODIUM_THRESHOLD = 500.0  # mg per 100g\n",
    "            SATURATED_FAT_THRESHOLD = 5.0  # g per 100g\n",
    "            CALORIE_THRESHOLD = 300.0  # kcal per 100g\n",
    "            CARB_THRESHOLD = 50.0  # g per 100g\n",
    "\n",
    "            for ingredient in recipe.ingredients:\n",
    "                ing_key = ingredient.lower().strip()\n",
    "                nutrition = ingredients_nutrition.get(ing_key)\n",
    "\n",
    "                if nutrition is None:\n",
    "                    continue\n",
    "\n",
    "                should_remove = False\n",
    "\n",
    "                # Check reduction constraints\n",
    "                if (\n",
    "                    constraints.decrease_sugar\n",
    "                    and nutrition.get(\"SUGAR_G\", 0) > SUGAR_THRESHOLD\n",
    "                ):\n",
    "                    should_remove = True\n",
    "                    # print(f\"_identify_ingredients_to_remove_by_algo: {ingredient} identified for sugar reduction ({nutrition.get('SUGAR_G', 0):.1f}g)\")\n",
    "\n",
    "                if (\n",
    "                    constraints.decrease_sodium\n",
    "                    and nutrition.get(\"SODIUM_MG\", 0) > SODIUM_THRESHOLD\n",
    "                ):\n",
    "                    should_remove = True\n",
    "                    # print(f\"_identify_ingredients_to_remove_by_algo: {ingredient} identified for sodium reduction ({nutrition.get('SODIUM_MG', 0):.1f}mg)\")\n",
    "\n",
    "                if (\n",
    "                    constraints.decrease_calories\n",
    "                    and nutrition.get(\"ENERGY_KCAL\", 0) > CALORIE_THRESHOLD\n",
    "                ):\n",
    "                    should_remove = True\n",
    "                    # print(f\"_identify_ingredients_to_remove_by_algo: {ingredient} identified for calorie reduction ({nutrition.get('ENERGY_KCAL', 0):.1f}kcal)\")\n",
    "\n",
    "                if (\n",
    "                    constraints.decrease_carbs\n",
    "                    and nutrition.get(\"CARB_G\", 0) > CARB_THRESHOLD\n",
    "                ):\n",
    "                    should_remove = True\n",
    "                    # print(f\"_identify_ingredients_to_remove_by_algo: {ingredient} identified for carbohydrate reduction ({nutrition.get('CARB_G', 0):.1f}g)\")\n",
    "\n",
    "                # Check dietary constraints (via PCA data if available)\n",
    "                tags = ingredients_tags.get(ing_key)\n",
    "                if tags is not None:\n",
    "                    if constraints.no_lactose and tags.get(\"IS_DAIRY\") is True:\n",
    "                        should_remove = True\n",
    "                    if constraints.no_gluten and tags.get(\"IS_GLUTEN\") is True:\n",
    "                        should_remove = True\n",
    "                    if (\n",
    "                        constraints.no_nuts\n",
    "                        and tags.get(\"CONTAINS_NUTS\") is True\n",
    "                    ):\n",
    "                        should_remove = True\n",
    "                    if (\n",
    "                        constraints.vegetarian\n",
    "                        and tags.get(\"IS_VEGETARIAN\") is False\n",
    "                    ):\n",
    "                        should_remove = True\n",
    "                    if constraints.vegan and tags.get(\"IS_VEGETABLE\") is False:\n",
    "                        should_remove = True  # proxy as you requested\n",
    "\n",
    "                if should_remove:\n",
    "                    ingredients_to_remove.append(ingredient)\n",
    "                    if max_items and len(ingredients_to_remove) >= max_items:\n",
    "                        break\n",
    "\n",
    "            # Limit the number of ingredients to remove (max 3 to not destroy the recipe)\n",
    "            if len(ingredients_to_remove) > 3:\n",
    "                print(\n",
    "                    f\"_identify_ingredients_to_remove_by_algo: Limiting to 3 ingredients out of {len(ingredients_to_remove)} identified\"\n",
    "                )\n",
    "                ingredients_to_remove = ingredients_to_remove[:3]\n",
    "\n",
    "            return ingredients_to_remove\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\" Error in identifying ingredients to remove: {e}\")\n",
    "            traceback.print_exc()\n",
    "            return []\n",
    "\n",
    "    def identify_ingredients_to_remove_by_llm(\n",
    "        self, recipe: Recipe, constraints: TransformConstraints\n",
    "    ) -> List[str]:\n",
    "        \"\"\"\n",
    "        LLM fallback to identify ingredients to remove if the algorithm fails, based on full recipe and constraints.\n",
    "        If constraint is an allergy or regime specific (vegetarian, vegan) all ingredients to remove are returned\n",
    "        If constraint is a reduction (sugar, sodium, calories, carbs, protein) only one ingredient is returned\n",
    "\n",
    "        Args:\n",
    "            recipe: Recipe object\n",
    "            constraints: TransformConstraints with nutritional goals\n",
    "\n",
    "        Returns:\n",
    "            List of ingredient names to remove\n",
    "        \"\"\"\n",
    "        try:\n",
    "            allergy_constraints = [\n",
    "                \"no_lactose\",\n",
    "                \"no_gluten\",\n",
    "                \"no_nuts\",\n",
    "                \"vegetarian\",\n",
    "                \"vegan\",\n",
    "            ]\n",
    "            reduction_constraints = [\n",
    "                \"decrease_sugar\",\n",
    "                \"decrease_sodium\",\n",
    "                \"decrease_calories\",\n",
    "                \"decrease_carbs\",\n",
    "                \"increase_protein\",\n",
    "                \"decrease_protein\",\n",
    "            ]\n",
    "\n",
    "            active_allergy = [\n",
    "                c for c in allergy_constraints if getattr(constraints, c, False)\n",
    "            ]\n",
    "            active_reduction = [\n",
    "                c\n",
    "                for c in reduction_constraints\n",
    "                if getattr(constraints, c, False)\n",
    "            ]\n",
    "\n",
    "            if not active_allergy and not active_reduction:\n",
    "                return []\n",
    "\n",
    "            if active_allergy:\n",
    "                mode = \"ALL_VIOLATIONS\"\n",
    "                constraints_text = \", \".join(active_allergy + active_reduction)\n",
    "            else:\n",
    "                max_items = 1\n",
    "                mode = \"ONE_OFFENDER\"\n",
    "                constraints_text = \", \".join(active_reduction)\n",
    "            logging.info(\"boo\")\n",
    "            base_prompt = f\"\"\"\n",
    "            \n",
    "            You are a culinary and nutrition expert analyzing recipe ingredients.\n",
    "\n",
    "                YOUR TASK:\n",
    "                - Analyze the recipe as a whole (name, ingredients, quantities, and steps).\n",
    "                - Identify which ingredients should be REMOVED to meet the constraints.\n",
    "                If constraint are no lactose, no_gluten, no_nuts, vegetarian, vegan, return ingredients that obviously violate these constraints.\n",
    "                - For no lactose: only flag ingredients that are dairy by name. Do NOT flag hidden dairy (bread, crescent rolls, eggs etc.)\n",
    "                - For vegetarian/vegan, only remove ingredients that are clearly non-vegetarian/vegan by name (meat, fish, poultry, eggs, dairy, etc.)\n",
    "                - If constraint are to decrease sugar, sodium, calories, carbs, or protein, return one ingredient that most harms the constraints.\n",
    "\n",
    "                IMPORTANT:\n",
    "                - Only suggest removing ingredients that clearly violate the constraints\n",
    "                - Do NOT suggest removing essential ingredients that define the dish\n",
    "                - Be conservative - better to remove fewer ingredients than too many\n",
    "                - You MUST choose ONLY from the Ingredients list exactly (no synonyms / no variants).\n",
    "                - If no ingredients violate the constraints, respond with NONE.\n",
    "                \n",
    "                STRICT OUTPUT RULES (MANDATORY):\n",
    "                - Output ONLY either:\n",
    "                  (A) NONE\n",
    "                  OR\n",
    "                  (B) a comma-separated list of ingredient strings copied EXACTLY from RECIPE INGREDIENTS.\n",
    "                - NO other words. NO explanations. NO punctuation other than commas.\n",
    "                - NO prefixes like \"Explanation:\" or \"Ingredients:\".\n",
    "                - If nothing should be removed, output EXACTLY: NONE\n",
    "                Example: cheese, butter\n",
    "            \n",
    "                If no ingredients should be removed, output: NONE\n",
    "            \n",
    "            RECIPE: \n",
    "            Name: {recipe.name}\n",
    "            Ingredients: {\", \".join(recipe.ingredients)}\n",
    "            Quantities: {recipe.quantity_ingredients}\n",
    "            Steps:\n",
    "            {chr(10).join(recipe.steps)}\n",
    "            \n",
    "            CONSTRAINTS (booleans): {constraints.__dict__}\n",
    "            ANSWER:\n",
    "            DON'T add extra ingredients to remove. Just follow the constraints and be brief.\n",
    "            \"\"\"\n",
    "\n",
    "            prompt_escaped = base_prompt.replace(\"'\", \"''\")\n",
    "\n",
    "            llm_query = f\"\"\"\n",
    "                SELECT SNOWFLAKE.CORTEX.COMPLETE(\n",
    "                    'mixtral-8x7b',\n",
    "                   '{prompt_escaped}'\n",
    "                ) AS INGREDIENTS_TO_REMOVE\n",
    "            \"\"\"\n",
    "            res = self.session.sql(llm_query).collect()\n",
    "            if not res:\n",
    "                return []\n",
    "\n",
    "            response_text = (res[0][\"INGREDIENTS_TO_REMOVE\"] or \"\").strip()\n",
    "            if not response_text or response_text.upper() == \"NONE\":\n",
    "                print(\"LLM: No ingredients to remove\")\n",
    "                return []\n",
    "\n",
    "            # Parse the ingredient list (handle different formats)\n",
    "            ingredients_to_remove = []\n",
    "\n",
    "            # Clean the response from special characters and numbers\n",
    "            cleaned_response = response_text.replace(\"\\n\", \",\").replace(\n",
    "                \";\", \",\"\n",
    "            )\n",
    "\n",
    "            for item in cleaned_response.split(\",\"):\n",
    "                # Clean each item\n",
    "                cleaned_item = item.strip()\n",
    "                if not cleaned_item:\n",
    "                    continue\n",
    "                # Remove leading numbers (e.g., \"1. sugar\" -> \"sugar\")\n",
    "                if cleaned_item[0].isdigit():\n",
    "                    cleaned_item = cleaned_item.lstrip(\"0123456789.-) \").strip()\n",
    "\n",
    "                if len(cleaned_item) > 1:\n",
    "                    # Verify that the ingredient exists in the recipe (fuzzy matching)\n",
    "                    matched = False\n",
    "                    for recipe_ing in recipe.ingredients:\n",
    "                        if (\n",
    "                            cleaned_item.lower() in recipe_ing.lower()\n",
    "                            or recipe_ing.lower() in cleaned_item.lower()\n",
    "                        ):\n",
    "                            if recipe_ing not in ingredients_to_remove:\n",
    "                                ingredients_to_remove.append(recipe_ing)\n",
    "                            matched = True\n",
    "                            break\n",
    "\n",
    "                    if not matched:\n",
    "                        print(\n",
    "                            f\"LLM: Ingredient '{cleaned_item}' not found in recipe\"\n",
    "                        )\n",
    "\n",
    "                if len(ingredients_to_remove) >= 3:\n",
    "                    break\n",
    "            return ingredients_to_remove\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"LLM error for ingredient identification: {e}\")\n",
    "            traceback.print_exc()\n",
    "            return []\n",
    "\n",
    "    def adapt_recipe_with_llm(self, recipe: Recipe, substitutions: Dict) -> str:\n",
    "        \"\"\"\n",
    "        Adapt the recipe steps with substitutions via LLM\n",
    "        \"\"\"\n",
    "\n",
    "        # Building the prompt for the LLM\n",
    "        base_prompt = f\"\"\"You are an expert chef specializing in recipe adaptation and ingredient substitution.\n",
    "\n",
    "        ORIGINAL RECIPE:\n",
    "        Name: {recipe.name}\n",
    "        Ingredients: {recipe.ingredients}\n",
    "        Steps: {recipe.steps}\n",
    "\n",
    "        SUBSTITUTIONS TO APPLY:\n",
    "        \"\"\"\n",
    "\n",
    "        for original, substitute in substitutions.items():\n",
    "            base_prompt += f\"- Replace '{original}' with '{substitute}'\\n\"\n",
    "\n",
    "        base_prompt += \"\"\"\n",
    "        YOUR TASK:\n",
    "        Adapt the recipe steps to incorporate these ingredient substitutions while maintaining the dish's quality and integrity.\n",
    "\n",
    "        ADAPTATION GUIDELINES:\n",
    "        1. Modify ONLY the preparation steps that are affected by the substitutions\n",
    "        2. Preserve the original step numbering and structure\n",
    "        3. Adjust cooking times if the substitute cooks faster/slower than the original\n",
    "        4. Adjust temperatures if the substitute requires different heat levels\n",
    "        5. Note any texture or consistency changes that may occur\n",
    "        6. Suggest technique modifications if needed (e.g., mixing methods, prep techniques)\n",
    "        7. Keep instructions clear, concise, and actionable\n",
    "        8. Maintain the same cooking skill level as the original recipe\n",
    "\n",
    "        IMPORTANT CONSIDERATIONS:\n",
    "        - If a substitution significantly impacts flavor, briefly note it in the step\n",
    "        - If multiple steps use the same ingredient, ensure consistency across all adaptations\n",
    "        - Do not add new steps; only modify existing ones\n",
    "        - Do not change unaffected steps\n",
    "\n",
    "        OUTPUT FORMAT:\n",
    "        Provide only the adapted recipe steps in numbered format.\n",
    "\n",
    "        ADAPTED RECIPE STEPS:\"\"\"\n",
    "\n",
    "        try:\n",
    "            # Échapper les guillemets simples pour éviter les erreurs SQL\n",
    "            prompt_escaped = base_prompt.replace(\"'\", \"''\")\n",
    "\n",
    "            # Construire la requête SQL avec le prompt échappé\n",
    "            llm_query = f\"\"\"\n",
    "                SELECT SNOWFLAKE.CORTEX.COMPLETE(\n",
    "                    'mixtral-8x7b',\n",
    "                   '{prompt_escaped}'\n",
    "                ) AS adapted_steps\n",
    "            \"\"\"\n",
    "\n",
    "            llm_response = self.session.sql(llm_query)\n",
    "            logging.info(f\"LLM response: {llm_response}\")\n",
    "            llm_response = parse_query_result(llm_response)\n",
    "            response_text = llm_response[0][\"ADAPTED_STEPS\"].strip()\n",
    "\n",
    "            # Verification of LLM output format\n",
    "            if not response_text:\n",
    "                print(\"LLM returned an empty response\")\n",
    "                return recipe.steps, []\n",
    "\n",
    "            parsed_steps = response_text.split(\"\\n\")\n",
    "\n",
    "            new_steps = []\n",
    "            notes = []\n",
    "\n",
    "            for step in parsed_steps:\n",
    "                step_cleaned = step.strip()\n",
    "                if not step_cleaned:\n",
    "                    continue\n",
    "\n",
    "                # Check if it's a numbered step (format: \"1.\", \"1)\", or just a digit at the beginning)\n",
    "                if (\n",
    "                    step_cleaned[0].isdigit()\n",
    "                    or step_cleaned.startswith(\"-\")\n",
    "                    or step_cleaned.startswith(\"*\")\n",
    "                ):  # Clean list formats\n",
    "                    cleaned_step = step_cleaned.lstrip(\n",
    "                        \"0123456789.-*) \"\n",
    "                    ).strip()\n",
    "                    if cleaned_step:\n",
    "                        new_steps.append(cleaned_step)\n",
    "                elif step_cleaned.lower().startswith(\"note\"):\n",
    "                    # Extract the note after \"Note:\"\n",
    "                    note_content = step_cleaned.split(\":\", 1)[-1].strip()\n",
    "                    if note_content:\n",
    "                        notes.append(note_content)\n",
    "\n",
    "            # Validation: if no steps were extracted, fallback to original steps\n",
    "            if not new_steps:\n",
    "                print(\"LLM: No valid steps extracted, using original steps\")\n",
    "                return recipe.steps, notes\n",
    "\n",
    "            print(f\"LLM: {len(new_steps)} adapted steps, {len(notes)} notes\")\n",
    "            return new_steps, notes\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(\n",
    "                f\"Failure:  Error found with recipe adaptation steps with substitution transformation made by LLM. Error: {str(e)}. Traceback: {traceback.format_exc()}\"\n",
    "            )\n",
    "            # Fallback: simple manual adaptation\n",
    "            adapted_steps = recipe.steps\n",
    "            adapted_steps = [\n",
    "                step.replace(original, substitute)\n",
    "                for original, substitute in substitutions.items()\n",
    "                for step in adapted_steps\n",
    "            ]\n",
    "            return adapted_steps, []\n",
    "\n",
    "    def adapt_recipe_delete(\n",
    "        self, recipe: Recipe, ingredients_to_delete: List[str]\n",
    "    ) -> Tuple[List[str], List[str]]:\n",
    "        \"\"\"\n",
    "        Adapt the recipe steps by deleting ingredients via LLM.\n",
    "        Returns: (new_steps, notes)\n",
    "        \"\"\"\n",
    "\n",
    "        base_prompt = f\"\"\"You are an expert chef specializing in recipe adaptation for ingredient deletion.\n",
    "        ORIGINAL RECIPE:\n",
    "        Name: {recipe.name}\n",
    "        Ingredients: {recipe.ingredients}\n",
    "        Steps: {recipe.steps}\n",
    "\n",
    "        INGREDIENTS TO REMOVE:\n",
    "        \"\"\"\n",
    "\n",
    "        for ing in ingredients_to_delete:\n",
    "            base_prompt += f\"- Remove '{ing}'\\n\"\n",
    "\n",
    "        base_prompt += \"\"\"\n",
    "        YOUR TASK:\n",
    "        Adapt the recipe steps to REMOVE these ingredients while maintaining the dish's quality and integrity.\n",
    "\n",
    "        ADAPTATION GUIDELINES:\n",
    "        1. Modify ONLY the preparation steps that are affected by the deletions\n",
    "        2. Remove all mentions of the deleted ingredients from the steps\n",
    "        2. Preserve the original step numbering and structure\n",
    "        5. Note any texture or consistency changes that may occur\n",
    "        6. Suggest technique modifications if needed (e.g., mixing methods, prep techniques)\n",
    "        7. Keep instructions clear, concise, and actionable\n",
    "        8. Maintain the same cooking skill level as the original recipe\n",
    "\n",
    "        IMPORTANT CONSIDERATIONS:\n",
    "        - If multiple steps use the same deleted ingredient, ensure consistency across all adaptations\n",
    "        - Do not add new steps; only modify or delete existing ones.\n",
    "        - Do not change unaffected steps\n",
    "        - Do NOT add new ingredients no matter what. Even if the recipe does not seem coherent to you.\n",
    "\n",
    "        OUTPUT FORMAT:\n",
    "        Provide only the adapted recipe steps in numbered format.\n",
    "\n",
    "        ADAPTED RECIPE STEPS:\"\"\"\n",
    "\n",
    "        try:\n",
    "            prompt_escaped = base_prompt.replace(\"'\", \"''\")\n",
    "\n",
    "            llm_query = f\"\"\"\n",
    "                SELECT SNOWFLAKE.CORTEX.COMPLETE(\n",
    "                    'mixtral-8x7b',\n",
    "                   '{prompt_escaped}'\n",
    "                ) AS adapted_steps\n",
    "            \"\"\"\n",
    "\n",
    "            llm_response = self.session.sql(llm_query)\n",
    "            llm_response = parse_query_result(llm_response)\n",
    "            response_text = llm_response[0][\"ADAPTED_STEPS\"].strip()\n",
    "\n",
    "            # Verification of LLM output format\n",
    "            if not response_text:\n",
    "                print(\"LLM returned an empty response -> adapt_recipe_delete\")\n",
    "                return recipe.steps, []\n",
    "\n",
    "            parsed_steps = response_text.split(\"\\n\")\n",
    "\n",
    "            new_steps: List[str] = []\n",
    "            notes: List[str] = []\n",
    "\n",
    "            for step in parsed_steps:\n",
    "                step_cleaned = step.strip()\n",
    "                if not step_cleaned:\n",
    "                    continue\n",
    "\n",
    "                # Check if it's a numbered step\n",
    "\n",
    "                if (\n",
    "                    step_cleaned[0].isdigit()\n",
    "                    or step_cleaned.startswith(\"-\")\n",
    "                    or step_cleaned.startswith(\"*\")\n",
    "                ):  # Clean list formats\n",
    "                    cleaned_step = step_cleaned.lstrip(\n",
    "                        \"0123456789.-*) \"\n",
    "                    ).strip()\n",
    "                    if cleaned_step:\n",
    "                        new_steps.append(cleaned_step)\n",
    "                elif step_cleaned.lower().startswith(\"note\"):\n",
    "                    # Extract the note after \"Note:\"\n",
    "                    note_content = step_cleaned.split(\":\", 1)[-1].strip()\n",
    "                    if note_content:\n",
    "                        notes.append(note_content)\n",
    "\n",
    "            # Validation: if no steps were extracted, fallback to original steps\n",
    "            if not new_steps:\n",
    "                print(\n",
    "                    \"LLM: No valid steps extracted, using original steps -> adapt_recipe_delete\"\n",
    "                )\n",
    "                return recipe.steps, notes\n",
    "\n",
    "            print(f\"LLM: {len(new_steps)} adapted steps, {len(notes)} notes\")\n",
    "            return new_steps, notes\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(\n",
    "                f\"Failure:  Error found with recipe adaptation steps for deletion transformation made by LLM. Error: {str(e)}. Traceback: {traceback.format_exc()}\"\n",
    "            )\n",
    "\n",
    "            # Fallback: naive removal of ingredient words in steps\n",
    "            adapted_steps = list(recipe.steps)\n",
    "            for ing in ingredients_to_delete:\n",
    "                adapted_steps = [\n",
    "                    step.replace(ing, \"\").strip() for step in adapted_steps\n",
    "                ]\n",
    "\n",
    "            return adapted_steps, []\n",
    "\n",
    "    def transform(\n",
    "        self,\n",
    "        recipe: Recipe,\n",
    "        ingredients_to_remove: List[str],\n",
    "        constraints: TransformConstraints,\n",
    "    ) -> TransformResponse:\n",
    "        \"\"\"\n",
    "        Transform a recipe based on constraints and ingredients to remove, full pipeline\n",
    "        \"\"\"\n",
    "        success = True\n",
    "\n",
    "        try:\n",
    "            notes = []\n",
    "            # Step 1: Find ingredient to 'transform' depending on constraints if not received\n",
    "            transformation_type = constraints.transformation\n",
    "            if ingredients_to_remove is not None:\n",
    "                ingredients_to_transform = ingredients_to_remove\n",
    "            else:\n",
    "                # Algorithm in priority to identify ingredients\n",
    "                print(\"Step 1a: Identification by algorithm...\")\n",
    "                ingredients_to_transform = (\n",
    "                    self.identify_ingredients_to_remove_by_algo(\n",
    "                        recipe, constraints\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                # LLM fallback if the algorithm finds nothing\n",
    "                if not ingredients_to_transform:\n",
    "                    print(\"Step 1b: LLM fallback for identification...\")\n",
    "                    ingredients_to_transform = (\n",
    "                        self.identify_ingredients_to_remove_by_llm(\n",
    "                            recipe, constraints\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                if not ingredients_to_transform:\n",
    "                    print(\"No ingredients to transform identified\")\n",
    "                else:\n",
    "                    print(f\"Ingredients identified: {ingredients_to_transform}\")\n",
    "\n",
    "            logging.info(\n",
    "                \"Success: Step 1 finished (Ingredients to remove has been found).\"\n",
    "            )\n",
    "\n",
    "            # Input for whole pipeline\n",
    "            transformations = {}\n",
    "            transformation_count = 0\n",
    "            new_recipe_score = 0.0\n",
    "            # Ingredients to keep from original recipe\n",
    "            base_ingredients = [\n",
    "                ing\n",
    "                for ing in recipe.ingredients\n",
    "                if ing not in ingredients_to_transform\n",
    "            ]\n",
    "\n",
    "            new_recipe = Recipe(\n",
    "                id=recipe.id,\n",
    "                name=recipe.name,\n",
    "                serving_size=recipe.serving_size,\n",
    "                servings=recipe.servings,\n",
    "                health_score=new_recipe_score,\n",
    "                ingredients=base_ingredients,\n",
    "                quantity_ingredients=recipe.quantity_ingredients,\n",
    "                minutes=recipe.minutes,\n",
    "                steps=recipe.steps,\n",
    "            )\n",
    "            new_ingredients = recipe.ingredients  # default value\n",
    "            new_recipe_nutrition = self._zero_nutrition()\n",
    "\n",
    "            # Pipeline diversion based on transformation type\n",
    "            if transformation_type == TransformationType.SUBSTITUTION:\n",
    "                logging.info(\"Substitution: Looking for matched ingredients.\")\n",
    "                # Step 2 : Find substitutes for ingredients to transform, function returns new recipe health score as well.\n",
    "                if self.pca_data is None:\n",
    "                    self.load_pca_data()\n",
    "\n",
    "                # Use cache match when available, otherwise query the database to get matched ingredient\n",
    "                ingredients_to_substitute_matched = [\n",
    "                    ing_dict.get(\"name\")\n",
    "                    for ing_dict in self.get_ingredient_matched(\n",
    "                        ingredients_to_transform\n",
    "                    )\n",
    "                ]\n",
    "\n",
    "                ingredients_to_substitute_matched\n",
    "\n",
    "                logging.info(\"Substitution: Ingredients matched found.\")\n",
    "                logging.info(\n",
    "                    f\"Substitution: Matched ingredients {ingredients_to_substitute_matched}, {type(ingredients_to_substitute_matched)}.\"\n",
    "                )\n",
    "                logging.info(\n",
    "                    f\"Substitution: Base ingredients {base_ingredients}, {type(base_ingredients)}.\"\n",
    "                )\n",
    "                logging.info(\n",
    "                    f\"Substitution: Ingredients to transform {ingredients_to_transform}, {type(ingredients_to_transform)}.\"\n",
    "                )\n",
    "\n",
    "                working_ingredients = list(base_ingredients)\n",
    "                for original_ing, matched_name in zip(\n",
    "                    ingredients_to_transform, ingredients_to_substitute_matched\n",
    "                ):\n",
    "                    logging.info(\n",
    "                        f\"Substitution: Looking for ({original_ing} matched with {matched_name}) substitute candidat.\"\n",
    "                    )\n",
    "                    substitute, was_substituted, new_recipe_nutrition = (\n",
    "                        self.substitute_ingr(\n",
    "                            matched_name,\n",
    "                            constraints,\n",
    "                            working_ingredients,\n",
    "                            recipe.id,\n",
    "                            recipe.serving_size,\n",
    "                            recipe.servings,\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                    if was_substituted:\n",
    "                        logging.info(\n",
    "                            f\"Substitution: Found substitute {substitute} with nutrition {new_recipe_nutrition}.\"\n",
    "                        )\n",
    "                        logging.info(\n",
    "                            f\"Substitution: Updating the new_recipe (ingredients and health score).\"\n",
    "                        )\n",
    "                        transformations[original_ing] = substitute\n",
    "                        transformation_count += 1\n",
    "\n",
    "                        # Update the working ingredient list for the next iteration\n",
    "                        # (replace original_ing if it still exists, otherwise just append substitute)\n",
    "                        if original_ing in working_ingredients:\n",
    "                            working_ingredients = [\n",
    "                                substitute if x == original_ing else x\n",
    "                                for x in working_ingredients\n",
    "                            ]\n",
    "                        else:\n",
    "                            working_ingredients.append(substitute)\n",
    "\n",
    "                        # Apply substitutions to the full recipe ingredient list\n",
    "                        new_ingredients = [\n",
    "                            transformations.get(ingredient, ingredient)\n",
    "                            for ingredient in recipe.ingredients\n",
    "                        ]\n",
    "                        new_recipe.ingredients = new_ingredients\n",
    "\n",
    "                        # Trust the nutrition returned by the last substitute_ingr call (now based on updated working_ingredients)\n",
    "                        new_recipe_score = new_recipe_nutrition.health_score\n",
    "                        new_recipe.health_score = new_recipe_score\n",
    "\n",
    "                logging.info(\n",
    "                    \"Success: Step 2 finished for Substitution (Subtitute ingredients found for eache ingredients to remove).\"\n",
    "                )\n",
    "\n",
    "                # Step 3 : Adapt recipe step with LLM\n",
    "                if transformations:\n",
    "                    new_recipe.steps, notes = self.adapt_recipe_with_llm(\n",
    "                        new_recipe, transformations\n",
    "                    )\n",
    "                logging.info(\n",
    "                    \"Success: Step 3 finished for Substitution (LLM's adapted new_recipe steps successfully).\"\n",
    "                )\n",
    "\n",
    "            elif transformation_type == TransformationType.ADD:\n",
    "                # TODO\n",
    "                pass\n",
    "\n",
    "            elif (\n",
    "                transformation_type == TransformationType.DELETE\n",
    "                and ingredients_to_transform\n",
    "            ):\n",
    "                # Step 2 : Delete ingredients from recipe, calculate health score after deletion\n",
    "                new_recipe_nutrition = self.compute_recipe_nutrition_totals(\n",
    "                    recipe_id=recipe.id,\n",
    "                    ingredients=base_ingredients,\n",
    "                    serving_size=recipe.serving_size,\n",
    "                    servings=recipe.servings,\n",
    "                )\n",
    "                denom = (recipe.serving_size or 0) * (recipe.servings or 0)\n",
    "                if denom > 0:\n",
    "                    scaled_nutrition = self.scale_nutrition(\n",
    "                        new_recipe_nutrition, factor=100.0 / denom\n",
    "                    )\n",
    "                else:\n",
    "                    scaled_nutrition = (\n",
    "                        new_recipe_nutrition  ## fallback servings null\n",
    "                    )\n",
    "                new_recipe_score = self.compute_rhi(scaled_nutrition)\n",
    "                new_recipe_nutrition.health_score = new_recipe_score\n",
    "                logging.info(\n",
    "                    \"Success: Step 2 finished for Deletion (Removed successfully unwanted ingredients and computed new health score).\"\n",
    "                )\n",
    "                # Step 3 : Adapt recipe step with LLM\n",
    "                new_recipe.steps, notes = self.adapt_recipe_delete(\n",
    "                    recipe, ingredients_to_transform\n",
    "                )\n",
    "                logging.info(\n",
    "                    \"Success: Step 3 finished for Deletion (LLM's adapted new_recipe steps successfully).\"\n",
    "                )\n",
    "\n",
    "            # Step 4 : Build output\n",
    "            original_nutrition = self.compute_recipe_nutrition_totals(\n",
    "                recipe_id=recipe.id,\n",
    "                ingredients=recipe.ingredients,\n",
    "                serving_size=recipe.serving_size,\n",
    "                servings=recipe.servings,\n",
    "            )\n",
    "            original_nutrition.health_score = recipe.health_score\n",
    "\n",
    "            logging.info(\n",
    "                \"Success: Step 4 finished (Original recipe health score computing finished).\"\n",
    "            )\n",
    "            response = TransformResponse(\n",
    "                recipe=new_recipe,\n",
    "                original_name=recipe.name,\n",
    "                transformed_name=new_recipe.name,\n",
    "                substitutions=None,\n",
    "                nutrition_before=original_nutrition,\n",
    "                nutrition_after=new_recipe_nutrition,\n",
    "                success=success,\n",
    "                message=\"\\n\".join(notes),\n",
    "            )\n",
    "            logging.info(\n",
    "                \"Success: Step 5 finished (TransformerResponse successfully built, returning it...).\"\n",
    "            )\n",
    "            return response\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(\n",
    "                f\"Failure: Transform function failed. Error: {str(e)}. Traceback: {traceback.format_exc()}\"\n",
    "            )\n",
    "            success = False\n",
    "            response = TransformResponse(\n",
    "                recipe=recipe,\n",
    "                original_name=recipe.name,\n",
    "                transformed_name=recipe.name,\n",
    "                substitutions=None,\n",
    "                nutrition_before=None,\n",
    "                nutrition_after=None,\n",
    "                success=success,\n",
    "                message=None,\n",
    "            )\n",
    "            logging.error(\"Returning default response with input recipe.\")\n",
    "            return response\n",
    "\n",
    "\n",
    "def transform_recipe(session: Session, request: str) -> str:\n",
    "    \"\"\"\n",
    "    Transform endpoint handler - Snowflake Procedure\n",
    "\n",
    "    Args:\n",
    "        session: Snowflake session to execute queries\n",
    "        request: JSON string with TransformRequest structure\n",
    "\n",
    "    Returns:\n",
    "        JSON string with TransformResponse structure\n",
    "    \"\"\"\n",
    "\n",
    "    # Input loading\n",
    "    loaded_request: dict = json.loads(request)\n",
    "    input_recipe: Recipe = Recipe(**loaded_request[\"recipe\"])\n",
    "    input_ingredients_to_remove: List[str] = loaded_request.get(\n",
    "        \"ingredients_to_remove\"\n",
    "    )\n",
    "    input_constraints: TransformConstraints = TransformConstraints(\n",
    "        **loaded_request.get(\"constraints\", {})\n",
    "    )\n",
    "\n",
    "    service = TransformService(session)\n",
    "    # Call transform service\n",
    "    print(\"call service transform\")\n",
    "    output = service.transform(\n",
    "        input_recipe, input_ingredients_to_remove, input_constraints\n",
    "    )\n",
    "\n",
    "    return format_output(to_dict(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f44595",
   "metadata": {},
   "source": [
    "### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "04bde481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "call service transform\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-10 23:57:56,342 - root - INFO - Success: Step 1 finished (Ingredients to remove has been found).\n",
      "2026-01-10 23:57:56,346 - root - INFO - Substitution: Looking for matched ingredients.\n",
      "2026-01-10 23:57:57,977 - root - INFO - Success: PCA ingredients coordinates successfully loaded.\n",
      "2026-01-10 23:57:57,984 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:57:57,985 - snowflake.connector.cursor - INFO - query: [SELECT DISTINCT \"DESCRIP\", \"PROTEIN_G\", \"SATURATED_FATS_G\", \"FAT_G\", \"CARB_G\", \"...]\n",
      "2026-01-10 23:57:57,986 - snowflake.connector.connection - DEBUG - sequence counter: 4\n",
      "2026-01-10 23:57:57,989 - snowflake.connector.cursor - DEBUG - Request id: 469032bd-cbc2-4114-ac9b-1b6d216113d8\n",
      "2026-01-10 23:57:57,998 - snowflake.connector.cursor - DEBUG - running query [SELECT DISTINCT \"DESCRIP\", \"PROTEIN_G\", \"SATURATED_FATS_G\", \"FAT_G\", \"CARB_G\", \"...]\n",
      "2026-01-10 23:57:57,999 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:57:58,001 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:57:58,002 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:57:58,003 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085629272483, 0)\n",
      "2026-01-10 23:57:58,015 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085629272483, 'priority': 0, 'context': {'base64Data': 'COKl94Bw'}}]}\n",
      "2026-01-10 23:57:58,016 - snowflake.connector.connection - DEBUG - sql=[SELECT DISTINCT \"DESCRIP\", \"PROTEIN_G\", \"SATURATED_FATS_G\", \"FAT_G\", \"CARB_G\", \"...], sequence_id=[4], is_file_transfer=[False]\n",
      "2026-01-10 23:57:58,017 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:57:58,019 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:57:58,057 - snowflake.connector.network - DEBUG - Request guid: 4a8c9aa2-f2e0-4572-a2e3-f8e6590a6fe2\n",
      "2026-01-10 23:57:58,061 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:57:58,067 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - Resetting dropped connection: sfedu02-oub04122.snowflakecomputing.com\n",
      "2026-01-10 23:57:58,580 - snowflake.connector.ssl_wrap_socket - DEBUG - OCSP Mode: INSECURE, OCSP response cache file name: None\n",
      "2026-01-10 23:57:58,582 - snowflake.connector.ssl_wrap_socket - INFO - THIS CONNECTION IS IN INSECURE MODE. IT MEANS THE CERTIFICATE WILL BE VALIDATED BUT THE CERTIFICATE REVOCATION STATUS WILL NOT BE CHECKED.\n",
      "2026-01-10 23:57:58,894 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=469032bd-cbc2-4114-ac9b-1b6d216113d8&request_guid=4a8c9aa2-f2e0-4572-a2e3-f8e6590a6fe2 HTTP/1.1\" 200 None\n",
      "2026-01-10 23:57:58,897 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:57:58,898 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:57:58,899 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:57:58,900 - snowflake.connector.network - DEBUG - Query id: 01c1a5c1-0307-73b1-0010-0853008609da\n",
      "2026-01-10 23:57:58,902 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085878857756, 'priority': 0, 'context': 'CMad94Bw'}]}\n",
      "2026-01-10 23:57:58,903 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085629272483, 0)\n",
      "2026-01-10 23:57:58,906 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085878857756, 'priority': 0, 'context': 'CMad94Bw'}\n",
      "2026-01-10 23:57:58,912 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:57:58,919 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:57:58,953 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:57:58,984 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:57:58,986 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085878857756, 0)\n",
      "2026-01-10 23:57:58,998 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c1-0307-73b1-0010-0853008609da\n",
      "2026-01-10 23:57:59,001 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:57:59,003 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:57:59,017 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:57:59,019 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:57:59,023 - snowflake.connector.cursor - INFO - Number of results in first chunk: 24\n",
      "2026-01-10 23:57:59,044 - snowflake.snowpark._internal.server_connection - DEBUG - Execute query [queryID: 01c1a5c1-0307-73b1-0010-0853008609da] \n",
      "            SELECT DISTINCT\n",
      "                \"DESCRIP\",\n",
      "                \"PROTEIN_G\",\n",
      "                \"SATURATED_FATS_G\",\n",
      "                \"FAT_G\",\n",
      "                \"CARB_G\",\n",
      "                \"SODIUM_MG\",\n",
      "                \"FIBER_G\",\n",
      "                \"SUGAR_G\",\n",
      "                \"ENERGY_KCAL\",\n",
      "                \"INGREDIENT_FROM_RECIPE_NAME\" as matched_ingredient\n",
      "            FROM (\n",
      "                SELECT\n",
      "                    ci.\"DESCRIP\",\n",
      "                    ci.\"PROTEIN_G\",\n",
      "                    ci.\"SATURATED_FATS_G\",\n",
      "                    ci.\"FAT_G\",\n",
      "                    ci.\"CARB_G\",\n",
      "                    ci.\"SODIUM_MG\",\n",
      "                    ci.\"FIBER_G\",\n",
      "                    ci.\"SUGAR_G\",\n",
      "                    ci.\"ENERGY_KCAL\",\n",
      "                    ci.\"NDB_NO\",\n",
      "                    im.\"INGREDIENT_FROM_RECIPE_NAME\"\n",
      "                FROM NUTRIRAG_PROJECT.RAW.CLEANED_INGREDIENTS ci\n",
      "                FULL OUTER JOIN NUTRIRAG_PROJECT.RAW.INGREDIENTS_MATCHING im\n",
      "                    ON im.\"INGREDIENT_ID\" = ci.\"NDB_NO\"\n",
      "                WHERE\n",
      "                            (LOWER(ci.\"DESCRIP\") LIKE '%cream cheese%'\n",
      "                    OR LOWER(im.\"INGREDIENT_FROM_RECIPE_NAME\") LIKE '%cream cheese%')\n",
      "            ) AS result\n",
      "            \n",
      "2026-01-10 23:57:59,046 - snowflake.connector.result_batch - DEBUG - Using nanoarrow as the arrow data converter\n",
      "2026-01-10 23:57:59,050 - snowflake.connector.CArrowIterator - DEBUG - Arrow BatchSize: 1\n",
      "2026-01-10 23:57:59,052 - snowflake.connector.CArrowIterator - DEBUG - Arrow chunk info: batchCount 1, columnCount 10, use_numpy: 0\n",
      "2026-01-10 23:57:59,067 - snowflake.connector.nanoarrow_arrow_iterator - DEBUG - Batches read: 0\n",
      "2026-01-10 23:57:59,069 - snowflake.connector.result_set - DEBUG - beginning to schedule result batch downloads\n",
      "2026-01-10 23:57:59,085 - snowflake.connector.CArrowIterator - DEBUG - Current batch index: 0, rows in current batch: 24\n",
      "2026-01-10 23:57:59,098 - root - INFO - Substitution: Ingredients matched found.\n",
      "2026-01-10 23:57:59,102 - root - INFO - Substitution: Matched ingredients ['cheese cream low fat'], <class 'list'>.\n",
      "2026-01-10 23:57:59,114 - root - INFO - Substitution: Base ingredients ['crabmeat', 'green onions', 'garlic salt', 'refrigerated crescent dinner rolls', 'egg yolk', 'water', 'sesame seeds', 'sweet and sour sauce'], <class 'list'>.\n",
      "2026-01-10 23:57:59,119 - root - INFO - Substitution: Ingredients to transform ['cream cheese'], <class 'list'>.\n",
      "2026-01-10 23:57:59,132 - root - INFO - Substitution: Looking for (cream cheese matched with cheese cream low fat) substitute candidat.\n",
      "2026-01-10 23:57:59,184 - root - INFO - Success: Ingredient found: cheese cream low fat → cheese cream low fat\n",
      "2026-01-10 23:57:59,498 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:57:59,499 - snowflake.connector.cursor - INFO - query: [SELECT  *  FROM NUTRIRAG_PROJECT.RAW.INGREDIENTS_QUANTITY]\n",
      "2026-01-10 23:57:59,500 - snowflake.connector.connection - DEBUG - sequence counter: 5\n",
      "2026-01-10 23:57:59,501 - snowflake.connector.cursor - DEBUG - Request id: e0a85aa0-4147-4482-a035-f0f9df801861\n",
      "2026-01-10 23:57:59,502 - snowflake.connector.cursor - DEBUG - running query [SELECT  *  FROM NUTRIRAG_PROJECT.RAW.INGREDIENTS_QUANTITY]\n",
      "2026-01-10 23:57:59,505 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:57:59,506 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:57:59,508 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:57:59,509 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085878857756, 0)\n",
      "2026-01-10 23:57:59,516 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085878857756, 'priority': 0, 'context': {'base64Data': 'CMad94Bw'}}]}\n",
      "2026-01-10 23:57:59,519 - snowflake.connector.connection - DEBUG - sql=[SELECT  *  FROM NUTRIRAG_PROJECT.RAW.INGREDIENTS_QUANTITY], sequence_id=[5], is_file_transfer=[False]\n",
      "2026-01-10 23:57:59,525 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:57:59,533 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:57:59,538 - snowflake.connector.network - DEBUG - Request guid: 2285f47e-ad5f-4176-8e18-f1a6e9c096ca\n",
      "2026-01-10 23:57:59,548 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:57:59,787 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=e0a85aa0-4147-4482-a035-f0f9df801861&request_guid=2285f47e-ad5f-4176-8e18-f1a6e9c096ca HTTP/1.1\" 200 None\n",
      "2026-01-10 23:57:59,794 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:57:59,796 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:57:59,798 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:57:59,800 - snowflake.connector.network - DEBUG - Query id: 01c1a5c1-0307-7294-0010-0853008625fa\n",
      "2026-01-10 23:57:59,801 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085879749649, 'priority': 0, 'context': 'CNKU94Bw'}]}\n",
      "2026-01-10 23:57:59,809 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085878857756, 0)\n",
      "2026-01-10 23:57:59,813 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085879749649, 'priority': 0, 'context': 'CNKU94Bw'}\n",
      "2026-01-10 23:57:59,817 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:57:59,819 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:57:59,831 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:57:59,836 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:57:59,864 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085879749649, 0)\n",
      "2026-01-10 23:57:59,866 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c1-0307-7294-0010-0853008625fa\n",
      "2026-01-10 23:57:59,867 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:57:59,868 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:57:59,869 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:57:59,873 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:57:59,883 - snowflake.connector.cursor - INFO - Number of results in first chunk: 0\n",
      "2026-01-10 23:57:59,899 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:57:59,900 - snowflake.connector.cursor - INFO - query: [SELECT \"INGREDIENTS\", \"QTY_G\" FROM NUTRIRAG_PROJECT.RAW.INGREDIENTS_QUANTITY WHE...]\n",
      "2026-01-10 23:57:59,901 - snowflake.connector.connection - DEBUG - sequence counter: 6\n",
      "2026-01-10 23:57:59,902 - snowflake.connector.cursor - DEBUG - Request id: 0f85cf4e-61d9-4511-af0f-2ab2954902c9\n",
      "2026-01-10 23:57:59,913 - snowflake.connector.cursor - DEBUG - running query [SELECT \"INGREDIENTS\", \"QTY_G\" FROM NUTRIRAG_PROJECT.RAW.INGREDIENTS_QUANTITY WHE...]\n",
      "2026-01-10 23:57:59,916 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:57:59,933 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:57:59,935 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:57:59,938 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085879749649, 0)\n",
      "2026-01-10 23:57:59,945 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085879749649, 'priority': 0, 'context': {'base64Data': 'CNKU94Bw'}}]}\n",
      "2026-01-10 23:57:59,953 - snowflake.connector.connection - DEBUG - sql=[SELECT \"INGREDIENTS\", \"QTY_G\" FROM NUTRIRAG_PROJECT.RAW.INGREDIENTS_QUANTITY WHE...], sequence_id=[6], is_file_transfer=[False]\n",
      "2026-01-10 23:57:59,960 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:57:59,962 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:57:59,967 - snowflake.connector.network - DEBUG - Request guid: a52f995e-6895-475c-94a8-859b2c629130\n",
      "2026-01-10 23:57:59,969 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:58:00,273 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=0f85cf4e-61d9-4511-af0f-2ab2954902c9&request_guid=a52f995e-6895-475c-94a8-859b2c629130 HTTP/1.1\" 200 None\n",
      "2026-01-10 23:58:00,276 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:00,280 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:58:00,282 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:58:00,284 - snowflake.connector.network - DEBUG - Query id: 01c1a5c2-0307-7557-0010-085300861af6\n",
      "2026-01-10 23:58:00,285 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085880233162, 'priority': 0, 'context': 'CN6q94Bw'}]}\n",
      "2026-01-10 23:58:00,295 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085879749649, 0)\n",
      "2026-01-10 23:58:00,297 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085880233162, 'priority': 0, 'context': 'CN6q94Bw'}\n",
      "2026-01-10 23:58:00,303 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:58:00,311 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:00,316 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:00,318 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:58:00,319 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085880233162, 0)\n",
      "2026-01-10 23:58:00,337 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c2-0307-7557-0010-085300861af6\n",
      "2026-01-10 23:58:00,353 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:58:00,356 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:00,358 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:58:00,359 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:58:00,361 - snowflake.connector.cursor - INFO - Number of results in first chunk: 9\n",
      "2026-01-10 23:58:00,373 - snowflake.snowpark._internal.server_connection - DEBUG - Execute query [queryID: 01c1a5c2-0307-7557-0010-085300861af6]  SELECT \"INGREDIENTS\", \"QTY_G\" FROM NUTRIRAG_PROJECT.RAW.INGREDIENTS_QUANTITY WHERE (\"ID\" = 94947 :: INT)\n",
      "2026-01-10 23:58:00,378 - snowflake.connector.result_batch - DEBUG - Using nanoarrow as the arrow data converter\n",
      "2026-01-10 23:58:00,382 - snowflake.connector.CArrowIterator - DEBUG - Arrow BatchSize: 5\n",
      "2026-01-10 23:58:00,384 - snowflake.connector.CArrowIterator - DEBUG - Arrow chunk info: batchCount 5, columnCount 2, use_numpy: 0\n",
      "2026-01-10 23:58:00,386 - snowflake.connector.nanoarrow_arrow_iterator - DEBUG - Batches read: 0\n",
      "2026-01-10 23:58:00,389 - snowflake.connector.result_set - DEBUG - beginning to schedule result batch downloads\n",
      "2026-01-10 23:58:00,403 - snowflake.connector.CArrowIterator - DEBUG - Current batch index: 0, rows in current batch: 1\n",
      "2026-01-10 23:58:00,410 - snowflake.connector.CArrowIterator - DEBUG - Current batch index: 1, rows in current batch: 1\n",
      "2026-01-10 23:58:00,419 - snowflake.connector.CArrowIterator - DEBUG - Current batch index: 2, rows in current batch: 4\n",
      "2026-01-10 23:58:00,423 - snowflake.connector.CArrowIterator - DEBUG - Current batch index: 3, rows in current batch: 1\n",
      "2026-01-10 23:58:00,435 - snowflake.connector.CArrowIterator - DEBUG - Current batch index: 4, rows in current batch: 2\n",
      "2026-01-10 23:58:00,440 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:58:00,450 - snowflake.connector.cursor - INFO - query: [SELECT  *  FROM NUTRIRAG_PROJECT.RAW.INGREDIENTS_MATCHING]\n",
      "2026-01-10 23:58:00,458 - snowflake.connector.connection - DEBUG - sequence counter: 7\n",
      "2026-01-10 23:58:00,473 - snowflake.connector.cursor - DEBUG - Request id: 40700788-1cf6-4054-96af-57bf5df0f26c\n",
      "2026-01-10 23:58:00,482 - snowflake.connector.cursor - DEBUG - running query [SELECT  *  FROM NUTRIRAG_PROJECT.RAW.INGREDIENTS_MATCHING]\n",
      "2026-01-10 23:58:00,486 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:58:00,489 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:58:00,502 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:58:00,507 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085880233162, 0)\n",
      "2026-01-10 23:58:00,518 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085880233162, 'priority': 0, 'context': {'base64Data': 'CN6q94Bw'}}]}\n",
      "2026-01-10 23:58:00,523 - snowflake.connector.connection - DEBUG - sql=[SELECT  *  FROM NUTRIRAG_PROJECT.RAW.INGREDIENTS_MATCHING], sequence_id=[7], is_file_transfer=[False]\n",
      "2026-01-10 23:58:00,535 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:58:00,539 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:58:00,559 - snowflake.connector.network - DEBUG - Request guid: 4d0cfa0d-8848-493c-8b56-6eeeb70e135b\n",
      "2026-01-10 23:58:00,583 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:58:00,832 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=40700788-1cf6-4054-96af-57bf5df0f26c&request_guid=4d0cfa0d-8848-493c-8b56-6eeeb70e135b HTTP/1.1\" 200 None\n",
      "2026-01-10 23:58:00,835 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:00,841 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:58:00,844 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:58:00,850 - snowflake.connector.network - DEBUG - Query id: 01c1a5c2-0307-74b8-0010-085300863222\n",
      "2026-01-10 23:58:00,854 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085880784584, 'priority': 0, 'context': 'COKl94Bw'}]}\n",
      "2026-01-10 23:58:00,866 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085880233162, 0)\n",
      "2026-01-10 23:58:00,868 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085880784584, 'priority': 0, 'context': 'COKl94Bw'}\n",
      "2026-01-10 23:58:00,869 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:58:00,872 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:00,889 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:00,907 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:58:00,916 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085880784584, 0)\n",
      "2026-01-10 23:58:00,921 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c2-0307-74b8-0010-085300863222\n",
      "2026-01-10 23:58:00,932 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:58:00,939 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:00,954 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:58:00,957 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:58:00,970 - snowflake.connector.cursor - INFO - Number of results in first chunk: 0\n",
      "2026-01-10 23:58:00,984 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:58:00,998 - snowflake.connector.cursor - INFO - query: [SELECT \"RECIPE_ID\", \"INGREDIENT_FROM_RECIPE_NAME\", \"INGREDIENT_ID\", lower(trim(\"...]\n",
      "2026-01-10 23:58:01,000 - snowflake.connector.connection - DEBUG - sequence counter: 8\n",
      "2026-01-10 23:58:01,002 - snowflake.connector.cursor - DEBUG - Request id: fc35c9bd-ac21-438d-a97a-869101aa7741\n",
      "2026-01-10 23:58:01,016 - snowflake.connector.cursor - DEBUG - running query [SELECT \"RECIPE_ID\", \"INGREDIENT_FROM_RECIPE_NAME\", \"INGREDIENT_ID\", lower(trim(\"...]\n",
      "2026-01-10 23:58:01,019 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:58:01,020 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:58:01,025 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:58:01,033 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085880784584, 0)\n",
      "2026-01-10 23:58:01,061 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085880784584, 'priority': 0, 'context': {'base64Data': 'COKl94Bw'}}]}\n",
      "2026-01-10 23:58:01,068 - snowflake.connector.connection - DEBUG - sql=[SELECT \"RECIPE_ID\", \"INGREDIENT_FROM_RECIPE_NAME\", \"INGREDIENT_ID\", lower(trim(\"...], sequence_id=[8], is_file_transfer=[False]\n",
      "2026-01-10 23:58:01,072 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:58:01,078 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:58:01,083 - snowflake.connector.network - DEBUG - Request guid: 7bad61c1-0243-4bd6-b0dc-56ee4e3fc6aa\n",
      "2026-01-10 23:58:01,086 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:58:01,345 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=fc35c9bd-ac21-438d-a97a-869101aa7741&request_guid=7bad61c1-0243-4bd6-b0dc-56ee4e3fc6aa HTTP/1.1\" 200 None\n",
      "2026-01-10 23:58:01,348 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:01,351 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:58:01,353 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:58:01,357 - snowflake.connector.network - DEBUG - Query id: 01c1a5c2-0307-7557-0010-085300861afa\n",
      "2026-01-10 23:58:01,367 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085881305639, 'priority': 0, 'context': 'CN6q94Bw'}]}\n",
      "2026-01-10 23:58:01,372 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085880784584, 0)\n",
      "2026-01-10 23:58:01,377 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085881305639, 'priority': 0, 'context': 'CN6q94Bw'}\n",
      "2026-01-10 23:58:01,381 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:58:01,384 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:01,400 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:01,402 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:58:01,411 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085881305639, 0)\n",
      "2026-01-10 23:58:01,415 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c2-0307-7557-0010-085300861afa\n",
      "2026-01-10 23:58:01,418 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:58:01,419 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:01,422 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:58:01,436 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:58:01,438 - snowflake.connector.cursor - INFO - Number of results in first chunk: 0\n",
      "2026-01-10 23:58:01,451 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:58:01,453 - snowflake.connector.cursor - INFO - query: [SELECT  *  FROM NUTRIRAG_PROJECT.RAW.CLEANED_INGREDIENTS]\n",
      "2026-01-10 23:58:01,456 - snowflake.connector.connection - DEBUG - sequence counter: 9\n",
      "2026-01-10 23:58:01,469 - snowflake.connector.cursor - DEBUG - Request id: c0f39bb8-92f6-41d7-9cdc-45c4718a1970\n",
      "2026-01-10 23:58:01,482 - snowflake.connector.cursor - DEBUG - running query [SELECT  *  FROM NUTRIRAG_PROJECT.RAW.CLEANED_INGREDIENTS]\n",
      "2026-01-10 23:58:01,486 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:58:01,490 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:58:01,501 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:58:01,515 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085881305639, 0)\n",
      "2026-01-10 23:58:01,517 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085881305639, 'priority': 0, 'context': {'base64Data': 'CN6q94Bw'}}]}\n",
      "2026-01-10 23:58:01,520 - snowflake.connector.connection - DEBUG - sql=[SELECT  *  FROM NUTRIRAG_PROJECT.RAW.CLEANED_INGREDIENTS], sequence_id=[9], is_file_transfer=[False]\n",
      "2026-01-10 23:58:01,526 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:58:01,532 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:58:01,541 - snowflake.connector.network - DEBUG - Request guid: a0e55abc-5632-4d1e-a26b-68a9d616db8e\n",
      "2026-01-10 23:58:01,549 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:58:01,766 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=c0f39bb8-92f6-41d7-9cdc-45c4718a1970&request_guid=a0e55abc-5632-4d1e-a26b-68a9d616db8e HTTP/1.1\" 200 None\n",
      "2026-01-10 23:58:01,770 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:01,774 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:58:01,777 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:58:01,784 - snowflake.connector.network - DEBUG - Query id: 01c1a5c2-0307-7294-0010-0853008625fe\n",
      "2026-01-10 23:58:01,790 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085881729488, 'priority': 0, 'context': 'CNKU94Bw'}]}\n",
      "2026-01-10 23:58:01,802 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085881305639, 0)\n",
      "2026-01-10 23:58:01,803 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085881729488, 'priority': 0, 'context': 'CNKU94Bw'}\n",
      "2026-01-10 23:58:01,808 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:58:01,819 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:01,821 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:01,824 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:58:01,833 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085881729488, 0)\n",
      "2026-01-10 23:58:01,838 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c2-0307-7294-0010-0853008625fe\n",
      "2026-01-10 23:58:01,841 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:58:01,856 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:01,862 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:58:01,871 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:58:01,875 - snowflake.connector.cursor - INFO - Number of results in first chunk: 0\n",
      "2026-01-10 23:58:01,952 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:58:01,953 - snowflake.connector.cursor - INFO - query: [SELECT \"RECIPE_ID\" AS \"RECIPE_ID\", \"INGREDIENT_FROM_RECIPE_NAME\" AS \"INGREDIENT_...]\n",
      "2026-01-10 23:58:01,958 - snowflake.connector.connection - DEBUG - sequence counter: 10\n",
      "2026-01-10 23:58:01,962 - snowflake.connector.cursor - DEBUG - Request id: f29e2364-81f2-415b-8771-c6b7b8e0c8f9\n",
      "2026-01-10 23:58:01,965 - snowflake.connector.cursor - DEBUG - running query [SELECT \"RECIPE_ID\" AS \"RECIPE_ID\", \"INGREDIENT_FROM_RECIPE_NAME\" AS \"INGREDIENT_...]\n",
      "2026-01-10 23:58:01,966 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:58:01,969 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:58:01,971 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:58:01,974 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085881729488, 0)\n",
      "2026-01-10 23:58:01,975 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085881729488, 'priority': 0, 'context': {'base64Data': 'CNKU94Bw'}}]}\n",
      "2026-01-10 23:58:01,979 - snowflake.connector.connection - DEBUG - sql=[SELECT \"RECIPE_ID\" AS \"RECIPE_ID\", \"INGREDIENT_FROM_RECIPE_NAME\" AS \"INGREDIENT_...], sequence_id=[10], is_file_transfer=[False]\n",
      "2026-01-10 23:58:01,980 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:58:01,983 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:58:01,985 - snowflake.connector.network - DEBUG - Request guid: c8dc0320-bf84-4f51-96a8-8fd4e01a7c79\n",
      "2026-01-10 23:58:01,988 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:58:02,203 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=f29e2364-81f2-415b-8771-c6b7b8e0c8f9&request_guid=c8dc0320-bf84-4f51-96a8-8fd4e01a7c79 HTTP/1.1\" 200 None\n",
      "2026-01-10 23:58:02,206 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:02,209 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:58:02,212 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:58:02,214 - snowflake.connector.network - DEBUG - Query id: 01c1a5c2-0307-7557-0010-085300861afe\n",
      "2026-01-10 23:58:02,218 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085882143654, 'priority': 0, 'context': 'CN6q94Bw'}]}\n",
      "2026-01-10 23:58:02,225 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085881729488, 0)\n",
      "2026-01-10 23:58:02,231 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085882143654, 'priority': 0, 'context': 'CN6q94Bw'}\n",
      "2026-01-10 23:58:02,237 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:58:02,244 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:02,250 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:02,252 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:58:02,268 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085882143654, 0)\n",
      "2026-01-10 23:58:02,270 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c2-0307-7557-0010-085300861afe\n",
      "2026-01-10 23:58:02,278 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:58:02,289 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:02,292 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:58:02,295 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:58:02,298 - snowflake.connector.cursor - INFO - Number of results in first chunk: 0\n",
      "2026-01-10 23:58:02,300 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:58:02,303 - snowflake.connector.cursor - INFO - query: [SELECT \"NDB_NO\" AS \"NDB_NO\", \"DESCRIP\" AS \"DESCRIP\", \"ENERGY_KCAL\" AS \"ENERGY_KC...]\n",
      "2026-01-10 23:58:02,313 - snowflake.connector.connection - DEBUG - sequence counter: 11\n",
      "2026-01-10 23:58:02,315 - snowflake.connector.cursor - DEBUG - Request id: b2dc7481-2982-4489-9595-78fbe21cc876\n",
      "2026-01-10 23:58:02,316 - snowflake.connector.cursor - DEBUG - running query [SELECT \"NDB_NO\" AS \"NDB_NO\", \"DESCRIP\" AS \"DESCRIP\", \"ENERGY_KCAL\" AS \"ENERGY_KC...]\n",
      "2026-01-10 23:58:02,324 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:58:02,327 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:58:02,329 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:58:02,331 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085882143654, 0)\n",
      "2026-01-10 23:58:02,334 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085882143654, 'priority': 0, 'context': {'base64Data': 'CN6q94Bw'}}]}\n",
      "2026-01-10 23:58:02,335 - snowflake.connector.connection - DEBUG - sql=[SELECT \"NDB_NO\" AS \"NDB_NO\", \"DESCRIP\" AS \"DESCRIP\", \"ENERGY_KCAL\" AS \"ENERGY_KC...], sequence_id=[11], is_file_transfer=[False]\n",
      "2026-01-10 23:58:02,337 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:58:02,340 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:58:02,342 - snowflake.connector.network - DEBUG - Request guid: 5142ef61-2a9c-4b90-9ba7-1a3b1c73df9e\n",
      "2026-01-10 23:58:02,347 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:58:02,569 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=b2dc7481-2982-4489-9595-78fbe21cc876&request_guid=5142ef61-2a9c-4b90-9ba7-1a3b1c73df9e HTTP/1.1\" 200 None\n",
      "2026-01-10 23:58:02,577 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:02,582 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:58:02,583 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:58:02,592 - snowflake.connector.network - DEBUG - Query id: 01c1a5c2-0307-74b8-0010-085300863226\n",
      "2026-01-10 23:58:02,601 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085882528795, 'priority': 0, 'context': 'COKl94Bw'}]}\n",
      "2026-01-10 23:58:02,614 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085882143654, 0)\n",
      "2026-01-10 23:58:02,619 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085882528795, 'priority': 0, 'context': 'COKl94Bw'}\n",
      "2026-01-10 23:58:02,633 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:58:02,637 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:02,651 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:02,658 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:58:02,664 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085882528795, 0)\n",
      "2026-01-10 23:58:02,669 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c2-0307-74b8-0010-085300863226\n",
      "2026-01-10 23:58:02,686 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:58:02,701 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:02,703 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:58:02,716 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:58:02,718 - snowflake.connector.cursor - INFO - Number of results in first chunk: 0\n",
      "2026-01-10 23:58:02,726 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:58:02,736 - snowflake.connector.cursor - INFO - query: [SELECT  *  FROM (( SELECT NULL :: BIGINT AS \"RECIPE_ID\", NULL :: STRING(16777216...]\n",
      "2026-01-10 23:58:02,785 - snowflake.connector.connection - DEBUG - sequence counter: 12\n",
      "2026-01-10 23:58:02,801 - snowflake.connector.cursor - DEBUG - Request id: 165d153b-2353-447e-93a6-888a83a26608\n",
      "2026-01-10 23:58:02,802 - snowflake.connector.cursor - DEBUG - running query [SELECT  *  FROM (( SELECT NULL :: BIGINT AS \"RECIPE_ID\", NULL :: STRING(16777216...]\n",
      "2026-01-10 23:58:02,806 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:58:02,808 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:58:02,811 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:58:02,819 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085882528795, 0)\n",
      "2026-01-10 23:58:02,831 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085882528795, 'priority': 0, 'context': {'base64Data': 'COKl94Bw'}}]}\n",
      "2026-01-10 23:58:02,836 - snowflake.connector.connection - DEBUG - sql=[SELECT  *  FROM (( SELECT NULL :: BIGINT AS \"RECIPE_ID\", NULL :: STRING(16777216...], sequence_id=[12], is_file_transfer=[False]\n",
      "2026-01-10 23:58:02,849 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:58:02,855 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:58:02,866 - snowflake.connector.network - DEBUG - Request guid: 30f76869-8c90-48d7-8591-c6c4b7e5fd0d\n",
      "2026-01-10 23:58:02,874 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:58:03,090 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=165d153b-2353-447e-93a6-888a83a26608&request_guid=30f76869-8c90-48d7-8591-c6c4b7e5fd0d HTTP/1.1\" 200 None\n",
      "2026-01-10 23:58:03,103 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:03,106 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:58:03,107 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:58:03,116 - snowflake.connector.network - DEBUG - Query id: 01c1a5c2-0307-7294-0010-085300862602\n",
      "2026-01-10 23:58:03,119 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085883052328, 'priority': 0, 'context': 'CNKU94Bw'}]}\n",
      "2026-01-10 23:58:03,132 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085882528795, 0)\n",
      "2026-01-10 23:58:03,137 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085883052328, 'priority': 0, 'context': 'CNKU94Bw'}\n",
      "2026-01-10 23:58:03,144 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:58:03,145 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:03,149 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:03,152 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:58:03,171 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085883052328, 0)\n",
      "2026-01-10 23:58:03,214 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c2-0307-7294-0010-085300862602\n",
      "2026-01-10 23:58:03,219 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:58:03,234 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:03,235 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:58:03,241 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:58:03,256 - snowflake.connector.cursor - INFO - Number of results in first chunk: 0\n",
      "2026-01-10 23:58:03,290 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:58:03,303 - snowflake.connector.cursor - INFO - query: [SELECT \"ING_KEY\", \"ENERGY_KCAL\", \"PROTEIN_G\", \"FAT_G\", \"SATURATED_FATS_G\", \"CARB...]\n",
      "2026-01-10 23:58:03,313 - snowflake.connector.connection - DEBUG - sequence counter: 13\n",
      "2026-01-10 23:58:03,328 - snowflake.connector.cursor - DEBUG - Request id: 5ff290f8-68aa-43c5-bdb0-f0cad654b69f\n",
      "2026-01-10 23:58:03,349 - snowflake.connector.cursor - DEBUG - running query [SELECT \"ING_KEY\", \"ENERGY_KCAL\", \"PROTEIN_G\", \"FAT_G\", \"SATURATED_FATS_G\", \"CARB...]\n",
      "2026-01-10 23:58:03,352 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:58:03,353 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:58:03,391 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:58:03,401 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085883052328, 0)\n",
      "2026-01-10 23:58:03,403 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085883052328, 'priority': 0, 'context': {'base64Data': 'CNKU94Bw'}}]}\n",
      "2026-01-10 23:58:03,406 - snowflake.connector.connection - DEBUG - sql=[SELECT \"ING_KEY\", \"ENERGY_KCAL\", \"PROTEIN_G\", \"FAT_G\", \"SATURATED_FATS_G\", \"CARB...], sequence_id=[13], is_file_transfer=[False]\n",
      "2026-01-10 23:58:03,420 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:58:03,424 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:58:03,438 - snowflake.connector.network - DEBUG - Request guid: 1a570f43-f798-4876-8430-a3af8dfa0bea\n",
      "2026-01-10 23:58:03,454 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:58:03,693 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=5ff290f8-68aa-43c5-bdb0-f0cad654b69f&request_guid=1a570f43-f798-4876-8430-a3af8dfa0bea HTTP/1.1\" 200 None\n",
      "2026-01-10 23:58:03,700 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:03,702 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:58:03,703 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:58:03,706 - snowflake.connector.network - DEBUG - Query id: 01c1a5c2-0307-73b1-0010-0853008609de\n",
      "2026-01-10 23:58:03,707 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085883652797, 'priority': 0, 'context': 'CMad94Bw'}]}\n",
      "2026-01-10 23:58:03,709 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085883052328, 0)\n",
      "2026-01-10 23:58:03,717 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085883652797, 'priority': 0, 'context': 'CMad94Bw'}\n",
      "2026-01-10 23:58:03,747 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:58:03,749 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:03,750 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:03,752 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:58:03,753 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085883652797, 0)\n",
      "2026-01-10 23:58:03,758 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c2-0307-73b1-0010-0853008609de\n",
      "2026-01-10 23:58:03,759 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:58:03,767 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:03,779 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:58:03,785 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:58:03,787 - snowflake.connector.cursor - INFO - Number of results in first chunk: 0\n",
      "2026-01-10 23:58:03,819 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:58:03,822 - snowflake.connector.cursor - INFO - query: [SELECT \"ING_KEY\", \"ENERGY_KCAL\", \"PROTEIN_G\", \"FAT_G\", \"SATURATED_FATS_G\", \"CARB...]\n",
      "2026-01-10 23:58:03,824 - snowflake.connector.connection - DEBUG - sequence counter: 14\n",
      "2026-01-10 23:58:03,829 - snowflake.connector.cursor - DEBUG - Request id: e5426512-379c-4a20-b088-4cbcb295275f\n",
      "2026-01-10 23:58:03,832 - snowflake.connector.cursor - DEBUG - running query [SELECT \"ING_KEY\", \"ENERGY_KCAL\", \"PROTEIN_G\", \"FAT_G\", \"SATURATED_FATS_G\", \"CARB...]\n",
      "2026-01-10 23:58:03,864 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:58:03,869 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:58:03,935 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:58:04,024 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085883652797, 0)\n",
      "2026-01-10 23:58:04,027 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085883652797, 'priority': 0, 'context': {'base64Data': 'CMad94Bw'}}]}\n",
      "2026-01-10 23:58:04,030 - snowflake.connector.connection - DEBUG - sql=[SELECT \"ING_KEY\", \"ENERGY_KCAL\", \"PROTEIN_G\", \"FAT_G\", \"SATURATED_FATS_G\", \"CARB...], sequence_id=[14], is_file_transfer=[False]\n",
      "2026-01-10 23:58:04,032 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:58:04,041 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:58:04,049 - snowflake.connector.network - DEBUG - Request guid: 6249367f-2aa2-45a2-b068-fdb9ac3978ad\n",
      "2026-01-10 23:58:04,091 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:58:04,335 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=e5426512-379c-4a20-b088-4cbcb295275f&request_guid=6249367f-2aa2-45a2-b068-fdb9ac3978ad HTTP/1.1\" 200 None\n",
      "2026-01-10 23:58:04,346 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:04,348 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:58:04,350 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:58:04,351 - snowflake.connector.network - DEBUG - Query id: 01c1a5c2-0307-7294-0010-085300862606\n",
      "2026-01-10 23:58:04,352 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085884290452, 'priority': 0, 'context': 'CNKU94Bw'}]}\n",
      "2026-01-10 23:58:04,353 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085883652797, 0)\n",
      "2026-01-10 23:58:04,358 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085884290452, 'priority': 0, 'context': 'CNKU94Bw'}\n",
      "2026-01-10 23:58:04,408 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:58:04,417 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:04,452 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:04,453 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:58:04,487 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085884290452, 0)\n",
      "2026-01-10 23:58:04,502 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c2-0307-7294-0010-085300862606\n",
      "2026-01-10 23:58:04,521 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:58:04,528 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:04,535 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:58:04,540 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:58:04,551 - snowflake.connector.cursor - INFO - Number of results in first chunk: 0\n",
      "2026-01-10 23:58:04,553 - snowflake.snowpark._internal.server_connection - DEBUG - Execute query [queryID: 01c1a5c2-0307-7294-0010-085300862606]  SELECT \"ING_KEY\", \"ENERGY_KCAL\", \"PROTEIN_G\", \"FAT_G\", \"SATURATED_FATS_G\", \"CARB_G\", \"FIBER_G\", \"SUGAR_G\", \"SODIUM_MG\", \"CALCIUM_MG\", \"IRON_MG\", \"MAGNESIUM_MG\", \"POTASSIUM_MG\", \"VITC_MG\" FROM ( SELECT \"ING_KEY\", \"ENERGY_KCAL\", \"PROTEIN_G\", \"FAT_G\", \"SATURATED_FATS_G\", \"CARB_G\", \"FIBER_G\", \"SUGAR_G\", \"SODIUM_MG\", \"CALCIUM_MG\", \"IRON_MG\", \"MAGNESIUM_MG\", \"POTASSIUM_MG\", \"VITC_MG\", \"SCORE_SANTE\", row_number() OVER (PARTITION BY \"ING_KEY\"  ORDER BY \"SCORE_SANTE\" DESC NULLS LAST ) AS \"RN\" FROM ( SELECT  *  FROM (( SELECT \"RECIPE_ID\" AS \"RECIPE_ID\", \"INGREDIENT_FROM_RECIPE_NAME\" AS \"INGREDIENT_FROM_RECIPE_NAME\", \"INGREDIENT_ID\" AS \"INGREDIENT_ID\", \"ING_KEY\" AS \"ING_KEY\" FROM ( SELECT \"RECIPE_ID\", \"INGREDIENT_FROM_RECIPE_NAME\", \"INGREDIENT_ID\", lower(trim(\"INGREDIENT_FROM_RECIPE_NAME\")) AS \"ING_KEY\" FROM NUTRIRAG_PROJECT.RAW.INGREDIENTS_MATCHING WHERE (\"RECIPE_ID\" = 94947 :: INT)) WHERE \"ING_KEY\" IN ('crabmeat', 'egg yolk', 'garlic salt', 'green onions', 'refrigerated crescent dinner rolls', 'sandwich spread pork beef', 'sesame seeds', 'sweet and sour sauce', 'water')) AS SNOWPARK_LEFT LEFT OUTER JOIN ( SELECT \"NDB_NO\" AS \"NDB_NO\", \"DESCRIP\" AS \"DESCRIP\", \"ENERGY_KCAL\" AS \"ENERGY_KCAL\", \"PROTEIN_G\" AS \"PROTEIN_G\", \"SATURATED_FATS_G\" AS \"SATURATED_FATS_G\", \"FAT_G\" AS \"FAT_G\", \"CARB_G\" AS \"CARB_G\", \"FIBER_G\" AS \"FIBER_G\", \"SUGAR_G\" AS \"SUGAR_G\", \"CALCIUM_MG\" AS \"CALCIUM_MG\", \"IRON_MG\" AS \"IRON_MG\", \"PHOSPHORUS_MG\" AS \"PHOSPHORUS_MG\", \"POTASSIUM_MG\" AS \"POTASSIUM_MG\", \"SODIUM_MG\" AS \"SODIUM_MG\", \"ZINC_MG\" AS \"ZINC_MG\", \"COPPER_MCG\" AS \"COPPER_MCG\", \"MANGANESE_MG\" AS \"MANGANESE_MG\", \"SELENIUM_MCG\" AS \"SELENIUM_MCG\", \"VITC_MG\" AS \"VITC_MG\", \"THIAMIN_MG\" AS \"THIAMIN_MG\", \"RIBOFLAVIN_MG\" AS \"RIBOFLAVIN_MG\", \"NIACIN_MG\" AS \"NIACIN_MG\", \"VITB6_MG\" AS \"VITB6_MG\", \"FOLATE_MCG\" AS \"FOLATE_MCG\", \"VITB12_MCG\" AS \"VITB12_MCG\", \"VITA_MCG\" AS \"VITA_MCG\", \"MAGNESIUM_MG\" AS \"MAGNESIUM_MG\", \"SCORE_SANTE\" AS \"SCORE_SANTE\" FROM NUTRIRAG_PROJECT.RAW.CLEANED_INGREDIENTS) AS SNOWPARK_RIGHT ON (\"INGREDIENT_ID\" = \"NDB_NO\")))) WHERE (\"RN\" = 1 :: INT)\n",
      "2026-01-10 23:58:04,563 - snowflake.connector.result_set - DEBUG - beginning to schedule result batch downloads\n",
      "2026-01-10 23:58:04,568 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:58:04,576 - snowflake.connector.cursor - INFO - query: [SELECT  *  FROM NUTRIRAG_PROJECT.RAW.INGREDIENTS_MATCHING]\n",
      "2026-01-10 23:58:04,585 - snowflake.connector.connection - DEBUG - sequence counter: 15\n",
      "2026-01-10 23:58:04,590 - snowflake.connector.cursor - DEBUG - Request id: 807c37b3-439f-4845-a3b0-6d0b6e61fffe\n",
      "2026-01-10 23:58:04,600 - snowflake.connector.cursor - DEBUG - running query [SELECT  *  FROM NUTRIRAG_PROJECT.RAW.INGREDIENTS_MATCHING]\n",
      "2026-01-10 23:58:04,604 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:58:04,610 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:58:04,615 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:58:04,618 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085884290452, 0)\n",
      "2026-01-10 23:58:04,623 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085884290452, 'priority': 0, 'context': {'base64Data': 'CNKU94Bw'}}]}\n",
      "2026-01-10 23:58:04,626 - snowflake.connector.connection - DEBUG - sql=[SELECT  *  FROM NUTRIRAG_PROJECT.RAW.INGREDIENTS_MATCHING], sequence_id=[15], is_file_transfer=[False]\n",
      "2026-01-10 23:58:04,634 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:58:04,645 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:58:04,648 - snowflake.connector.network - DEBUG - Request guid: 3a665165-fa37-4ce0-ab48-a411c14a3c47\n",
      "2026-01-10 23:58:04,651 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:58:04,873 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=807c37b3-439f-4845-a3b0-6d0b6e61fffe&request_guid=3a665165-fa37-4ce0-ab48-a411c14a3c47 HTTP/1.1\" 200 None\n",
      "2026-01-10 23:58:04,876 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:04,880 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:58:04,882 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:58:04,883 - snowflake.connector.network - DEBUG - Query id: 01c1a5c2-0307-73b1-0010-0853008609e2\n",
      "2026-01-10 23:58:04,885 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085884823330, 'priority': 0, 'context': 'CMad94Bw'}]}\n",
      "2026-01-10 23:58:04,887 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085884290452, 0)\n",
      "2026-01-10 23:58:04,917 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085884823330, 'priority': 0, 'context': 'CMad94Bw'}\n",
      "2026-01-10 23:58:04,918 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:58:04,920 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:04,924 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:04,926 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:58:04,928 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085884823330, 0)\n",
      "2026-01-10 23:58:04,937 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c2-0307-73b1-0010-0853008609e2\n",
      "2026-01-10 23:58:04,946 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:58:04,952 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:04,955 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:58:04,959 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:58:04,983 - snowflake.connector.cursor - INFO - Number of results in first chunk: 0\n",
      "2026-01-10 23:58:05,002 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:58:05,010 - snowflake.connector.cursor - INFO - query: [SELECT \"RECIPE_ID\", \"INGREDIENT_FROM_RECIPE_NAME\", \"INGREDIENT_ID\", lower(trim(\"...]\n",
      "2026-01-10 23:58:05,012 - snowflake.connector.connection - DEBUG - sequence counter: 16\n",
      "2026-01-10 23:58:05,015 - snowflake.connector.cursor - DEBUG - Request id: d0225433-3dc3-4d5d-92ad-2b2f65c6d8d7\n",
      "2026-01-10 23:58:05,016 - snowflake.connector.cursor - DEBUG - running query [SELECT \"RECIPE_ID\", \"INGREDIENT_FROM_RECIPE_NAME\", \"INGREDIENT_ID\", lower(trim(\"...]\n",
      "2026-01-10 23:58:05,018 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:58:05,024 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:58:05,055 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:58:05,057 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085884823330, 0)\n",
      "2026-01-10 23:58:05,063 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085884823330, 'priority': 0, 'context': {'base64Data': 'CMad94Bw'}}]}\n",
      "2026-01-10 23:58:05,067 - snowflake.connector.connection - DEBUG - sql=[SELECT \"RECIPE_ID\", \"INGREDIENT_FROM_RECIPE_NAME\", \"INGREDIENT_ID\", lower(trim(\"...], sequence_id=[16], is_file_transfer=[False]\n",
      "2026-01-10 23:58:05,122 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:58:05,155 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:58:05,185 - snowflake.connector.network - DEBUG - Request guid: f3b92a39-9635-42d4-99f0-bb441c03368d\n",
      "2026-01-10 23:58:05,187 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:58:05,413 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=d0225433-3dc3-4d5d-92ad-2b2f65c6d8d7&request_guid=f3b92a39-9635-42d4-99f0-bb441c03368d HTTP/1.1\" 200 None\n",
      "2026-01-10 23:58:05,424 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:05,426 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:58:05,434 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:58:05,453 - snowflake.connector.network - DEBUG - Query id: 01c1a5c2-0307-73b1-0010-0853008609e6\n",
      "2026-01-10 23:58:05,466 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085885340332, 'priority': 0, 'context': 'CMad94Bw'}]}\n",
      "2026-01-10 23:58:05,534 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085884823330, 0)\n",
      "2026-01-10 23:58:05,575 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085885340332, 'priority': 0, 'context': 'CMad94Bw'}\n",
      "2026-01-10 23:58:05,582 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:58:05,591 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:05,595 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:05,600 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:58:05,603 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085885340332, 0)\n",
      "2026-01-10 23:58:05,606 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c2-0307-73b1-0010-0853008609e6\n",
      "2026-01-10 23:58:05,608 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:58:05,612 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:05,620 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:58:05,628 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:58:05,638 - snowflake.connector.cursor - INFO - Number of results in first chunk: 0\n",
      "2026-01-10 23:58:05,646 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:58:05,652 - snowflake.connector.cursor - INFO - query: [SELECT  *  FROM NUTRIRAG_PROJECT.RAW.CLEANED_INGREDIENTS]\n",
      "2026-01-10 23:58:05,656 - snowflake.connector.connection - DEBUG - sequence counter: 17\n",
      "2026-01-10 23:58:05,658 - snowflake.connector.cursor - DEBUG - Request id: 28b64b5d-7876-4d13-ab7c-e4b5848f5b8a\n",
      "2026-01-10 23:58:05,660 - snowflake.connector.cursor - DEBUG - running query [SELECT  *  FROM NUTRIRAG_PROJECT.RAW.CLEANED_INGREDIENTS]\n",
      "2026-01-10 23:58:05,665 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:58:05,672 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:58:05,677 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:58:05,680 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085885340332, 0)\n",
      "2026-01-10 23:58:05,684 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085885340332, 'priority': 0, 'context': {'base64Data': 'CMad94Bw'}}]}\n",
      "2026-01-10 23:58:05,691 - snowflake.connector.connection - DEBUG - sql=[SELECT  *  FROM NUTRIRAG_PROJECT.RAW.CLEANED_INGREDIENTS], sequence_id=[17], is_file_transfer=[False]\n",
      "2026-01-10 23:58:05,696 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:58:05,726 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:58:05,731 - snowflake.connector.network - DEBUG - Request guid: 95120055-6b18-4e71-99ae-ac9e44e97f38\n",
      "2026-01-10 23:58:05,736 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:58:06,012 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=28b64b5d-7876-4d13-ab7c-e4b5848f5b8a&request_guid=95120055-6b18-4e71-99ae-ac9e44e97f38 HTTP/1.1\" 200 None\n",
      "2026-01-10 23:58:06,017 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:06,019 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:58:06,024 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:58:06,042 - snowflake.connector.network - DEBUG - Query id: 01c1a5c2-0307-7557-0010-085300861b06\n",
      "2026-01-10 23:58:06,051 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085885949375, 'priority': 0, 'context': 'CN6q94Bw'}]}\n",
      "2026-01-10 23:58:06,052 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085885340332, 0)\n",
      "2026-01-10 23:58:06,053 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085885949375, 'priority': 0, 'context': 'CN6q94Bw'}\n",
      "2026-01-10 23:58:06,059 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:58:06,060 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:06,078 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:06,099 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:58:06,100 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085885949375, 0)\n",
      "2026-01-10 23:58:06,103 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c2-0307-7557-0010-085300861b06\n",
      "2026-01-10 23:58:06,158 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:58:06,163 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:06,166 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:58:06,176 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:58:06,180 - snowflake.connector.cursor - INFO - Number of results in first chunk: 0\n",
      "2026-01-10 23:58:06,193 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:58:06,197 - snowflake.connector.cursor - INFO - query: [SELECT \"RECIPE_ID\" AS \"RECIPE_ID\", \"INGREDIENT_FROM_RECIPE_NAME\" AS \"INGREDIENT_...]\n",
      "2026-01-10 23:58:06,236 - snowflake.connector.connection - DEBUG - sequence counter: 18\n",
      "2026-01-10 23:58:06,268 - snowflake.connector.cursor - DEBUG - Request id: d88a418b-1ce6-45f0-870e-08e1e873caed\n",
      "2026-01-10 23:58:06,287 - snowflake.connector.cursor - DEBUG - running query [SELECT \"RECIPE_ID\" AS \"RECIPE_ID\", \"INGREDIENT_FROM_RECIPE_NAME\" AS \"INGREDIENT_...]\n",
      "2026-01-10 23:58:06,296 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:58:06,302 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:58:06,321 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:58:06,324 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085885949375, 0)\n",
      "2026-01-10 23:58:06,346 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085885949375, 'priority': 0, 'context': {'base64Data': 'CN6q94Bw'}}]}\n",
      "2026-01-10 23:58:06,387 - snowflake.connector.connection - DEBUG - sql=[SELECT \"RECIPE_ID\" AS \"RECIPE_ID\", \"INGREDIENT_FROM_RECIPE_NAME\" AS \"INGREDIENT_...], sequence_id=[18], is_file_transfer=[False]\n",
      "2026-01-10 23:58:06,388 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:58:06,398 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:58:06,404 - snowflake.connector.network - DEBUG - Request guid: 74d1e0d0-01f8-4fe7-bfa8-b0e6d78e1423\n",
      "2026-01-10 23:58:06,449 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:58:06,649 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=d88a418b-1ce6-45f0-870e-08e1e873caed&request_guid=74d1e0d0-01f8-4fe7-bfa8-b0e6d78e1423 HTTP/1.1\" 200 None\n",
      "2026-01-10 23:58:06,652 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:06,657 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:58:06,661 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:58:06,663 - snowflake.connector.network - DEBUG - Query id: 01c1a5c2-0307-7294-0010-08530086260a\n",
      "2026-01-10 23:58:06,668 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085886611979, 'priority': 0, 'context': 'CNKU94Bw'}]}\n",
      "2026-01-10 23:58:06,672 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085885949375, 0)\n",
      "2026-01-10 23:58:06,675 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085886611979, 'priority': 0, 'context': 'CNKU94Bw'}\n",
      "2026-01-10 23:58:06,702 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:58:06,705 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:06,707 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:06,709 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:58:06,715 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085886611979, 0)\n",
      "2026-01-10 23:58:06,717 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c2-0307-7294-0010-08530086260a\n",
      "2026-01-10 23:58:06,719 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:58:06,723 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:06,726 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:58:06,730 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:58:06,731 - snowflake.connector.cursor - INFO - Number of results in first chunk: 0\n",
      "2026-01-10 23:58:06,734 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:58:06,735 - snowflake.connector.cursor - INFO - query: [SELECT \"NDB_NO\" AS \"NDB_NO\", \"DESCRIP\" AS \"DESCRIP\", \"ENERGY_KCAL\" AS \"ENERGY_KC...]\n",
      "2026-01-10 23:58:06,739 - snowflake.connector.connection - DEBUG - sequence counter: 19\n",
      "2026-01-10 23:58:06,740 - snowflake.connector.cursor - DEBUG - Request id: 89489796-71f8-42a0-8223-278092a95d73\n",
      "2026-01-10 23:58:06,742 - snowflake.connector.cursor - DEBUG - running query [SELECT \"NDB_NO\" AS \"NDB_NO\", \"DESCRIP\" AS \"DESCRIP\", \"ENERGY_KCAL\" AS \"ENERGY_KC...]\n",
      "2026-01-10 23:58:06,744 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:58:06,747 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:58:06,749 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:58:06,754 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085886611979, 0)\n",
      "2026-01-10 23:58:06,756 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085886611979, 'priority': 0, 'context': {'base64Data': 'CNKU94Bw'}}]}\n",
      "2026-01-10 23:58:06,758 - snowflake.connector.connection - DEBUG - sql=[SELECT \"NDB_NO\" AS \"NDB_NO\", \"DESCRIP\" AS \"DESCRIP\", \"ENERGY_KCAL\" AS \"ENERGY_KC...], sequence_id=[19], is_file_transfer=[False]\n",
      "2026-01-10 23:58:06,762 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:58:06,764 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:58:06,767 - snowflake.connector.network - DEBUG - Request guid: 1d444e17-deec-4288-93f8-895b7ad8264a\n",
      "2026-01-10 23:58:06,770 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:58:06,964 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=89489796-71f8-42a0-8223-278092a95d73&request_guid=1d444e17-deec-4288-93f8-895b7ad8264a HTTP/1.1\" 200 None\n",
      "2026-01-10 23:58:06,968 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:06,970 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:58:06,972 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:58:06,975 - snowflake.connector.network - DEBUG - Query id: 01c1a5c2-0307-7557-0010-085300861b0a\n",
      "2026-01-10 23:58:06,978 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085886922224, 'priority': 0, 'context': 'CN6q94Bw'}]}\n",
      "2026-01-10 23:58:06,981 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085886611979, 0)\n",
      "2026-01-10 23:58:06,985 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085886922224, 'priority': 0, 'context': 'CN6q94Bw'}\n",
      "2026-01-10 23:58:06,989 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:58:06,993 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:06,996 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:06,999 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:58:07,004 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085886922224, 0)\n",
      "2026-01-10 23:58:07,042 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c2-0307-7557-0010-085300861b0a\n",
      "2026-01-10 23:58:07,048 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:58:07,051 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:07,059 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:58:07,068 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:58:07,077 - snowflake.connector.cursor - INFO - Number of results in first chunk: 0\n",
      "2026-01-10 23:58:07,090 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:58:07,093 - snowflake.connector.cursor - INFO - query: [SELECT  *  FROM (( SELECT NULL :: BIGINT AS \"RECIPE_ID\", NULL :: STRING(16777216...]\n",
      "2026-01-10 23:58:07,098 - snowflake.connector.connection - DEBUG - sequence counter: 20\n",
      "2026-01-10 23:58:07,101 - snowflake.connector.cursor - DEBUG - Request id: 7e0f07aa-7c73-4b20-b028-6fe22f6e42a7\n",
      "2026-01-10 23:58:07,103 - snowflake.connector.cursor - DEBUG - running query [SELECT  *  FROM (( SELECT NULL :: BIGINT AS \"RECIPE_ID\", NULL :: STRING(16777216...]\n",
      "2026-01-10 23:58:07,110 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:58:07,115 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:58:07,119 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:58:07,122 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085886922224, 0)\n",
      "2026-01-10 23:58:07,126 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085886922224, 'priority': 0, 'context': {'base64Data': 'CN6q94Bw'}}]}\n",
      "2026-01-10 23:58:07,129 - snowflake.connector.connection - DEBUG - sql=[SELECT  *  FROM (( SELECT NULL :: BIGINT AS \"RECIPE_ID\", NULL :: STRING(16777216...], sequence_id=[20], is_file_transfer=[False]\n",
      "2026-01-10 23:58:07,140 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:58:07,148 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:58:07,152 - snowflake.connector.network - DEBUG - Request guid: 327c1c89-6f90-48e7-99ec-05c15a98b493\n",
      "2026-01-10 23:58:07,164 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:58:07,392 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=7e0f07aa-7c73-4b20-b028-6fe22f6e42a7&request_guid=327c1c89-6f90-48e7-99ec-05c15a98b493 HTTP/1.1\" 200 None\n",
      "2026-01-10 23:58:07,397 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:07,399 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:58:07,401 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:58:07,402 - snowflake.connector.network - DEBUG - Query id: 01c1a5c2-0307-7294-0010-08530086260e\n",
      "2026-01-10 23:58:07,404 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085887354764, 'priority': 0, 'context': 'CNKU94Bw'}]}\n",
      "2026-01-10 23:58:07,407 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085886922224, 0)\n",
      "2026-01-10 23:58:07,416 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085887354764, 'priority': 0, 'context': 'CNKU94Bw'}\n",
      "2026-01-10 23:58:07,432 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:58:07,435 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:07,437 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:07,440 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:58:07,466 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085887354764, 0)\n",
      "2026-01-10 23:58:07,468 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c2-0307-7294-0010-08530086260e\n",
      "2026-01-10 23:58:07,470 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:58:07,476 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:07,484 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:58:07,494 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:58:07,500 - snowflake.connector.cursor - INFO - Number of results in first chunk: 0\n",
      "2026-01-10 23:58:07,526 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:58:07,532 - snowflake.connector.cursor - INFO - query: [SELECT \"ING_KEY\", \"ENERGY_KCAL\", \"PROTEIN_G\", \"FAT_G\", \"SATURATED_FATS_G\", \"CARB...]\n",
      "2026-01-10 23:58:07,534 - snowflake.connector.connection - DEBUG - sequence counter: 21\n",
      "2026-01-10 23:58:07,535 - snowflake.connector.cursor - DEBUG - Request id: f00d0444-43fe-475a-ad66-bfa3bf4bda2d\n",
      "2026-01-10 23:58:07,537 - snowflake.connector.cursor - DEBUG - running query [SELECT \"ING_KEY\", \"ENERGY_KCAL\", \"PROTEIN_G\", \"FAT_G\", \"SATURATED_FATS_G\", \"CARB...]\n",
      "2026-01-10 23:58:07,540 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:58:07,543 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:58:07,558 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:58:07,565 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085887354764, 0)\n",
      "2026-01-10 23:58:07,570 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085887354764, 'priority': 0, 'context': {'base64Data': 'CNKU94Bw'}}]}\n",
      "2026-01-10 23:58:07,700 - snowflake.connector.connection - DEBUG - sql=[SELECT \"ING_KEY\", \"ENERGY_KCAL\", \"PROTEIN_G\", \"FAT_G\", \"SATURATED_FATS_G\", \"CARB...], sequence_id=[21], is_file_transfer=[False]\n",
      "2026-01-10 23:58:07,703 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:58:07,706 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:58:07,707 - snowflake.connector.network - DEBUG - Request guid: e9ddfad0-0e69-483b-8c97-84f69d1713bd\n",
      "2026-01-10 23:58:07,709 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:58:07,942 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=f00d0444-43fe-475a-ad66-bfa3bf4bda2d&request_guid=e9ddfad0-0e69-483b-8c97-84f69d1713bd HTTP/1.1\" 200 None\n",
      "2026-01-10 23:58:07,956 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:07,963 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:58:07,965 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:58:07,969 - snowflake.connector.network - DEBUG - Query id: 01c1a5c2-0307-7557-0010-085300861b0e\n",
      "2026-01-10 23:58:07,970 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085887848828, 'priority': 0, 'context': 'CN6q94Bw'}]}\n",
      "2026-01-10 23:58:07,975 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085887354764, 0)\n",
      "2026-01-10 23:58:07,976 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085887848828, 'priority': 0, 'context': 'CN6q94Bw'}\n",
      "2026-01-10 23:58:07,979 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:58:07,981 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:07,982 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:07,984 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:58:07,987 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085887848828, 0)\n",
      "2026-01-10 23:58:07,989 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c2-0307-7557-0010-085300861b0e\n",
      "2026-01-10 23:58:07,991 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:58:07,993 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:07,996 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:58:07,998 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:58:08,006 - snowflake.connector.cursor - INFO - Number of results in first chunk: 0\n",
      "2026-01-10 23:58:08,018 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:58:08,024 - snowflake.connector.cursor - INFO - query: [SELECT \"ING_KEY\", \"ENERGY_KCAL\", \"PROTEIN_G\", \"FAT_G\", \"SATURATED_FATS_G\", \"CARB...]\n",
      "2026-01-10 23:58:08,029 - snowflake.connector.connection - DEBUG - sequence counter: 22\n",
      "2026-01-10 23:58:08,037 - snowflake.connector.cursor - DEBUG - Request id: dca888b2-94a3-45b4-bbf1-f4ba5e9791c3\n",
      "2026-01-10 23:58:08,040 - snowflake.connector.cursor - DEBUG - running query [SELECT \"ING_KEY\", \"ENERGY_KCAL\", \"PROTEIN_G\", \"FAT_G\", \"SATURATED_FATS_G\", \"CARB...]\n",
      "2026-01-10 23:58:08,052 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:58:08,056 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:58:08,059 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:58:08,061 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085887848828, 0)\n",
      "2026-01-10 23:58:08,065 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085887848828, 'priority': 0, 'context': {'base64Data': 'CN6q94Bw'}}]}\n",
      "2026-01-10 23:58:08,072 - snowflake.connector.connection - DEBUG - sql=[SELECT \"ING_KEY\", \"ENERGY_KCAL\", \"PROTEIN_G\", \"FAT_G\", \"SATURATED_FATS_G\", \"CARB...], sequence_id=[22], is_file_transfer=[False]\n",
      "2026-01-10 23:58:08,076 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:58:08,142 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:58:08,148 - snowflake.connector.network - DEBUG - Request guid: 9cb0f9a6-bef9-4b0a-8f2f-b539edaee85c\n",
      "2026-01-10 23:58:08,151 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:58:08,456 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=dca888b2-94a3-45b4-bbf1-f4ba5e9791c3&request_guid=9cb0f9a6-bef9-4b0a-8f2f-b539edaee85c HTTP/1.1\" 200 None\n",
      "2026-01-10 23:58:08,459 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:08,461 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:58:08,462 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:58:08,464 - snowflake.connector.network - DEBUG - Query id: 01c1a5c2-0307-7557-0010-085300861b12\n",
      "2026-01-10 23:58:08,465 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085888341100, 'priority': 0, 'context': 'CN6q94Bw'}]}\n",
      "2026-01-10 23:58:08,466 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085887848828, 0)\n",
      "2026-01-10 23:58:08,468 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085888341100, 'priority': 0, 'context': 'CN6q94Bw'}\n",
      "2026-01-10 23:58:08,470 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:58:08,498 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:08,499 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:08,501 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:58:08,502 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085888341100, 0)\n",
      "2026-01-10 23:58:08,503 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c2-0307-7557-0010-085300861b12\n",
      "2026-01-10 23:58:08,507 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:58:08,508 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:08,517 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:58:08,531 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:58:08,577 - snowflake.connector.cursor - INFO - Number of results in first chunk: 0\n",
      "2026-01-10 23:58:08,579 - snowflake.snowpark._internal.server_connection - DEBUG - Execute query [queryID: 01c1a5c2-0307-7557-0010-085300861b12]  SELECT \"ING_KEY\", \"ENERGY_KCAL\", \"PROTEIN_G\", \"FAT_G\", \"SATURATED_FATS_G\", \"CARB_G\", \"FIBER_G\", \"SUGAR_G\", \"SODIUM_MG\", \"CALCIUM_MG\", \"IRON_MG\", \"MAGNESIUM_MG\", \"POTASSIUM_MG\", \"VITC_MG\" FROM ( SELECT \"ING_KEY\", \"ENERGY_KCAL\", \"PROTEIN_G\", \"FAT_G\", \"SATURATED_FATS_G\", \"CARB_G\", \"FIBER_G\", \"SUGAR_G\", \"SODIUM_MG\", \"CALCIUM_MG\", \"IRON_MG\", \"MAGNESIUM_MG\", \"POTASSIUM_MG\", \"VITC_MG\", \"SCORE_SANTE\", row_number() OVER (PARTITION BY \"ING_KEY\"  ORDER BY \"SCORE_SANTE\" DESC NULLS LAST ) AS \"RN\" FROM ( SELECT  *  FROM (( SELECT \"RECIPE_ID\" AS \"RECIPE_ID\", \"INGREDIENT_FROM_RECIPE_NAME\" AS \"INGREDIENT_FROM_RECIPE_NAME\", \"INGREDIENT_ID\" AS \"INGREDIENT_ID\", \"ING_KEY\" AS \"ING_KEY\" FROM ( SELECT \"RECIPE_ID\", \"INGREDIENT_FROM_RECIPE_NAME\", \"INGREDIENT_ID\", lower(trim(\"INGREDIENT_FROM_RECIPE_NAME\")) AS \"ING_KEY\" FROM NUTRIRAG_PROJECT.RAW.INGREDIENTS_MATCHING WHERE (\"RECIPE_ID\" = 94947 :: INT)) WHERE \"ING_KEY\" IN ('sour cream reduced fat')) AS SNOWPARK_LEFT LEFT OUTER JOIN ( SELECT \"NDB_NO\" AS \"NDB_NO\", \"DESCRIP\" AS \"DESCRIP\", \"ENERGY_KCAL\" AS \"ENERGY_KCAL\", \"PROTEIN_G\" AS \"PROTEIN_G\", \"SATURATED_FATS_G\" AS \"SATURATED_FATS_G\", \"FAT_G\" AS \"FAT_G\", \"CARB_G\" AS \"CARB_G\", \"FIBER_G\" AS \"FIBER_G\", \"SUGAR_G\" AS \"SUGAR_G\", \"CALCIUM_MG\" AS \"CALCIUM_MG\", \"IRON_MG\" AS \"IRON_MG\", \"PHOSPHORUS_MG\" AS \"PHOSPHORUS_MG\", \"POTASSIUM_MG\" AS \"POTASSIUM_MG\", \"SODIUM_MG\" AS \"SODIUM_MG\", \"ZINC_MG\" AS \"ZINC_MG\", \"COPPER_MCG\" AS \"COPPER_MCG\", \"MANGANESE_MG\" AS \"MANGANESE_MG\", \"SELENIUM_MCG\" AS \"SELENIUM_MCG\", \"VITC_MG\" AS \"VITC_MG\", \"THIAMIN_MG\" AS \"THIAMIN_MG\", \"RIBOFLAVIN_MG\" AS \"RIBOFLAVIN_MG\", \"NIACIN_MG\" AS \"NIACIN_MG\", \"VITB6_MG\" AS \"VITB6_MG\", \"FOLATE_MCG\" AS \"FOLATE_MCG\", \"VITB12_MCG\" AS \"VITB12_MCG\", \"VITA_MCG\" AS \"VITA_MCG\", \"MAGNESIUM_MG\" AS \"MAGNESIUM_MG\", \"SCORE_SANTE\" AS \"SCORE_SANTE\" FROM NUTRIRAG_PROJECT.RAW.CLEANED_INGREDIENTS) AS SNOWPARK_RIGHT ON (\"INGREDIENT_ID\" = \"NDB_NO\")))) WHERE (\"RN\" = 1 :: INT)\n",
      "2026-01-10 23:58:08,580 - snowflake.connector.result_set - DEBUG - beginning to schedule result batch downloads\n",
      "2026-01-10 23:58:08,582 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:58:08,583 - snowflake.connector.cursor - INFO - query: [SELECT  *  FROM NUTRIRAG_PROJECT.RAW.INGREDIENTS_MATCHING]\n",
      "2026-01-10 23:58:08,584 - snowflake.connector.connection - DEBUG - sequence counter: 23\n",
      "2026-01-10 23:58:08,586 - snowflake.connector.cursor - DEBUG - Request id: 49769a2a-9172-4e1e-abee-6ec337304c87\n",
      "2026-01-10 23:58:08,588 - snowflake.connector.cursor - DEBUG - running query [SELECT  *  FROM NUTRIRAG_PROJECT.RAW.INGREDIENTS_MATCHING]\n",
      "2026-01-10 23:58:08,596 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:58:08,616 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:58:08,633 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:58:08,650 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085888341100, 0)\n",
      "2026-01-10 23:58:08,652 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085888341100, 'priority': 0, 'context': {'base64Data': 'CN6q94Bw'}}]}\n",
      "2026-01-10 23:58:08,670 - snowflake.connector.connection - DEBUG - sql=[SELECT  *  FROM NUTRIRAG_PROJECT.RAW.INGREDIENTS_MATCHING], sequence_id=[23], is_file_transfer=[False]\n",
      "2026-01-10 23:58:08,685 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:58:08,699 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:58:08,703 - snowflake.connector.network - DEBUG - Request guid: d08dfa72-b66d-49bb-bc27-179cbfcf4dc1\n",
      "2026-01-10 23:58:08,720 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:58:08,925 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=49769a2a-9172-4e1e-abee-6ec337304c87&request_guid=d08dfa72-b66d-49bb-bc27-179cbfcf4dc1 HTTP/1.1\" 200 None\n",
      "2026-01-10 23:58:08,930 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:08,932 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:58:08,935 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:58:08,937 - snowflake.connector.network - DEBUG - Query id: 01c1a5c2-0307-7557-0010-085300861b16\n",
      "2026-01-10 23:58:08,943 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085888879114, 'priority': 0, 'context': 'CN6q94Bw'}]}\n",
      "2026-01-10 23:58:08,952 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085888341100, 0)\n",
      "2026-01-10 23:58:08,970 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085888879114, 'priority': 0, 'context': 'CN6q94Bw'}\n",
      "2026-01-10 23:58:08,975 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:58:08,977 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:08,979 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:08,986 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:58:08,996 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085888879114, 0)\n",
      "2026-01-10 23:58:09,002 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c2-0307-7557-0010-085300861b16\n",
      "2026-01-10 23:58:09,003 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:58:09,009 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:09,018 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:58:09,080 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:58:09,081 - snowflake.connector.cursor - INFO - Number of results in first chunk: 0\n",
      "2026-01-10 23:58:09,084 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:58:09,085 - snowflake.connector.cursor - INFO - query: [SELECT \"RECIPE_ID\", \"INGREDIENT_FROM_RECIPE_NAME\", \"INGREDIENT_ID\", lower(trim(\"...]\n",
      "2026-01-10 23:58:09,087 - snowflake.connector.connection - DEBUG - sequence counter: 24\n",
      "2026-01-10 23:58:09,095 - snowflake.connector.cursor - DEBUG - Request id: bbdfaba6-b827-424a-9d2e-23cf1c3e5b3f\n",
      "2026-01-10 23:58:09,099 - snowflake.connector.cursor - DEBUG - running query [SELECT \"RECIPE_ID\", \"INGREDIENT_FROM_RECIPE_NAME\", \"INGREDIENT_ID\", lower(trim(\"...]\n",
      "2026-01-10 23:58:09,101 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:58:09,102 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:58:09,104 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:58:09,119 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085888879114, 0)\n",
      "2026-01-10 23:58:09,129 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085888879114, 'priority': 0, 'context': {'base64Data': 'CN6q94Bw'}}]}\n",
      "2026-01-10 23:58:09,134 - snowflake.connector.connection - DEBUG - sql=[SELECT \"RECIPE_ID\", \"INGREDIENT_FROM_RECIPE_NAME\", \"INGREDIENT_ID\", lower(trim(\"...], sequence_id=[24], is_file_transfer=[False]\n",
      "2026-01-10 23:58:09,147 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:58:09,152 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:58:09,170 - snowflake.connector.network - DEBUG - Request guid: a9b86a79-ac81-4327-9139-c98075dbf04b\n",
      "2026-01-10 23:58:09,176 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:58:09,483 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=bbdfaba6-b827-424a-9d2e-23cf1c3e5b3f&request_guid=a9b86a79-ac81-4327-9139-c98075dbf04b HTTP/1.1\" 200 None\n",
      "2026-01-10 23:58:09,486 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:09,491 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:58:09,493 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:58:09,498 - snowflake.connector.network - DEBUG - Query id: 01c1a5c2-0307-7294-0010-085300862612\n",
      "2026-01-10 23:58:09,514 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085889330842, 'priority': 0, 'context': 'CNKU94Bw'}]}\n",
      "2026-01-10 23:58:09,517 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085888879114, 0)\n",
      "2026-01-10 23:58:09,549 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085889330842, 'priority': 0, 'context': 'CNKU94Bw'}\n",
      "2026-01-10 23:58:09,552 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:58:09,553 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:09,560 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:09,611 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:58:09,615 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085889330842, 0)\n",
      "2026-01-10 23:58:09,622 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c2-0307-7294-0010-085300862612\n",
      "2026-01-10 23:58:09,629 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:58:09,635 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:09,639 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:58:09,651 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:58:09,658 - snowflake.connector.cursor - INFO - Number of results in first chunk: 0\n",
      "2026-01-10 23:58:09,669 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:58:09,675 - snowflake.connector.cursor - INFO - query: [SELECT  *  FROM NUTRIRAG_PROJECT.RAW.CLEANED_INGREDIENTS]\n",
      "2026-01-10 23:58:09,679 - snowflake.connector.connection - DEBUG - sequence counter: 25\n",
      "2026-01-10 23:58:09,683 - snowflake.connector.cursor - DEBUG - Request id: 24771f03-34e4-49aa-beb5-6231a94903fe\n",
      "2026-01-10 23:58:09,685 - snowflake.connector.cursor - DEBUG - running query [SELECT  *  FROM NUTRIRAG_PROJECT.RAW.CLEANED_INGREDIENTS]\n",
      "2026-01-10 23:58:09,687 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:58:09,696 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:58:09,703 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:58:09,816 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085889330842, 0)\n",
      "2026-01-10 23:58:09,818 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085889330842, 'priority': 0, 'context': {'base64Data': 'CNKU94Bw'}}]}\n",
      "2026-01-10 23:58:09,819 - snowflake.connector.connection - DEBUG - sql=[SELECT  *  FROM NUTRIRAG_PROJECT.RAW.CLEANED_INGREDIENTS], sequence_id=[25], is_file_transfer=[False]\n",
      "2026-01-10 23:58:09,821 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:58:09,824 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:58:09,828 - snowflake.connector.network - DEBUG - Request guid: 5083ea5d-cf3f-43bb-bb4a-f51ae15b9522\n",
      "2026-01-10 23:58:09,833 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:58:10,099 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=24771f03-34e4-49aa-beb5-6231a94903fe&request_guid=5083ea5d-cf3f-43bb-bb4a-f51ae15b9522 HTTP/1.1\" 200 None\n",
      "2026-01-10 23:58:10,109 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:10,119 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:58:10,136 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:58:10,151 - snowflake.connector.network - DEBUG - Query id: 01c1a5c2-0307-73b1-0010-0853008609ea\n",
      "2026-01-10 23:58:10,154 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085890039792, 'priority': 0, 'context': 'CMad94Bw'}]}\n",
      "2026-01-10 23:58:10,163 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085889330842, 0)\n",
      "2026-01-10 23:58:10,179 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085890039792, 'priority': 0, 'context': 'CMad94Bw'}\n",
      "2026-01-10 23:58:10,181 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:58:10,182 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:10,193 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:10,233 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:58:10,235 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085890039792, 0)\n",
      "2026-01-10 23:58:10,236 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c2-0307-73b1-0010-0853008609ea\n",
      "2026-01-10 23:58:10,253 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:58:10,300 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:10,302 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:58:10,317 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:58:10,324 - snowflake.connector.cursor - INFO - Number of results in first chunk: 0\n",
      "2026-01-10 23:58:10,386 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:58:10,387 - snowflake.connector.cursor - INFO - query: [SELECT \"RECIPE_ID\" AS \"RECIPE_ID\", \"INGREDIENT_FROM_RECIPE_NAME\" AS \"INGREDIENT_...]\n",
      "2026-01-10 23:58:10,392 - snowflake.connector.connection - DEBUG - sequence counter: 26\n",
      "2026-01-10 23:58:10,394 - snowflake.connector.cursor - DEBUG - Request id: 9410c63b-89c0-40b6-9de0-49fdad609aa1\n",
      "2026-01-10 23:58:10,397 - snowflake.connector.cursor - DEBUG - running query [SELECT \"RECIPE_ID\" AS \"RECIPE_ID\", \"INGREDIENT_FROM_RECIPE_NAME\" AS \"INGREDIENT_...]\n",
      "2026-01-10 23:58:10,403 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:58:10,405 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:58:10,457 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:58:10,465 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085890039792, 0)\n",
      "2026-01-10 23:58:10,472 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085890039792, 'priority': 0, 'context': {'base64Data': 'CMad94Bw'}}]}\n",
      "2026-01-10 23:58:10,474 - snowflake.connector.connection - DEBUG - sql=[SELECT \"RECIPE_ID\" AS \"RECIPE_ID\", \"INGREDIENT_FROM_RECIPE_NAME\" AS \"INGREDIENT_...], sequence_id=[26], is_file_transfer=[False]\n",
      "2026-01-10 23:58:10,478 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:58:10,484 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:58:10,489 - snowflake.connector.network - DEBUG - Request guid: 3371189c-dbc3-43c9-a26c-45d5077720d0\n",
      "2026-01-10 23:58:10,492 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:58:10,708 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=9410c63b-89c0-40b6-9de0-49fdad609aa1&request_guid=3371189c-dbc3-43c9-a26c-45d5077720d0 HTTP/1.1\" 200 None\n",
      "2026-01-10 23:58:10,715 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:10,717 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:58:10,719 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:58:10,721 - snowflake.connector.network - DEBUG - Query id: 01c1a5c2-0307-73b1-0010-0853008609ee\n",
      "2026-01-10 23:58:10,725 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085890658637, 'priority': 0, 'context': 'CMad94Bw'}]}\n",
      "2026-01-10 23:58:10,735 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085890039792, 0)\n",
      "2026-01-10 23:58:10,750 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085890658637, 'priority': 0, 'context': 'CMad94Bw'}\n",
      "2026-01-10 23:58:10,751 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:58:10,753 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:10,754 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:10,767 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:58:10,784 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085890658637, 0)\n",
      "2026-01-10 23:58:10,788 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c2-0307-73b1-0010-0853008609ee\n",
      "2026-01-10 23:58:10,794 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:58:10,817 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:10,820 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:58:10,823 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:58:10,832 - snowflake.connector.cursor - INFO - Number of results in first chunk: 0\n",
      "2026-01-10 23:58:10,880 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:58:10,898 - snowflake.connector.cursor - INFO - query: [SELECT \"NDB_NO\" AS \"NDB_NO\", \"DESCRIP\" AS \"DESCRIP\", \"ENERGY_KCAL\" AS \"ENERGY_KC...]\n",
      "2026-01-10 23:58:10,900 - snowflake.connector.connection - DEBUG - sequence counter: 27\n",
      "2026-01-10 23:58:10,901 - snowflake.connector.cursor - DEBUG - Request id: 71788179-ebf8-4ccb-b5bb-972a9ae2d477\n",
      "2026-01-10 23:58:10,903 - snowflake.connector.cursor - DEBUG - running query [SELECT \"NDB_NO\" AS \"NDB_NO\", \"DESCRIP\" AS \"DESCRIP\", \"ENERGY_KCAL\" AS \"ENERGY_KC...]\n",
      "2026-01-10 23:58:10,904 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:58:10,908 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:58:10,914 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:58:10,922 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085890658637, 0)\n",
      "2026-01-10 23:58:10,966 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085890658637, 'priority': 0, 'context': {'base64Data': 'CMad94Bw'}}]}\n",
      "2026-01-10 23:58:10,968 - snowflake.connector.connection - DEBUG - sql=[SELECT \"NDB_NO\" AS \"NDB_NO\", \"DESCRIP\" AS \"DESCRIP\", \"ENERGY_KCAL\" AS \"ENERGY_KC...], sequence_id=[27], is_file_transfer=[False]\n",
      "2026-01-10 23:58:10,975 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:58:10,978 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:58:10,984 - snowflake.connector.network - DEBUG - Request guid: fa9b5bf8-e5f6-471b-b4ad-1eed3c8d1ff7\n",
      "2026-01-10 23:58:10,985 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:58:11,179 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=71788179-ebf8-4ccb-b5bb-972a9ae2d477&request_guid=fa9b5bf8-e5f6-471b-b4ad-1eed3c8d1ff7 HTTP/1.1\" 200 None\n",
      "2026-01-10 23:58:11,183 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:11,185 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:58:11,187 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:58:11,191 - snowflake.connector.network - DEBUG - Query id: 01c1a5c2-0307-74b8-0010-08530086322e\n",
      "2026-01-10 23:58:11,199 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085891142619, 'priority': 0, 'context': 'COKl94Bw'}]}\n",
      "2026-01-10 23:58:11,202 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085890658637, 0)\n",
      "2026-01-10 23:58:11,204 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085891142619, 'priority': 0, 'context': 'COKl94Bw'}\n",
      "2026-01-10 23:58:11,216 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:58:11,219 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:11,224 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:11,257 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:58:11,262 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085891142619, 0)\n",
      "2026-01-10 23:58:11,267 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c2-0307-74b8-0010-08530086322e\n",
      "2026-01-10 23:58:11,269 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:58:11,302 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:11,303 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:58:11,305 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:58:11,312 - snowflake.connector.cursor - INFO - Number of results in first chunk: 0\n",
      "2026-01-10 23:58:11,349 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:58:11,353 - snowflake.connector.cursor - INFO - query: [SELECT  *  FROM (( SELECT NULL :: BIGINT AS \"RECIPE_ID\", NULL :: STRING(16777216...]\n",
      "2026-01-10 23:58:11,362 - snowflake.connector.connection - DEBUG - sequence counter: 28\n",
      "2026-01-10 23:58:11,368 - snowflake.connector.cursor - DEBUG - Request id: 265430b7-dd24-4340-9626-f24e45289f11\n",
      "2026-01-10 23:58:11,390 - snowflake.connector.cursor - DEBUG - running query [SELECT  *  FROM (( SELECT NULL :: BIGINT AS \"RECIPE_ID\", NULL :: STRING(16777216...]\n",
      "2026-01-10 23:58:11,413 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:58:11,417 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:58:11,459 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:58:11,466 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085891142619, 0)\n",
      "2026-01-10 23:58:11,474 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085891142619, 'priority': 0, 'context': {'base64Data': 'COKl94Bw'}}]}\n",
      "2026-01-10 23:58:11,478 - snowflake.connector.connection - DEBUG - sql=[SELECT  *  FROM (( SELECT NULL :: BIGINT AS \"RECIPE_ID\", NULL :: STRING(16777216...], sequence_id=[28], is_file_transfer=[False]\n",
      "2026-01-10 23:58:11,483 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:58:11,489 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:58:11,519 - snowflake.connector.network - DEBUG - Request guid: 46ab3901-bd15-44b4-b82b-ed7eaa323e09\n",
      "2026-01-10 23:58:11,523 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:58:11,728 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=265430b7-dd24-4340-9626-f24e45289f11&request_guid=46ab3901-bd15-44b4-b82b-ed7eaa323e09 HTTP/1.1\" 200 None\n",
      "2026-01-10 23:58:11,798 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:11,807 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:58:11,814 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:58:11,822 - snowflake.connector.network - DEBUG - Query id: 01c1a5c2-0307-7294-0010-085300862616\n",
      "2026-01-10 23:58:11,829 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085891687548, 'priority': 0, 'context': 'CNKU94Bw'}]}\n",
      "2026-01-10 23:58:11,836 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085891142619, 0)\n",
      "2026-01-10 23:58:11,844 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085891687548, 'priority': 0, 'context': 'CNKU94Bw'}\n",
      "2026-01-10 23:58:11,851 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:58:11,856 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:11,861 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:11,868 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:58:11,876 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085891687548, 0)\n",
      "2026-01-10 23:58:11,883 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c2-0307-7294-0010-085300862616\n",
      "2026-01-10 23:58:11,892 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:58:11,900 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:11,910 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:58:11,912 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:58:11,919 - snowflake.connector.cursor - INFO - Number of results in first chunk: 0\n",
      "2026-01-10 23:58:11,933 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:58:11,944 - snowflake.connector.cursor - INFO - query: [SELECT \"ING_KEY\", \"ENERGY_KCAL\", \"PROTEIN_G\", \"FAT_G\", \"SATURATED_FATS_G\", \"CARB...]\n",
      "2026-01-10 23:58:11,951 - snowflake.connector.connection - DEBUG - sequence counter: 29\n",
      "2026-01-10 23:58:11,961 - snowflake.connector.cursor - DEBUG - Request id: b380e3bc-1793-4a2a-9cac-1b92c3f75e19\n",
      "2026-01-10 23:58:12,008 - snowflake.connector.cursor - DEBUG - running query [SELECT \"ING_KEY\", \"ENERGY_KCAL\", \"PROTEIN_G\", \"FAT_G\", \"SATURATED_FATS_G\", \"CARB...]\n",
      "2026-01-10 23:58:12,018 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:58:12,020 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:58:12,027 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:58:12,032 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085891687548, 0)\n",
      "2026-01-10 23:58:12,036 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085891687548, 'priority': 0, 'context': {'base64Data': 'CNKU94Bw'}}]}\n",
      "2026-01-10 23:58:12,041 - snowflake.connector.connection - DEBUG - sql=[SELECT \"ING_KEY\", \"ENERGY_KCAL\", \"PROTEIN_G\", \"FAT_G\", \"SATURATED_FATS_G\", \"CARB...], sequence_id=[29], is_file_transfer=[False]\n",
      "2026-01-10 23:58:12,043 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:58:12,047 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:58:12,050 - snowflake.connector.network - DEBUG - Request guid: 38c1873f-e080-4d92-8d55-65463127ca5e\n",
      "2026-01-10 23:58:12,054 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:58:12,251 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=b380e3bc-1793-4a2a-9cac-1b92c3f75e19&request_guid=38c1873f-e080-4d92-8d55-65463127ca5e HTTP/1.1\" 200 None\n",
      "2026-01-10 23:58:12,258 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:12,260 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:58:12,265 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:58:12,266 - snowflake.connector.network - DEBUG - Query id: 01c1a5c2-0307-7294-0010-08530086261a\n",
      "2026-01-10 23:58:12,269 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085892184998, 'priority': 0, 'context': 'CNKU94Bw'}]}\n",
      "2026-01-10 23:58:12,272 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085891687548, 0)\n",
      "2026-01-10 23:58:12,276 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085892184998, 'priority': 0, 'context': 'CNKU94Bw'}\n",
      "2026-01-10 23:58:12,280 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:58:12,287 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:12,291 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:12,297 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:58:12,298 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085892184998, 0)\n",
      "2026-01-10 23:58:12,300 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c2-0307-7294-0010-08530086261a\n",
      "2026-01-10 23:58:12,302 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:58:12,305 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:12,308 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:58:12,309 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:58:12,321 - snowflake.connector.cursor - INFO - Number of results in first chunk: 0\n",
      "2026-01-10 23:58:12,330 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:58:12,334 - snowflake.connector.cursor - INFO - query: [SELECT \"ING_KEY\", \"ENERGY_KCAL\", \"PROTEIN_G\", \"FAT_G\", \"SATURATED_FATS_G\", \"CARB...]\n",
      "2026-01-10 23:58:12,349 - snowflake.connector.connection - DEBUG - sequence counter: 30\n",
      "2026-01-10 23:58:12,362 - snowflake.connector.cursor - DEBUG - Request id: 38074e78-2f95-4daf-9d16-e0b7d7f0507e\n",
      "2026-01-10 23:58:12,454 - snowflake.connector.cursor - DEBUG - running query [SELECT \"ING_KEY\", \"ENERGY_KCAL\", \"PROTEIN_G\", \"FAT_G\", \"SATURATED_FATS_G\", \"CARB...]\n",
      "2026-01-10 23:58:12,461 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:58:12,465 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:58:12,468 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:58:12,473 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085892184998, 0)\n",
      "2026-01-10 23:58:12,483 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085892184998, 'priority': 0, 'context': {'base64Data': 'CNKU94Bw'}}]}\n",
      "2026-01-10 23:58:12,489 - snowflake.connector.connection - DEBUG - sql=[SELECT \"ING_KEY\", \"ENERGY_KCAL\", \"PROTEIN_G\", \"FAT_G\", \"SATURATED_FATS_G\", \"CARB...], sequence_id=[30], is_file_transfer=[False]\n",
      "2026-01-10 23:58:12,494 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:58:12,502 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:58:12,507 - snowflake.connector.network - DEBUG - Request guid: 1b12ba41-db72-4a26-97f7-42d9c2e8fe78\n",
      "2026-01-10 23:58:12,511 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:58:12,758 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=38074e78-2f95-4daf-9d16-e0b7d7f0507e&request_guid=1b12ba41-db72-4a26-97f7-42d9c2e8fe78 HTTP/1.1\" 200 None\n",
      "2026-01-10 23:58:12,763 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:12,769 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:58:12,771 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:58:12,778 - snowflake.connector.network - DEBUG - Query id: 01c1a5c2-0307-74b8-0010-085300863232\n",
      "2026-01-10 23:58:12,784 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085892699707, 'priority': 0, 'context': 'COKl94Bw'}]}\n",
      "2026-01-10 23:58:12,792 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085892184998, 0)\n",
      "2026-01-10 23:58:12,799 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085892699707, 'priority': 0, 'context': 'COKl94Bw'}\n",
      "2026-01-10 23:58:12,812 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:58:12,822 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:12,826 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:12,901 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:58:12,911 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085892699707, 0)\n",
      "2026-01-10 23:58:12,917 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c2-0307-74b8-0010-085300863232\n",
      "2026-01-10 23:58:12,932 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:58:12,940 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:12,951 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:58:12,957 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:58:12,964 - snowflake.connector.cursor - INFO - Number of results in first chunk: 0\n",
      "2026-01-10 23:58:12,970 - snowflake.snowpark._internal.server_connection - DEBUG - Execute query [queryID: 01c1a5c2-0307-74b8-0010-085300863232]  SELECT \"ING_KEY\", \"ENERGY_KCAL\", \"PROTEIN_G\", \"FAT_G\", \"SATURATED_FATS_G\", \"CARB_G\", \"FIBER_G\", \"SUGAR_G\", \"SODIUM_MG\", \"CALCIUM_MG\", \"IRON_MG\", \"MAGNESIUM_MG\", \"POTASSIUM_MG\", \"VITC_MG\" FROM ( SELECT \"ING_KEY\", \"ENERGY_KCAL\", \"PROTEIN_G\", \"FAT_G\", \"SATURATED_FATS_G\", \"CARB_G\", \"FIBER_G\", \"SUGAR_G\", \"SODIUM_MG\", \"CALCIUM_MG\", \"IRON_MG\", \"MAGNESIUM_MG\", \"POTASSIUM_MG\", \"VITC_MG\", \"SCORE_SANTE\", row_number() OVER (PARTITION BY \"ING_KEY\"  ORDER BY \"SCORE_SANTE\" DESC NULLS LAST ) AS \"RN\" FROM ( SELECT  *  FROM (( SELECT \"RECIPE_ID\" AS \"RECIPE_ID\", \"INGREDIENT_FROM_RECIPE_NAME\" AS \"INGREDIENT_FROM_RECIPE_NAME\", \"INGREDIENT_ID\" AS \"INGREDIENT_ID\", \"ING_KEY\" AS \"ING_KEY\" FROM ( SELECT \"RECIPE_ID\", \"INGREDIENT_FROM_RECIPE_NAME\", \"INGREDIENT_ID\", lower(trim(\"INGREDIENT_FROM_RECIPE_NAME\")) AS \"ING_KEY\" FROM NUTRIRAG_PROJECT.RAW.INGREDIENTS_MATCHING WHERE (\"RECIPE_ID\" = 94947 :: INT)) WHERE \"ING_KEY\" IN ('cream fluid lt (coffee crm or table crm)')) AS SNOWPARK_LEFT LEFT OUTER JOIN ( SELECT \"NDB_NO\" AS \"NDB_NO\", \"DESCRIP\" AS \"DESCRIP\", \"ENERGY_KCAL\" AS \"ENERGY_KCAL\", \"PROTEIN_G\" AS \"PROTEIN_G\", \"SATURATED_FATS_G\" AS \"SATURATED_FATS_G\", \"FAT_G\" AS \"FAT_G\", \"CARB_G\" AS \"CARB_G\", \"FIBER_G\" AS \"FIBER_G\", \"SUGAR_G\" AS \"SUGAR_G\", \"CALCIUM_MG\" AS \"CALCIUM_MG\", \"IRON_MG\" AS \"IRON_MG\", \"PHOSPHORUS_MG\" AS \"PHOSPHORUS_MG\", \"POTASSIUM_MG\" AS \"POTASSIUM_MG\", \"SODIUM_MG\" AS \"SODIUM_MG\", \"ZINC_MG\" AS \"ZINC_MG\", \"COPPER_MCG\" AS \"COPPER_MCG\", \"MANGANESE_MG\" AS \"MANGANESE_MG\", \"SELENIUM_MCG\" AS \"SELENIUM_MCG\", \"VITC_MG\" AS \"VITC_MG\", \"THIAMIN_MG\" AS \"THIAMIN_MG\", \"RIBOFLAVIN_MG\" AS \"RIBOFLAVIN_MG\", \"NIACIN_MG\" AS \"NIACIN_MG\", \"VITB6_MG\" AS \"VITB6_MG\", \"FOLATE_MCG\" AS \"FOLATE_MCG\", \"VITB12_MCG\" AS \"VITB12_MCG\", \"VITA_MCG\" AS \"VITA_MCG\", \"MAGNESIUM_MG\" AS \"MAGNESIUM_MG\", \"SCORE_SANTE\" AS \"SCORE_SANTE\" FROM NUTRIRAG_PROJECT.RAW.CLEANED_INGREDIENTS) AS SNOWPARK_RIGHT ON (\"INGREDIENT_ID\" = \"NDB_NO\")))) WHERE (\"RN\" = 1 :: INT)\n",
      "2026-01-10 23:58:12,974 - snowflake.connector.result_set - DEBUG - beginning to schedule result batch downloads\n",
      "2026-01-10 23:58:12,978 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:58:12,982 - snowflake.connector.cursor - INFO - query: [SELECT  *  FROM NUTRIRAG_PROJECT.RAW.INGREDIENTS_MATCHING]\n",
      "2026-01-10 23:58:12,985 - snowflake.connector.connection - DEBUG - sequence counter: 31\n",
      "2026-01-10 23:58:12,988 - snowflake.connector.cursor - DEBUG - Request id: ac94c2ef-409c-4cc9-a435-be5912be6d48\n",
      "2026-01-10 23:58:12,990 - snowflake.connector.cursor - DEBUG - running query [SELECT  *  FROM NUTRIRAG_PROJECT.RAW.INGREDIENTS_MATCHING]\n",
      "2026-01-10 23:58:12,994 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:58:12,996 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:58:12,998 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:58:13,002 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085892699707, 0)\n",
      "2026-01-10 23:58:13,006 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085892699707, 'priority': 0, 'context': {'base64Data': 'COKl94Bw'}}]}\n",
      "2026-01-10 23:58:13,014 - snowflake.connector.connection - DEBUG - sql=[SELECT  *  FROM NUTRIRAG_PROJECT.RAW.INGREDIENTS_MATCHING], sequence_id=[31], is_file_transfer=[False]\n",
      "2026-01-10 23:58:13,020 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:58:13,024 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:58:13,027 - snowflake.connector.network - DEBUG - Request guid: bfd19f9f-6efc-49cb-b341-d352eac75803\n",
      "2026-01-10 23:58:13,032 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:58:13,230 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=ac94c2ef-409c-4cc9-a435-be5912be6d48&request_guid=bfd19f9f-6efc-49cb-b341-d352eac75803 HTTP/1.1\" 200 None\n",
      "2026-01-10 23:58:13,234 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:13,235 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:58:13,237 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:58:13,239 - snowflake.connector.network - DEBUG - Query id: 01c1a5c2-0307-74b8-0010-085300863236\n",
      "2026-01-10 23:58:13,241 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085893188242, 'priority': 0, 'context': 'COKl94Bw'}]}\n",
      "2026-01-10 23:58:13,242 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085892699707, 0)\n",
      "2026-01-10 23:58:13,243 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085893188242, 'priority': 0, 'context': 'COKl94Bw'}\n",
      "2026-01-10 23:58:13,248 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:58:13,254 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:13,268 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:13,271 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:58:13,274 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085893188242, 0)\n",
      "2026-01-10 23:58:13,288 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c2-0307-74b8-0010-085300863236\n",
      "2026-01-10 23:58:13,366 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:58:13,371 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:13,384 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:58:13,389 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:58:13,393 - snowflake.connector.cursor - INFO - Number of results in first chunk: 0\n",
      "2026-01-10 23:58:13,400 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:58:13,403 - snowflake.connector.cursor - INFO - query: [SELECT \"RECIPE_ID\", \"INGREDIENT_FROM_RECIPE_NAME\", \"INGREDIENT_ID\", lower(trim(\"...]\n",
      "2026-01-10 23:58:13,408 - snowflake.connector.connection - DEBUG - sequence counter: 32\n",
      "2026-01-10 23:58:13,412 - snowflake.connector.cursor - DEBUG - Request id: eb39cbc0-c619-4415-8a4f-c0218c939c76\n",
      "2026-01-10 23:58:13,414 - snowflake.connector.cursor - DEBUG - running query [SELECT \"RECIPE_ID\", \"INGREDIENT_FROM_RECIPE_NAME\", \"INGREDIENT_ID\", lower(trim(\"...]\n",
      "2026-01-10 23:58:13,420 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:58:13,426 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:58:13,430 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:58:13,436 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085893188242, 0)\n",
      "2026-01-10 23:58:13,441 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085893188242, 'priority': 0, 'context': {'base64Data': 'COKl94Bw'}}]}\n",
      "2026-01-10 23:58:13,448 - snowflake.connector.connection - DEBUG - sql=[SELECT \"RECIPE_ID\", \"INGREDIENT_FROM_RECIPE_NAME\", \"INGREDIENT_ID\", lower(trim(\"...], sequence_id=[32], is_file_transfer=[False]\n",
      "2026-01-10 23:58:13,453 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:58:13,457 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:58:13,497 - snowflake.connector.network - DEBUG - Request guid: e918046f-42e6-40a3-b1c9-27ba60edb89b\n",
      "2026-01-10 23:58:13,589 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:58:13,792 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=eb39cbc0-c619-4415-8a4f-c0218c939c76&request_guid=e918046f-42e6-40a3-b1c9-27ba60edb89b HTTP/1.1\" 200 None\n",
      "2026-01-10 23:58:13,797 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:13,798 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:58:13,800 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:58:13,802 - snowflake.connector.network - DEBUG - Query id: 01c1a5c2-0307-7557-0010-085300861b1a\n",
      "2026-01-10 23:58:13,807 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085893756091, 'priority': 0, 'context': 'CN6q94Bw'}]}\n",
      "2026-01-10 23:58:13,812 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085893188242, 0)\n",
      "2026-01-10 23:58:13,814 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085893756091, 'priority': 0, 'context': 'CN6q94Bw'}\n",
      "2026-01-10 23:58:13,820 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:58:13,824 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:13,825 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:13,828 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:58:13,831 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085893756091, 0)\n",
      "2026-01-10 23:58:13,833 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c2-0307-7557-0010-085300861b1a\n",
      "2026-01-10 23:58:13,835 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:58:13,836 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:13,840 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:58:13,845 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:58:13,849 - snowflake.connector.cursor - INFO - Number of results in first chunk: 0\n",
      "2026-01-10 23:58:13,856 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:58:13,860 - snowflake.connector.cursor - INFO - query: [SELECT  *  FROM NUTRIRAG_PROJECT.RAW.CLEANED_INGREDIENTS]\n",
      "2026-01-10 23:58:13,862 - snowflake.connector.connection - DEBUG - sequence counter: 33\n",
      "2026-01-10 23:58:13,869 - snowflake.connector.cursor - DEBUG - Request id: 0391da55-9f3a-485d-9bc7-c0233b0f0525\n",
      "2026-01-10 23:58:13,880 - snowflake.connector.cursor - DEBUG - running query [SELECT  *  FROM NUTRIRAG_PROJECT.RAW.CLEANED_INGREDIENTS]\n",
      "2026-01-10 23:58:13,884 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:58:13,901 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:58:13,909 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:58:13,912 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085893756091, 0)\n",
      "2026-01-10 23:58:13,916 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085893756091, 'priority': 0, 'context': {'base64Data': 'CN6q94Bw'}}]}\n",
      "2026-01-10 23:58:13,925 - snowflake.connector.connection - DEBUG - sql=[SELECT  *  FROM NUTRIRAG_PROJECT.RAW.CLEANED_INGREDIENTS], sequence_id=[33], is_file_transfer=[False]\n",
      "2026-01-10 23:58:13,931 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:58:13,937 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:58:13,945 - snowflake.connector.network - DEBUG - Request guid: ba9fe78d-c29c-4906-b0c2-591e99c25b6f\n",
      "2026-01-10 23:58:13,957 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:58:14,201 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=0391da55-9f3a-485d-9bc7-c0233b0f0525&request_guid=ba9fe78d-c29c-4906-b0c2-591e99c25b6f HTTP/1.1\" 200 None\n",
      "2026-01-10 23:58:14,210 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:14,217 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:58:14,224 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:58:14,227 - snowflake.connector.network - DEBUG - Query id: 01c1a5c2-0307-73b1-0010-0853008609f2\n",
      "2026-01-10 23:58:14,231 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085894110959, 'priority': 0, 'context': 'CMad94Bw'}]}\n",
      "2026-01-10 23:58:14,243 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085893756091, 0)\n",
      "2026-01-10 23:58:14,248 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085894110959, 'priority': 0, 'context': 'CMad94Bw'}\n",
      "2026-01-10 23:58:14,252 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:58:14,259 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:14,266 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:14,270 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:58:14,274 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085894110959, 0)\n",
      "2026-01-10 23:58:14,280 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c2-0307-73b1-0010-0853008609f2\n",
      "2026-01-10 23:58:14,284 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:58:14,289 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:14,298 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:58:14,304 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:58:14,310 - snowflake.connector.cursor - INFO - Number of results in first chunk: 0\n",
      "2026-01-10 23:58:14,332 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:58:14,335 - snowflake.connector.cursor - INFO - query: [SELECT \"RECIPE_ID\" AS \"RECIPE_ID\", \"INGREDIENT_FROM_RECIPE_NAME\" AS \"INGREDIENT_...]\n",
      "2026-01-10 23:58:14,351 - snowflake.connector.connection - DEBUG - sequence counter: 34\n",
      "2026-01-10 23:58:14,433 - snowflake.connector.cursor - DEBUG - Request id: 27b0ad30-e43d-4b9c-91fc-324069e9628b\n",
      "2026-01-10 23:58:14,451 - snowflake.connector.cursor - DEBUG - running query [SELECT \"RECIPE_ID\" AS \"RECIPE_ID\", \"INGREDIENT_FROM_RECIPE_NAME\" AS \"INGREDIENT_...]\n",
      "2026-01-10 23:58:14,458 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:58:14,467 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:58:14,486 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:58:14,525 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085894110959, 0)\n",
      "2026-01-10 23:58:14,544 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085894110959, 'priority': 0, 'context': {'base64Data': 'CMad94Bw'}}]}\n",
      "2026-01-10 23:58:14,558 - snowflake.connector.connection - DEBUG - sql=[SELECT \"RECIPE_ID\" AS \"RECIPE_ID\", \"INGREDIENT_FROM_RECIPE_NAME\" AS \"INGREDIENT_...], sequence_id=[34], is_file_transfer=[False]\n",
      "2026-01-10 23:58:14,568 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:58:14,577 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:58:14,585 - snowflake.connector.network - DEBUG - Request guid: bae7d7a5-55f2-4997-a2cf-5a6fc422a8ee\n",
      "2026-01-10 23:58:14,619 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:58:14,831 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=27b0ad30-e43d-4b9c-91fc-324069e9628b&request_guid=bae7d7a5-55f2-4997-a2cf-5a6fc422a8ee HTTP/1.1\" 200 None\n",
      "2026-01-10 23:58:14,834 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:14,835 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:58:14,837 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:58:14,839 - snowflake.connector.network - DEBUG - Query id: 01c1a5c2-0307-73b1-0010-0853008609f6\n",
      "2026-01-10 23:58:14,841 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085894789124, 'priority': 0, 'context': 'CMad94Bw'}]}\n",
      "2026-01-10 23:58:14,842 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085894110959, 0)\n",
      "2026-01-10 23:58:14,843 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085894789124, 'priority': 0, 'context': 'CMad94Bw'}\n",
      "2026-01-10 23:58:14,847 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:58:14,851 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:14,864 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:14,869 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:58:14,871 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085894789124, 0)\n",
      "2026-01-10 23:58:14,876 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c2-0307-73b1-0010-0853008609f6\n",
      "2026-01-10 23:58:14,878 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:58:14,887 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:14,896 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:58:14,898 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:58:14,902 - snowflake.connector.cursor - INFO - Number of results in first chunk: 0\n",
      "2026-01-10 23:58:14,905 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:58:14,922 - snowflake.connector.cursor - INFO - query: [SELECT \"NDB_NO\" AS \"NDB_NO\", \"DESCRIP\" AS \"DESCRIP\", \"ENERGY_KCAL\" AS \"ENERGY_KC...]\n",
      "2026-01-10 23:58:14,925 - snowflake.connector.connection - DEBUG - sequence counter: 35\n",
      "2026-01-10 23:58:14,935 - snowflake.connector.cursor - DEBUG - Request id: 9e15db10-eaf8-4669-b4e0-e93a3d455245\n",
      "2026-01-10 23:58:14,965 - snowflake.connector.cursor - DEBUG - running query [SELECT \"NDB_NO\" AS \"NDB_NO\", \"DESCRIP\" AS \"DESCRIP\", \"ENERGY_KCAL\" AS \"ENERGY_KC...]\n",
      "2026-01-10 23:58:14,970 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:58:14,971 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:58:14,976 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:58:14,978 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085894789124, 0)\n",
      "2026-01-10 23:58:14,979 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085894789124, 'priority': 0, 'context': {'base64Data': 'CMad94Bw'}}]}\n",
      "2026-01-10 23:58:14,983 - snowflake.connector.connection - DEBUG - sql=[SELECT \"NDB_NO\" AS \"NDB_NO\", \"DESCRIP\" AS \"DESCRIP\", \"ENERGY_KCAL\" AS \"ENERGY_KC...], sequence_id=[35], is_file_transfer=[False]\n",
      "2026-01-10 23:58:14,988 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:58:14,994 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:58:15,002 - snowflake.connector.network - DEBUG - Request guid: 8fb78923-143a-4f0f-8a7f-5b7e5eb5650e\n",
      "2026-01-10 23:58:15,005 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:58:15,249 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=9e15db10-eaf8-4669-b4e0-e93a3d455245&request_guid=8fb78923-143a-4f0f-8a7f-5b7e5eb5650e HTTP/1.1\" 200 None\n",
      "2026-01-10 23:58:15,252 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:15,255 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:58:15,268 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:58:15,271 - snowflake.connector.network - DEBUG - Query id: 01c1a5c2-0307-73b1-0010-0853008609fa\n",
      "2026-01-10 23:58:15,279 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085895213097, 'priority': 0, 'context': 'CMad94Bw'}]}\n",
      "2026-01-10 23:58:15,285 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085894789124, 0)\n",
      "2026-01-10 23:58:15,287 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085895213097, 'priority': 0, 'context': 'CMad94Bw'}\n",
      "2026-01-10 23:58:15,290 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:58:15,304 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:15,309 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:15,333 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:58:15,335 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085895213097, 0)\n",
      "2026-01-10 23:58:15,336 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c2-0307-73b1-0010-0853008609fa\n",
      "2026-01-10 23:58:15,364 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:58:15,367 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:15,368 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:58:15,370 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:58:15,371 - snowflake.connector.cursor - INFO - Number of results in first chunk: 0\n",
      "2026-01-10 23:58:15,377 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:58:15,379 - snowflake.connector.cursor - INFO - query: [SELECT  *  FROM (( SELECT NULL :: BIGINT AS \"RECIPE_ID\", NULL :: STRING(16777216...]\n",
      "2026-01-10 23:58:15,383 - snowflake.connector.connection - DEBUG - sequence counter: 36\n",
      "2026-01-10 23:58:15,388 - snowflake.connector.cursor - DEBUG - Request id: b30c0c2e-64c9-4f8b-a307-5fc21f025c6e\n",
      "2026-01-10 23:58:15,472 - snowflake.connector.cursor - DEBUG - running query [SELECT  *  FROM (( SELECT NULL :: BIGINT AS \"RECIPE_ID\", NULL :: STRING(16777216...]\n",
      "2026-01-10 23:58:15,481 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:58:15,491 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:58:15,508 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:58:15,516 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085895213097, 0)\n",
      "2026-01-10 23:58:15,524 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085895213097, 'priority': 0, 'context': {'base64Data': 'CMad94Bw'}}]}\n",
      "2026-01-10 23:58:15,533 - snowflake.connector.connection - DEBUG - sql=[SELECT  *  FROM (( SELECT NULL :: BIGINT AS \"RECIPE_ID\", NULL :: STRING(16777216...], sequence_id=[36], is_file_transfer=[False]\n",
      "2026-01-10 23:58:15,544 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:58:15,583 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:58:15,596 - snowflake.connector.network - DEBUG - Request guid: e20d9c02-58cc-41af-8370-4caebc1026f3\n",
      "2026-01-10 23:58:15,601 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:58:15,814 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=b30c0c2e-64c9-4f8b-a307-5fc21f025c6e&request_guid=e20d9c02-58cc-41af-8370-4caebc1026f3 HTTP/1.1\" 200 None\n",
      "2026-01-10 23:58:15,844 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:15,849 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:58:15,869 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:58:15,873 - snowflake.connector.network - DEBUG - Query id: 01c1a5c2-0307-7557-0010-085300861b1e\n",
      "2026-01-10 23:58:15,886 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085895760199, 'priority': 0, 'context': 'CN6q94Bw'}]}\n",
      "2026-01-10 23:58:15,892 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085895213097, 0)\n",
      "2026-01-10 23:58:15,897 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085895760199, 'priority': 0, 'context': 'CN6q94Bw'}\n",
      "2026-01-10 23:58:15,900 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:58:15,903 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:15,909 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:15,919 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:58:15,929 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085895760199, 0)\n",
      "2026-01-10 23:58:15,933 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c2-0307-7557-0010-085300861b1e\n",
      "2026-01-10 23:58:15,946 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:58:15,960 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:15,966 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:58:15,969 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:58:15,976 - snowflake.connector.cursor - INFO - Number of results in first chunk: 0\n",
      "2026-01-10 23:58:15,997 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:58:16,004 - snowflake.connector.cursor - INFO - query: [SELECT \"ING_KEY\", \"ENERGY_KCAL\", \"PROTEIN_G\", \"FAT_G\", \"SATURATED_FATS_G\", \"CARB...]\n",
      "2026-01-10 23:58:16,015 - snowflake.connector.connection - DEBUG - sequence counter: 37\n",
      "2026-01-10 23:58:16,020 - snowflake.connector.cursor - DEBUG - Request id: ad672d81-ff14-47ee-9a26-bdce09992058\n",
      "2026-01-10 23:58:16,031 - snowflake.connector.cursor - DEBUG - running query [SELECT \"ING_KEY\", \"ENERGY_KCAL\", \"PROTEIN_G\", \"FAT_G\", \"SATURATED_FATS_G\", \"CARB...]\n",
      "2026-01-10 23:58:16,035 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:58:16,045 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:58:16,053 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:58:16,059 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085895760199, 0)\n",
      "2026-01-10 23:58:16,065 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085895760199, 'priority': 0, 'context': {'base64Data': 'CN6q94Bw'}}]}\n",
      "2026-01-10 23:58:16,078 - snowflake.connector.connection - DEBUG - sql=[SELECT \"ING_KEY\", \"ENERGY_KCAL\", \"PROTEIN_G\", \"FAT_G\", \"SATURATED_FATS_G\", \"CARB...], sequence_id=[37], is_file_transfer=[False]\n",
      "2026-01-10 23:58:16,085 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:58:16,095 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:58:16,233 - snowflake.connector.network - DEBUG - Request guid: 87bcfe24-a98c-429e-a84e-ef004651889b\n",
      "2026-01-10 23:58:16,240 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:58:16,445 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=ad672d81-ff14-47ee-9a26-bdce09992058&request_guid=87bcfe24-a98c-429e-a84e-ef004651889b HTTP/1.1\" 200 None\n",
      "2026-01-10 23:58:16,449 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:16,451 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:58:16,453 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:58:16,458 - snowflake.connector.network - DEBUG - Query id: 01c1a5c2-0307-7294-0010-08530086261e\n",
      "2026-01-10 23:58:16,460 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085896410089, 'priority': 0, 'context': 'CNKU94Bw'}]}\n",
      "2026-01-10 23:58:16,464 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085895760199, 0)\n",
      "2026-01-10 23:58:16,465 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085896410089, 'priority': 0, 'context': 'CNKU94Bw'}\n",
      "2026-01-10 23:58:16,467 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:58:16,470 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:16,472 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:16,503 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:58:16,511 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085896410089, 0)\n",
      "2026-01-10 23:58:16,515 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c2-0307-7294-0010-08530086261e\n",
      "2026-01-10 23:58:16,521 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:58:16,535 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:16,546 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:58:16,558 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:58:16,563 - snowflake.connector.cursor - INFO - Number of results in first chunk: 0\n",
      "2026-01-10 23:58:16,581 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:58:16,586 - snowflake.connector.cursor - INFO - query: [SELECT \"ING_KEY\", \"ENERGY_KCAL\", \"PROTEIN_G\", \"FAT_G\", \"SATURATED_FATS_G\", \"CARB...]\n",
      "2026-01-10 23:58:16,588 - snowflake.connector.connection - DEBUG - sequence counter: 38\n",
      "2026-01-10 23:58:16,593 - snowflake.connector.cursor - DEBUG - Request id: 3d8d9174-705c-41ce-928c-b3f64518a2fc\n",
      "2026-01-10 23:58:16,600 - snowflake.connector.cursor - DEBUG - running query [SELECT \"ING_KEY\", \"ENERGY_KCAL\", \"PROTEIN_G\", \"FAT_G\", \"SATURATED_FATS_G\", \"CARB...]\n",
      "2026-01-10 23:58:16,607 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:58:16,609 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:58:16,614 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:58:16,616 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085896410089, 0)\n",
      "2026-01-10 23:58:16,619 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085896410089, 'priority': 0, 'context': {'base64Data': 'CNKU94Bw'}}]}\n",
      "2026-01-10 23:58:16,627 - snowflake.connector.connection - DEBUG - sql=[SELECT \"ING_KEY\", \"ENERGY_KCAL\", \"PROTEIN_G\", \"FAT_G\", \"SATURATED_FATS_G\", \"CARB...], sequence_id=[38], is_file_transfer=[False]\n",
      "2026-01-10 23:58:16,633 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:58:16,637 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:58:16,640 - snowflake.connector.network - DEBUG - Request guid: bfd8a990-add5-48f5-909e-d3d45b94474f\n",
      "2026-01-10 23:58:16,642 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:58:17,791 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=3d8d9174-705c-41ce-928c-b3f64518a2fc&request_guid=bfd8a990-add5-48f5-909e-d3d45b94474f HTTP/1.1\" 200 None\n",
      "2026-01-10 23:58:17,944 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:17,956 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:58:17,960 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:58:17,963 - snowflake.connector.network - DEBUG - Query id: 01c1a5c2-0307-7557-0010-085300861b22\n",
      "2026-01-10 23:58:17,966 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085897648184, 'priority': 0, 'context': 'CN6q94Bw'}]}\n",
      "2026-01-10 23:58:17,969 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085896410089, 0)\n",
      "2026-01-10 23:58:17,975 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085897648184, 'priority': 0, 'context': 'CN6q94Bw'}\n",
      "2026-01-10 23:58:17,990 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:58:18,017 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:18,018 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:18,020 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:58:18,023 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085897648184, 0)\n",
      "2026-01-10 23:58:18,025 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c2-0307-7557-0010-085300861b22\n",
      "2026-01-10 23:58:18,028 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:58:18,031 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:18,032 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:58:18,035 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:58:18,038 - snowflake.connector.cursor - INFO - Number of results in first chunk: 0\n",
      "2026-01-10 23:58:18,048 - snowflake.snowpark._internal.server_connection - DEBUG - Execute query [queryID: 01c1a5c2-0307-7557-0010-085300861b22]  SELECT \"ING_KEY\", \"ENERGY_KCAL\", \"PROTEIN_G\", \"FAT_G\", \"SATURATED_FATS_G\", \"CARB_G\", \"FIBER_G\", \"SUGAR_G\", \"SODIUM_MG\", \"CALCIUM_MG\", \"IRON_MG\", \"MAGNESIUM_MG\", \"POTASSIUM_MG\", \"VITC_MG\" FROM ( SELECT \"ING_KEY\", \"ENERGY_KCAL\", \"PROTEIN_G\", \"FAT_G\", \"SATURATED_FATS_G\", \"CARB_G\", \"FIBER_G\", \"SUGAR_G\", \"SODIUM_MG\", \"CALCIUM_MG\", \"IRON_MG\", \"MAGNESIUM_MG\", \"POTASSIUM_MG\", \"VITC_MG\", \"SCORE_SANTE\", row_number() OVER (PARTITION BY \"ING_KEY\"  ORDER BY \"SCORE_SANTE\" DESC NULLS LAST ) AS \"RN\" FROM ( SELECT  *  FROM (( SELECT \"RECIPE_ID\" AS \"RECIPE_ID\", \"INGREDIENT_FROM_RECIPE_NAME\" AS \"INGREDIENT_FROM_RECIPE_NAME\", \"INGREDIENT_ID\" AS \"INGREDIENT_ID\", \"ING_KEY\" AS \"ING_KEY\" FROM ( SELECT \"RECIPE_ID\", \"INGREDIENT_FROM_RECIPE_NAME\", \"INGREDIENT_ID\", lower(trim(\"INGREDIENT_FROM_RECIPE_NAME\")) AS \"ING_KEY\" FROM NUTRIRAG_PROJECT.RAW.INGREDIENTS_MATCHING WHERE (\"RECIPE_ID\" = 94947 :: INT)) WHERE \"ING_KEY\" IN ('cream sour cultured')) AS SNOWPARK_LEFT LEFT OUTER JOIN ( SELECT \"NDB_NO\" AS \"NDB_NO\", \"DESCRIP\" AS \"DESCRIP\", \"ENERGY_KCAL\" AS \"ENERGY_KCAL\", \"PROTEIN_G\" AS \"PROTEIN_G\", \"SATURATED_FATS_G\" AS \"SATURATED_FATS_G\", \"FAT_G\" AS \"FAT_G\", \"CARB_G\" AS \"CARB_G\", \"FIBER_G\" AS \"FIBER_G\", \"SUGAR_G\" AS \"SUGAR_G\", \"CALCIUM_MG\" AS \"CALCIUM_MG\", \"IRON_MG\" AS \"IRON_MG\", \"PHOSPHORUS_MG\" AS \"PHOSPHORUS_MG\", \"POTASSIUM_MG\" AS \"POTASSIUM_MG\", \"SODIUM_MG\" AS \"SODIUM_MG\", \"ZINC_MG\" AS \"ZINC_MG\", \"COPPER_MCG\" AS \"COPPER_MCG\", \"MANGANESE_MG\" AS \"MANGANESE_MG\", \"SELENIUM_MCG\" AS \"SELENIUM_MCG\", \"VITC_MG\" AS \"VITC_MG\", \"THIAMIN_MG\" AS \"THIAMIN_MG\", \"RIBOFLAVIN_MG\" AS \"RIBOFLAVIN_MG\", \"NIACIN_MG\" AS \"NIACIN_MG\", \"VITB6_MG\" AS \"VITB6_MG\", \"FOLATE_MCG\" AS \"FOLATE_MCG\", \"VITB12_MCG\" AS \"VITB12_MCG\", \"VITA_MCG\" AS \"VITA_MCG\", \"MAGNESIUM_MG\" AS \"MAGNESIUM_MG\", \"SCORE_SANTE\" AS \"SCORE_SANTE\" FROM NUTRIRAG_PROJECT.RAW.CLEANED_INGREDIENTS) AS SNOWPARK_RIGHT ON (\"INGREDIENT_ID\" = \"NDB_NO\")))) WHERE (\"RN\" = 1 :: INT)\n",
      "2026-01-10 23:58:18,053 - snowflake.connector.result_set - DEBUG - beginning to schedule result batch downloads\n",
      "2026-01-10 23:58:18,056 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:58:18,060 - snowflake.connector.cursor - INFO - query: [SELECT  *  FROM NUTRIRAG_PROJECT.RAW.INGREDIENTS_MATCHING]\n",
      "2026-01-10 23:58:18,065 - snowflake.connector.connection - DEBUG - sequence counter: 39\n",
      "2026-01-10 23:58:18,067 - snowflake.connector.cursor - DEBUG - Request id: 74feaf9b-a87d-42a7-a3ca-a303113e11a2\n",
      "2026-01-10 23:58:18,068 - snowflake.connector.cursor - DEBUG - running query [SELECT  *  FROM NUTRIRAG_PROJECT.RAW.INGREDIENTS_MATCHING]\n",
      "2026-01-10 23:58:18,072 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:58:18,081 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:58:18,083 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:58:18,084 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085897648184, 0)\n",
      "2026-01-10 23:58:18,087 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085897648184, 'priority': 0, 'context': {'base64Data': 'CN6q94Bw'}}]}\n",
      "2026-01-10 23:58:18,091 - snowflake.connector.connection - DEBUG - sql=[SELECT  *  FROM NUTRIRAG_PROJECT.RAW.INGREDIENTS_MATCHING], sequence_id=[39], is_file_transfer=[False]\n",
      "2026-01-10 23:58:18,094 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:58:18,097 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:58:18,100 - snowflake.connector.network - DEBUG - Request guid: b6dad8ba-31aa-4998-94be-8ae46a475317\n",
      "2026-01-10 23:58:18,101 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:58:18,297 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=74feaf9b-a87d-42a7-a3ca-a303113e11a2&request_guid=b6dad8ba-31aa-4998-94be-8ae46a475317 HTTP/1.1\" 200 None\n",
      "2026-01-10 23:58:18,342 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:18,347 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:58:18,492 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:58:18,508 - snowflake.connector.network - DEBUG - Query id: 01c1a5c2-0307-7294-0010-085300862622\n",
      "2026-01-10 23:58:18,514 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085898256664, 'priority': 0, 'context': 'CNKU94Bw'}]}\n",
      "2026-01-10 23:58:18,525 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085897648184, 0)\n",
      "2026-01-10 23:58:18,529 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085898256664, 'priority': 0, 'context': 'CNKU94Bw'}\n",
      "2026-01-10 23:58:18,538 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:58:18,550 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:18,558 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:18,567 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:58:18,573 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085898256664, 0)\n",
      "2026-01-10 23:58:18,576 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c2-0307-7294-0010-085300862622\n",
      "2026-01-10 23:58:18,579 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:58:18,584 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:18,590 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:58:18,595 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:58:18,598 - snowflake.connector.cursor - INFO - Number of results in first chunk: 0\n",
      "2026-01-10 23:58:18,604 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:58:18,637 - snowflake.connector.cursor - INFO - query: [SELECT \"RECIPE_ID\", \"INGREDIENT_FROM_RECIPE_NAME\", \"INGREDIENT_ID\", lower(trim(\"...]\n",
      "2026-01-10 23:58:18,720 - snowflake.connector.connection - DEBUG - sequence counter: 40\n",
      "2026-01-10 23:58:18,725 - snowflake.connector.cursor - DEBUG - Request id: 6fec3fd4-2818-481c-9fef-c5eef8b4e28d\n",
      "2026-01-10 23:58:18,729 - snowflake.connector.cursor - DEBUG - running query [SELECT \"RECIPE_ID\", \"INGREDIENT_FROM_RECIPE_NAME\", \"INGREDIENT_ID\", lower(trim(\"...]\n",
      "2026-01-10 23:58:18,741 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:58:18,744 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:58:18,752 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:58:18,762 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085898256664, 0)\n",
      "2026-01-10 23:58:18,771 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085898256664, 'priority': 0, 'context': {'base64Data': 'CNKU94Bw'}}]}\n",
      "2026-01-10 23:58:18,778 - snowflake.connector.connection - DEBUG - sql=[SELECT \"RECIPE_ID\", \"INGREDIENT_FROM_RECIPE_NAME\", \"INGREDIENT_ID\", lower(trim(\"...], sequence_id=[40], is_file_transfer=[False]\n",
      "2026-01-10 23:58:18,797 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:58:18,830 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:58:18,856 - snowflake.connector.network - DEBUG - Request guid: d8f223dc-2792-4925-9f8d-72087dff546f\n",
      "2026-01-10 23:58:18,880 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:58:19,090 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=6fec3fd4-2818-481c-9fef-c5eef8b4e28d&request_guid=d8f223dc-2792-4925-9f8d-72087dff546f HTTP/1.1\" 200 None\n",
      "2026-01-10 23:58:19,100 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:19,104 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:58:19,108 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:58:19,110 - snowflake.connector.network - DEBUG - Query id: 01c1a5c2-0307-73b1-0010-0853008609fe\n",
      "2026-01-10 23:58:19,115 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085899050325, 'priority': 0, 'context': 'CMad94Bw'}]}\n",
      "2026-01-10 23:58:19,116 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085898256664, 0)\n",
      "2026-01-10 23:58:19,121 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085899050325, 'priority': 0, 'context': 'CMad94Bw'}\n",
      "2026-01-10 23:58:19,125 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:58:19,129 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:19,130 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:19,132 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:58:19,135 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085899050325, 0)\n",
      "2026-01-10 23:58:19,137 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c2-0307-73b1-0010-0853008609fe\n",
      "2026-01-10 23:58:19,138 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:58:19,140 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:19,143 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:58:19,144 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:58:19,146 - snowflake.connector.cursor - INFO - Number of results in first chunk: 0\n",
      "2026-01-10 23:58:19,149 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:58:19,152 - snowflake.connector.cursor - INFO - query: [SELECT  *  FROM NUTRIRAG_PROJECT.RAW.CLEANED_INGREDIENTS]\n",
      "2026-01-10 23:58:19,154 - snowflake.connector.connection - DEBUG - sequence counter: 41\n",
      "2026-01-10 23:58:19,156 - snowflake.connector.cursor - DEBUG - Request id: 7a643ab8-5bd2-4d1e-a705-00f1a4da0eaa\n",
      "2026-01-10 23:58:19,161 - snowflake.connector.cursor - DEBUG - running query [SELECT  *  FROM NUTRIRAG_PROJECT.RAW.CLEANED_INGREDIENTS]\n",
      "2026-01-10 23:58:19,163 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:58:19,165 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:58:19,167 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:58:19,168 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085899050325, 0)\n",
      "2026-01-10 23:58:19,169 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085899050325, 'priority': 0, 'context': {'base64Data': 'CMad94Bw'}}]}\n",
      "2026-01-10 23:58:19,170 - snowflake.connector.connection - DEBUG - sql=[SELECT  *  FROM NUTRIRAG_PROJECT.RAW.CLEANED_INGREDIENTS], sequence_id=[41], is_file_transfer=[False]\n",
      "2026-01-10 23:58:19,173 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:58:19,174 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:58:19,176 - snowflake.connector.network - DEBUG - Request guid: 64e8a216-0f2b-485a-9855-b426f65d3d4a\n",
      "2026-01-10 23:58:19,179 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:58:19,379 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=7a643ab8-5bd2-4d1e-a705-00f1a4da0eaa&request_guid=64e8a216-0f2b-485a-9855-b426f65d3d4a HTTP/1.1\" 200 None\n",
      "2026-01-10 23:58:19,382 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:19,389 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:58:19,391 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:58:19,393 - snowflake.connector.network - DEBUG - Query id: 01c1a5c2-0307-7557-0010-085300861b26\n",
      "2026-01-10 23:58:19,394 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085899341344, 'priority': 0, 'context': 'CN6q94Bw'}]}\n",
      "2026-01-10 23:58:19,396 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085899050325, 0)\n",
      "2026-01-10 23:58:19,399 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085899341344, 'priority': 0, 'context': 'CN6q94Bw'}\n",
      "2026-01-10 23:58:19,400 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:58:19,401 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:19,403 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:19,405 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:58:19,407 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085899341344, 0)\n",
      "2026-01-10 23:58:19,409 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c2-0307-7557-0010-085300861b26\n",
      "2026-01-10 23:58:19,410 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:58:19,412 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:19,413 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:58:19,415 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:58:19,416 - snowflake.connector.cursor - INFO - Number of results in first chunk: 0\n",
      "2026-01-10 23:58:19,421 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:58:19,423 - snowflake.connector.cursor - INFO - query: [SELECT \"RECIPE_ID\" AS \"RECIPE_ID\", \"INGREDIENT_FROM_RECIPE_NAME\" AS \"INGREDIENT_...]\n",
      "2026-01-10 23:58:19,425 - snowflake.connector.connection - DEBUG - sequence counter: 42\n",
      "2026-01-10 23:58:19,427 - snowflake.connector.cursor - DEBUG - Request id: e1e72072-0fcf-497a-8b5b-66c99d0ef448\n",
      "2026-01-10 23:58:19,428 - snowflake.connector.cursor - DEBUG - running query [SELECT \"RECIPE_ID\" AS \"RECIPE_ID\", \"INGREDIENT_FROM_RECIPE_NAME\" AS \"INGREDIENT_...]\n",
      "2026-01-10 23:58:19,430 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:58:19,431 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:58:19,432 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:58:19,434 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085899341344, 0)\n",
      "2026-01-10 23:58:19,436 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085899341344, 'priority': 0, 'context': {'base64Data': 'CN6q94Bw'}}]}\n",
      "2026-01-10 23:58:19,438 - snowflake.connector.connection - DEBUG - sql=[SELECT \"RECIPE_ID\" AS \"RECIPE_ID\", \"INGREDIENT_FROM_RECIPE_NAME\" AS \"INGREDIENT_...], sequence_id=[42], is_file_transfer=[False]\n",
      "2026-01-10 23:58:19,439 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:58:19,441 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:58:19,442 - snowflake.connector.network - DEBUG - Request guid: 4e2e1da3-ba8f-4480-866b-c957718b69bd\n",
      "2026-01-10 23:58:19,443 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:58:19,702 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=e1e72072-0fcf-497a-8b5b-66c99d0ef448&request_guid=4e2e1da3-ba8f-4480-866b-c957718b69bd HTTP/1.1\" 200 None\n",
      "2026-01-10 23:58:19,710 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:19,713 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:58:19,716 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:58:19,719 - snowflake.connector.network - DEBUG - Query id: 01c1a5c2-0307-74b8-0010-08530086323a\n",
      "2026-01-10 23:58:19,721 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085899598405, 'priority': 0, 'context': 'COKl94Bw'}]}\n",
      "2026-01-10 23:58:19,766 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085899341344, 0)\n",
      "2026-01-10 23:58:19,769 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085899598405, 'priority': 0, 'context': 'COKl94Bw'}\n",
      "2026-01-10 23:58:19,770 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:58:19,774 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:19,782 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:19,799 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:58:19,801 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085899598405, 0)\n",
      "2026-01-10 23:58:19,804 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c2-0307-74b8-0010-08530086323a\n",
      "2026-01-10 23:58:19,806 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:58:19,810 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:19,835 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:58:19,836 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:58:19,837 - snowflake.connector.cursor - INFO - Number of results in first chunk: 0\n",
      "2026-01-10 23:58:19,865 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:58:19,867 - snowflake.connector.cursor - INFO - query: [SELECT \"NDB_NO\" AS \"NDB_NO\", \"DESCRIP\" AS \"DESCRIP\", \"ENERGY_KCAL\" AS \"ENERGY_KC...]\n",
      "2026-01-10 23:58:19,871 - snowflake.connector.connection - DEBUG - sequence counter: 43\n",
      "2026-01-10 23:58:19,875 - snowflake.connector.cursor - DEBUG - Request id: e1f046b8-3e01-41d9-8c5f-5f43bae71222\n",
      "2026-01-10 23:58:19,879 - snowflake.connector.cursor - DEBUG - running query [SELECT \"NDB_NO\" AS \"NDB_NO\", \"DESCRIP\" AS \"DESCRIP\", \"ENERGY_KCAL\" AS \"ENERGY_KC...]\n",
      "2026-01-10 23:58:19,884 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:58:19,888 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:58:19,894 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:58:19,903 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085899598405, 0)\n",
      "2026-01-10 23:58:19,908 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085899598405, 'priority': 0, 'context': {'base64Data': 'COKl94Bw'}}]}\n",
      "2026-01-10 23:58:19,911 - snowflake.connector.connection - DEBUG - sql=[SELECT \"NDB_NO\" AS \"NDB_NO\", \"DESCRIP\" AS \"DESCRIP\", \"ENERGY_KCAL\" AS \"ENERGY_KC...], sequence_id=[43], is_file_transfer=[False]\n",
      "2026-01-10 23:58:19,915 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:58:19,935 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:58:19,942 - snowflake.connector.network - DEBUG - Request guid: 7355d88b-ea39-4aaa-ba00-cea22aab1c85\n",
      "2026-01-10 23:58:19,949 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:58:20,144 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=e1f046b8-3e01-41d9-8c5f-5f43bae71222&request_guid=7355d88b-ea39-4aaa-ba00-cea22aab1c85 HTTP/1.1\" 200 None\n",
      "2026-01-10 23:58:20,153 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:20,155 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:58:20,160 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:58:20,164 - snowflake.connector.network - DEBUG - Query id: 01c1a5c2-0307-7294-0010-085300862626\n",
      "2026-01-10 23:58:20,165 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085900110149, 'priority': 0, 'context': 'CNKU94Bw'}]}\n",
      "2026-01-10 23:58:20,173 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085899598405, 0)\n",
      "2026-01-10 23:58:20,185 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085900110149, 'priority': 0, 'context': 'CNKU94Bw'}\n",
      "2026-01-10 23:58:20,194 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:58:20,215 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:20,219 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:20,224 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:58:20,232 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085900110149, 0)\n",
      "2026-01-10 23:58:20,235 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c2-0307-7294-0010-085300862626\n",
      "2026-01-10 23:58:20,259 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:58:20,266 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:20,276 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:58:20,282 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:58:20,312 - snowflake.connector.cursor - INFO - Number of results in first chunk: 0\n",
      "2026-01-10 23:58:20,324 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:58:20,340 - snowflake.connector.cursor - INFO - query: [SELECT  *  FROM (( SELECT NULL :: BIGINT AS \"RECIPE_ID\", NULL :: STRING(16777216...]\n",
      "2026-01-10 23:58:20,350 - snowflake.connector.connection - DEBUG - sequence counter: 44\n",
      "2026-01-10 23:58:20,390 - snowflake.connector.cursor - DEBUG - Request id: dbc00e18-15fa-47b1-b9fc-72506c0f7685\n",
      "2026-01-10 23:58:20,408 - snowflake.connector.cursor - DEBUG - running query [SELECT  *  FROM (( SELECT NULL :: BIGINT AS \"RECIPE_ID\", NULL :: STRING(16777216...]\n",
      "2026-01-10 23:58:20,437 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:58:20,444 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:58:20,461 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:58:20,471 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085900110149, 0)\n",
      "2026-01-10 23:58:20,476 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085900110149, 'priority': 0, 'context': {'base64Data': 'CNKU94Bw'}}]}\n",
      "2026-01-10 23:58:20,479 - snowflake.connector.connection - DEBUG - sql=[SELECT  *  FROM (( SELECT NULL :: BIGINT AS \"RECIPE_ID\", NULL :: STRING(16777216...], sequence_id=[44], is_file_transfer=[False]\n",
      "2026-01-10 23:58:20,505 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:58:20,584 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:58:20,599 - snowflake.connector.network - DEBUG - Request guid: 1df113ac-bca9-44ae-a88f-60bf828ef7f4\n",
      "2026-01-10 23:58:20,601 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:58:20,840 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=dbc00e18-15fa-47b1-b9fc-72506c0f7685&request_guid=1df113ac-bca9-44ae-a88f-60bf828ef7f4 HTTP/1.1\" 200 None\n",
      "2026-01-10 23:58:20,845 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:20,849 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:58:20,853 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:58:20,857 - snowflake.connector.network - DEBUG - Query id: 01c1a5c2-0307-74b8-0010-08530086323e\n",
      "2026-01-10 23:58:20,863 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085900781164, 'priority': 0, 'context': 'COKl94Bw'}]}\n",
      "2026-01-10 23:58:20,868 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085900110149, 0)\n",
      "2026-01-10 23:58:20,873 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085900781164, 'priority': 0, 'context': 'COKl94Bw'}\n",
      "2026-01-10 23:58:20,878 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:58:20,881 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:20,886 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:20,890 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:58:20,898 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085900781164, 0)\n",
      "2026-01-10 23:58:20,904 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c2-0307-74b8-0010-08530086323e\n",
      "2026-01-10 23:58:20,912 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:58:20,918 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:20,928 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:58:20,934 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:58:20,936 - snowflake.connector.cursor - INFO - Number of results in first chunk: 0\n",
      "2026-01-10 23:58:20,946 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:58:20,963 - snowflake.connector.cursor - INFO - query: [SELECT \"ING_KEY\", \"ENERGY_KCAL\", \"PROTEIN_G\", \"FAT_G\", \"SATURATED_FATS_G\", \"CARB...]\n",
      "2026-01-10 23:58:20,967 - snowflake.connector.connection - DEBUG - sequence counter: 45\n",
      "2026-01-10 23:58:20,976 - snowflake.connector.cursor - DEBUG - Request id: f98118bb-b8b8-4c9d-8365-e163c18682e9\n",
      "2026-01-10 23:58:20,986 - snowflake.connector.cursor - DEBUG - running query [SELECT \"ING_KEY\", \"ENERGY_KCAL\", \"PROTEIN_G\", \"FAT_G\", \"SATURATED_FATS_G\", \"CARB...]\n",
      "2026-01-10 23:58:21,101 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:58:21,117 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:58:21,127 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:58:21,164 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085900781164, 0)\n",
      "2026-01-10 23:58:21,168 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085900781164, 'priority': 0, 'context': {'base64Data': 'COKl94Bw'}}]}\n",
      "2026-01-10 23:58:21,187 - snowflake.connector.connection - DEBUG - sql=[SELECT \"ING_KEY\", \"ENERGY_KCAL\", \"PROTEIN_G\", \"FAT_G\", \"SATURATED_FATS_G\", \"CARB...], sequence_id=[45], is_file_transfer=[False]\n",
      "2026-01-10 23:58:21,234 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:58:21,251 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:58:21,255 - snowflake.connector.network - DEBUG - Request guid: 7e605202-c6a0-438a-8bfd-a4d8e8081c99\n",
      "2026-01-10 23:58:21,265 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:58:21,469 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=f98118bb-b8b8-4c9d-8365-e163c18682e9&request_guid=7e605202-c6a0-438a-8bfd-a4d8e8081c99 HTTP/1.1\" 200 None\n",
      "2026-01-10 23:58:21,478 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:21,483 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:58:21,486 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:58:21,491 - snowflake.connector.network - DEBUG - Query id: 01c1a5c2-0307-74b8-0010-085300863242\n",
      "2026-01-10 23:58:21,494 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085901431478, 'priority': 0, 'context': 'COKl94Bw'}]}\n",
      "2026-01-10 23:58:21,498 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085900781164, 0)\n",
      "2026-01-10 23:58:21,500 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085901431478, 'priority': 0, 'context': 'COKl94Bw'}\n",
      "2026-01-10 23:58:21,503 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:58:21,506 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:21,511 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:21,517 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:58:21,521 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085901431478, 0)\n",
      "2026-01-10 23:58:21,532 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c2-0307-74b8-0010-085300863242\n",
      "2026-01-10 23:58:21,538 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:58:21,542 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:21,547 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:58:21,561 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:58:21,566 - snowflake.connector.cursor - INFO - Number of results in first chunk: 0\n",
      "2026-01-10 23:58:21,574 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:58:21,580 - snowflake.connector.cursor - INFO - query: [SELECT \"ING_KEY\", \"ENERGY_KCAL\", \"PROTEIN_G\", \"FAT_G\", \"SATURATED_FATS_G\", \"CARB...]\n",
      "2026-01-10 23:58:21,584 - snowflake.connector.connection - DEBUG - sequence counter: 46\n",
      "2026-01-10 23:58:21,592 - snowflake.connector.cursor - DEBUG - Request id: cf78b2a2-68fa-45e4-8c42-89dcc5224e5e\n",
      "2026-01-10 23:58:21,597 - snowflake.connector.cursor - DEBUG - running query [SELECT \"ING_KEY\", \"ENERGY_KCAL\", \"PROTEIN_G\", \"FAT_G\", \"SATURATED_FATS_G\", \"CARB...]\n",
      "2026-01-10 23:58:21,611 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:58:21,743 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:58:21,751 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:58:21,756 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085901431478, 0)\n",
      "2026-01-10 23:58:21,761 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085901431478, 'priority': 0, 'context': {'base64Data': 'COKl94Bw'}}]}\n",
      "2026-01-10 23:58:21,766 - snowflake.connector.connection - DEBUG - sql=[SELECT \"ING_KEY\", \"ENERGY_KCAL\", \"PROTEIN_G\", \"FAT_G\", \"SATURATED_FATS_G\", \"CARB...], sequence_id=[46], is_file_transfer=[False]\n",
      "2026-01-10 23:58:21,770 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:58:21,774 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:58:21,777 - snowflake.connector.network - DEBUG - Request guid: 2970ba98-35ea-4997-986f-7188e02c3488\n",
      "2026-01-10 23:58:21,784 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:58:22,038 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=cf78b2a2-68fa-45e4-8c42-89dcc5224e5e&request_guid=2970ba98-35ea-4997-986f-7188e02c3488 HTTP/1.1\" 200 None\n",
      "2026-01-10 23:58:22,043 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:22,050 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:58:22,053 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:58:22,058 - snowflake.connector.network - DEBUG - Query id: 01c1a5c2-0307-73b1-0010-085300860a02\n",
      "2026-01-10 23:58:22,061 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085902000724, 'priority': 0, 'context': 'CMad94Bw'}]}\n",
      "2026-01-10 23:58:22,064 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085901431478, 0)\n",
      "2026-01-10 23:58:22,069 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085902000724, 'priority': 0, 'context': 'CMad94Bw'}\n",
      "2026-01-10 23:58:22,073 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:58:22,076 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:22,079 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:22,082 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:58:22,085 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085902000724, 0)\n",
      "2026-01-10 23:58:22,088 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c2-0307-73b1-0010-085300860a02\n",
      "2026-01-10 23:58:22,093 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:58:22,097 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:22,100 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:58:22,102 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:58:22,105 - snowflake.connector.cursor - INFO - Number of results in first chunk: 0\n",
      "2026-01-10 23:58:22,108 - snowflake.snowpark._internal.server_connection - DEBUG - Execute query [queryID: 01c1a5c2-0307-73b1-0010-085300860a02]  SELECT \"ING_KEY\", \"ENERGY_KCAL\", \"PROTEIN_G\", \"FAT_G\", \"SATURATED_FATS_G\", \"CARB_G\", \"FIBER_G\", \"SUGAR_G\", \"SODIUM_MG\", \"CALCIUM_MG\", \"IRON_MG\", \"MAGNESIUM_MG\", \"POTASSIUM_MG\", \"VITC_MG\" FROM ( SELECT \"ING_KEY\", \"ENERGY_KCAL\", \"PROTEIN_G\", \"FAT_G\", \"SATURATED_FATS_G\", \"CARB_G\", \"FIBER_G\", \"SUGAR_G\", \"SODIUM_MG\", \"CALCIUM_MG\", \"IRON_MG\", \"MAGNESIUM_MG\", \"POTASSIUM_MG\", \"VITC_MG\", \"SCORE_SANTE\", row_number() OVER (PARTITION BY \"ING_KEY\"  ORDER BY \"SCORE_SANTE\" DESC NULLS LAST ) AS \"RN\" FROM ( SELECT  *  FROM (( SELECT \"RECIPE_ID\" AS \"RECIPE_ID\", \"INGREDIENT_FROM_RECIPE_NAME\" AS \"INGREDIENT_FROM_RECIPE_NAME\", \"INGREDIENT_ID\" AS \"INGREDIENT_ID\", \"ING_KEY\" AS \"ING_KEY\" FROM ( SELECT \"RECIPE_ID\", \"INGREDIENT_FROM_RECIPE_NAME\", \"INGREDIENT_ID\", lower(trim(\"INGREDIENT_FROM_RECIPE_NAME\")) AS \"ING_KEY\" FROM NUTRIRAG_PROJECT.RAW.INGREDIENTS_MATCHING WHERE (\"RECIPE_ID\" = 94947 :: INT)) WHERE \"ING_KEY\" IN ('ham salad spread')) AS SNOWPARK_LEFT LEFT OUTER JOIN ( SELECT \"NDB_NO\" AS \"NDB_NO\", \"DESCRIP\" AS \"DESCRIP\", \"ENERGY_KCAL\" AS \"ENERGY_KCAL\", \"PROTEIN_G\" AS \"PROTEIN_G\", \"SATURATED_FATS_G\" AS \"SATURATED_FATS_G\", \"FAT_G\" AS \"FAT_G\", \"CARB_G\" AS \"CARB_G\", \"FIBER_G\" AS \"FIBER_G\", \"SUGAR_G\" AS \"SUGAR_G\", \"CALCIUM_MG\" AS \"CALCIUM_MG\", \"IRON_MG\" AS \"IRON_MG\", \"PHOSPHORUS_MG\" AS \"PHOSPHORUS_MG\", \"POTASSIUM_MG\" AS \"POTASSIUM_MG\", \"SODIUM_MG\" AS \"SODIUM_MG\", \"ZINC_MG\" AS \"ZINC_MG\", \"COPPER_MCG\" AS \"COPPER_MCG\", \"MANGANESE_MG\" AS \"MANGANESE_MG\", \"SELENIUM_MCG\" AS \"SELENIUM_MCG\", \"VITC_MG\" AS \"VITC_MG\", \"THIAMIN_MG\" AS \"THIAMIN_MG\", \"RIBOFLAVIN_MG\" AS \"RIBOFLAVIN_MG\", \"NIACIN_MG\" AS \"NIACIN_MG\", \"VITB6_MG\" AS \"VITB6_MG\", \"FOLATE_MCG\" AS \"FOLATE_MCG\", \"VITB12_MCG\" AS \"VITB12_MCG\", \"VITA_MCG\" AS \"VITA_MCG\", \"MAGNESIUM_MG\" AS \"MAGNESIUM_MG\", \"SCORE_SANTE\" AS \"SCORE_SANTE\" FROM NUTRIRAG_PROJECT.RAW.CLEANED_INGREDIENTS) AS SNOWPARK_RIGHT ON (\"INGREDIENT_ID\" = \"NDB_NO\")))) WHERE (\"RN\" = 1 :: INT)\n",
      "2026-01-10 23:58:22,112 - snowflake.connector.result_set - DEBUG - beginning to schedule result batch downloads\n",
      "2026-01-10 23:58:22,122 - root - INFO - Success: Found substitute for cheese cream low fat → sour cream reduced fat (PCA score: 0.257)\n",
      "2026-01-10 23:58:22,126 - root - INFO - Substitution: Found substitute sour cream reduced fat with nutrition calories=0.0 protein_g=0.0 saturated_fats_g=0.0 fat_g=0.0 carb_g=0.0 fiber_g=0.0 sodium_mg=0.0 sugar_g=0.0 iron_mg=0.0 calcium_mg=0.0 magnesium_mg=0.0 potassium_mg=0.0 vitamin_c_mg=0.0 health_score=0.0.\n",
      "2026-01-10 23:58:22,132 - root - INFO - Substitution: Updating the new_recipe (ingredients and health score).\n",
      "2026-01-10 23:58:22,138 - root - INFO - Success: Step 2 finished for Substitution (Subtitute ingredients found for eache ingredients to remove).\n",
      "2026-01-10 23:58:22,144 - root - INFO - LLM response: <snowflake.snowpark.dataframe.DataFrame object at 0x11e8bbd50>\n",
      "2026-01-10 23:58:22,150 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:58:22,152 - snowflake.connector.cursor - INFO - query: [SELECT SNOWFLAKE.CORTEX.COMPLETE( 'mixtral-8x7b', 'You are an expert chef specia...]\n",
      "2026-01-10 23:58:22,175 - snowflake.connector.connection - DEBUG - sequence counter: 47\n",
      "2026-01-10 23:58:22,184 - snowflake.connector.cursor - DEBUG - Request id: e722ebe0-8e1d-43ea-9209-7df2aaec4dd7\n",
      "2026-01-10 23:58:22,191 - snowflake.connector.cursor - DEBUG - running query [SELECT SNOWFLAKE.CORTEX.COMPLETE( 'mixtral-8x7b', 'You are an expert chef specia...]\n",
      "2026-01-10 23:58:22,196 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:58:22,203 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:58:22,206 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:58:22,209 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085902000724, 0)\n",
      "2026-01-10 23:58:22,212 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085902000724, 'priority': 0, 'context': {'base64Data': 'CMad94Bw'}}]}\n",
      "2026-01-10 23:58:22,217 - snowflake.connector.connection - DEBUG - sql=[SELECT SNOWFLAKE.CORTEX.COMPLETE( 'mixtral-8x7b', 'You are an expert chef specia...], sequence_id=[47], is_file_transfer=[False]\n",
      "2026-01-10 23:58:22,221 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:58:22,225 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:58:22,229 - snowflake.connector.network - DEBUG - Request guid: 284c93c8-b414-4636-8c44-412d37eb0ec3\n",
      "2026-01-10 23:58:22,232 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:58:26,272 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=e722ebe0-8e1d-43ea-9209-7df2aaec4dd7&request_guid=284c93c8-b414-4636-8c44-412d37eb0ec3 HTTP/1.1\" 200 None\n",
      "2026-01-10 23:58:26,277 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:26,279 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:58:26,281 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:58:26,282 - snowflake.connector.network - DEBUG - Query id: 01c1a5c2-0307-7294-0010-08530086262a\n",
      "2026-01-10 23:58:26,283 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085906170684, 'priority': 0, 'context': 'CNKU94Bw'}]}\n",
      "2026-01-10 23:58:26,284 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085902000724, 0)\n",
      "2026-01-10 23:58:26,286 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085906170684, 'priority': 0, 'context': 'CNKU94Bw'}\n",
      "2026-01-10 23:58:26,287 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:58:26,289 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:26,316 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:26,318 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:58:26,320 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085906170684, 0)\n",
      "2026-01-10 23:58:26,321 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c2-0307-7294-0010-08530086262a\n",
      "2026-01-10 23:58:26,327 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:58:26,329 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:26,341 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:58:26,353 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:58:26,356 - snowflake.connector.cursor - INFO - Number of results in first chunk: 1\n",
      "2026-01-10 23:58:26,359 - snowflake.snowpark._internal.server_connection - DEBUG - Execute query [queryID: 01c1a5c2-0307-7294-0010-08530086262a] \n",
      "                SELECT SNOWFLAKE.CORTEX.COMPLETE(\n",
      "                    'mixtral-8x7b',\n",
      "                   'You are an expert chef specializing in recipe adaptation and ingredient substitution.\n",
      "\n",
      "        ORIGINAL RECIPE:\n",
      "        Name: crab filled crescent snacks\n",
      "        Ingredients: [''crabmeat'', ''sour cream reduced fat'', ''green onions'', ''garlic salt'', ''refrigerated crescent dinner rolls'', ''egg yolk'', ''water'', ''sesame seeds'', ''sweet and sour sauce'']\n",
      "        Steps: [''heat over to 375 degrees'', ''spray large cookie sheet with non-stick cooking spray'', ''in small bowl , combine crabmeat , cream cheese , onions and garlic salt and mix well'', ''unroll both cans of dough'', ''separate into 16 triangles'', ''cut each triangle in half lengthwise to make 32 triangles'', ''place 1 teaspoon crab mixture on center of each triangle about 1 inch from short side of triangle'', ''fold short ends of each triangle over filling'', ''pinch sides to seal'', ''roll up'', ''place on sprayed cookie sheet'', ''in small bowl , combine egg yolk and water and mix well'', ''brush egg mixture over snacks'', ''sprinkle with sesame seed'', ''bake at 375 degrees for 15 to 20 minutes or until golden brown'', ''serve warn snacks with sweet-and-sour sauce'']\n",
      "\n",
      "        SUBSTITUTIONS TO APPLY:\n",
      "        - Replace ''cream cheese'' with ''sour cream reduced fat''\n",
      "\n",
      "        YOUR TASK:\n",
      "        Adapt the recipe steps to incorporate these ingredient substitutions while maintaining the dish''s quality and integrity.\n",
      "\n",
      "        ADAPTATION GUIDELINES:\n",
      "        1. Modify ONLY the preparation steps that are affected by the substitutions\n",
      "        2. Preserve the original step numbering and structure\n",
      "        3. Adjust cooking times if the substitute cooks faster/slower than the original\n",
      "        4. Adjust temperatures if the substitute requires different heat levels\n",
      "        5. Note any texture or consistency changes that may occur\n",
      "        6. Suggest technique modifications if needed (e.g., mixing methods, prep techniques)\n",
      "        7. Keep instructions clear, concise, and actionable\n",
      "        8. Maintain the same cooking skill level as the original recipe\n",
      "\n",
      "        IMPORTANT CONSIDERATIONS:\n",
      "        - If a substitution significantly impacts flavor, briefly note it in the step\n",
      "        - If multiple steps use the same ingredient, ensure consistency across all adaptations\n",
      "        - Do not add new steps; only modify existing ones\n",
      "        - Do not change unaffected steps\n",
      "\n",
      "        OUTPUT FORMAT:\n",
      "        Provide only the adapted recipe steps in numbered format.\n",
      "\n",
      "        ADAPTED RECIPE STEPS:'\n",
      "                ) AS adapted_steps\n",
      "            \n",
      "2026-01-10 23:58:26,370 - snowflake.connector.result_batch - DEBUG - Using nanoarrow as the arrow data converter\n",
      "2026-01-10 23:58:26,384 - snowflake.connector.CArrowIterator - DEBUG - Arrow BatchSize: 1\n",
      "2026-01-10 23:58:26,388 - snowflake.connector.CArrowIterator - DEBUG - Arrow chunk info: batchCount 1, columnCount 1, use_numpy: 0\n",
      "2026-01-10 23:58:26,404 - snowflake.connector.nanoarrow_arrow_iterator - DEBUG - Batches read: 0\n",
      "2026-01-10 23:58:26,452 - snowflake.connector.result_set - DEBUG - beginning to schedule result batch downloads\n",
      "2026-01-10 23:58:26,454 - snowflake.connector.CArrowIterator - DEBUG - Current batch index: 0, rows in current batch: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM: 16 adapted steps, 1 notes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-10 23:58:26,460 - root - INFO - Success: Step 3 finished for Substitution (LLM's adapted new_recipe steps successfully).\n",
      "2026-01-10 23:58:26,468 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:58:26,523 - snowflake.connector.cursor - INFO - query: [SELECT  *  FROM NUTRIRAG_PROJECT.RAW.INGREDIENTS_MATCHING]\n",
      "2026-01-10 23:58:26,525 - snowflake.connector.connection - DEBUG - sequence counter: 48\n",
      "2026-01-10 23:58:26,527 - snowflake.connector.cursor - DEBUG - Request id: 4e55b5c8-891e-4f61-acb0-4c98421cd429\n",
      "2026-01-10 23:58:26,536 - snowflake.connector.cursor - DEBUG - running query [SELECT  *  FROM NUTRIRAG_PROJECT.RAW.INGREDIENTS_MATCHING]\n",
      "2026-01-10 23:58:26,540 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:58:26,545 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:58:26,547 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:58:26,551 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085906170684, 0)\n",
      "2026-01-10 23:58:26,559 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085906170684, 'priority': 0, 'context': {'base64Data': 'CNKU94Bw'}}]}\n",
      "2026-01-10 23:58:26,562 - snowflake.connector.connection - DEBUG - sql=[SELECT  *  FROM NUTRIRAG_PROJECT.RAW.INGREDIENTS_MATCHING], sequence_id=[48], is_file_transfer=[False]\n",
      "2026-01-10 23:58:26,567 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:58:26,573 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:58:26,578 - snowflake.connector.network - DEBUG - Request guid: 230f5a5f-6b6f-41ce-930f-84fa14f1fa37\n",
      "2026-01-10 23:58:26,584 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:58:26,810 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=4e55b5c8-891e-4f61-acb0-4c98421cd429&request_guid=230f5a5f-6b6f-41ce-930f-84fa14f1fa37 HTTP/1.1\" 200 None\n",
      "2026-01-10 23:58:26,819 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:26,820 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:58:26,822 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:58:26,825 - snowflake.connector.network - DEBUG - Query id: 01c1a5c2-0307-74b8-0010-085300863246\n",
      "2026-01-10 23:58:26,826 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085906735784, 'priority': 0, 'context': 'COKl94Bw'}]}\n",
      "2026-01-10 23:58:26,828 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085906170684, 0)\n",
      "2026-01-10 23:58:26,835 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085906735784, 'priority': 0, 'context': 'COKl94Bw'}\n",
      "2026-01-10 23:58:26,837 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:58:26,838 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:26,850 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:26,852 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:58:26,899 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085906735784, 0)\n",
      "2026-01-10 23:58:26,908 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c2-0307-74b8-0010-085300863246\n",
      "2026-01-10 23:58:26,919 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:58:26,922 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:26,926 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:58:26,927 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:58:26,935 - snowflake.connector.cursor - INFO - Number of results in first chunk: 0\n",
      "2026-01-10 23:58:26,942 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:58:26,944 - snowflake.connector.cursor - INFO - query: [SELECT \"RECIPE_ID\", \"INGREDIENT_FROM_RECIPE_NAME\", \"INGREDIENT_ID\", lower(trim(\"...]\n",
      "2026-01-10 23:58:26,949 - snowflake.connector.connection - DEBUG - sequence counter: 49\n",
      "2026-01-10 23:58:26,954 - snowflake.connector.cursor - DEBUG - Request id: 56baeabe-b2a1-4be3-9fd5-7c5c96a7a430\n",
      "2026-01-10 23:58:26,956 - snowflake.connector.cursor - DEBUG - running query [SELECT \"RECIPE_ID\", \"INGREDIENT_FROM_RECIPE_NAME\", \"INGREDIENT_ID\", lower(trim(\"...]\n",
      "2026-01-10 23:58:26,970 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:58:26,973 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:58:26,984 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:58:26,989 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085906735784, 0)\n",
      "2026-01-10 23:58:26,999 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085906735784, 'priority': 0, 'context': {'base64Data': 'COKl94Bw'}}]}\n",
      "2026-01-10 23:58:27,007 - snowflake.connector.connection - DEBUG - sql=[SELECT \"RECIPE_ID\", \"INGREDIENT_FROM_RECIPE_NAME\", \"INGREDIENT_ID\", lower(trim(\"...], sequence_id=[49], is_file_transfer=[False]\n",
      "2026-01-10 23:58:27,018 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:58:27,030 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:58:27,036 - snowflake.connector.network - DEBUG - Request guid: 4ece9548-5477-4c23-9420-5404be3bba42\n",
      "2026-01-10 23:58:27,049 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:58:27,252 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=56baeabe-b2a1-4be3-9fd5-7c5c96a7a430&request_guid=4ece9548-5477-4c23-9420-5404be3bba42 HTTP/1.1\" 200 None\n",
      "2026-01-10 23:58:27,255 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:27,259 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:58:27,264 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:58:27,267 - snowflake.connector.network - DEBUG - Query id: 01c1a5c2-0307-74b8-0010-08530086324a\n",
      "2026-01-10 23:58:27,271 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085907215607, 'priority': 0, 'context': 'COKl94Bw'}]}\n",
      "2026-01-10 23:58:27,283 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085906735784, 0)\n",
      "2026-01-10 23:58:27,288 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085907215607, 'priority': 0, 'context': 'COKl94Bw'}\n",
      "2026-01-10 23:58:27,293 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:58:27,319 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:27,326 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:27,342 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:58:27,354 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085907215607, 0)\n",
      "2026-01-10 23:58:27,360 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c2-0307-74b8-0010-08530086324a\n",
      "2026-01-10 23:58:27,376 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:58:27,386 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:27,391 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:58:27,400 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:58:27,427 - snowflake.connector.cursor - INFO - Number of results in first chunk: 0\n",
      "2026-01-10 23:58:27,432 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:58:27,436 - snowflake.connector.cursor - INFO - query: [SELECT  *  FROM NUTRIRAG_PROJECT.RAW.CLEANED_INGREDIENTS]\n",
      "2026-01-10 23:58:27,439 - snowflake.connector.connection - DEBUG - sequence counter: 50\n",
      "2026-01-10 23:58:27,468 - snowflake.connector.cursor - DEBUG - Request id: 38d523fc-1940-4cc8-8930-3888a3b9340b\n",
      "2026-01-10 23:58:27,471 - snowflake.connector.cursor - DEBUG - running query [SELECT  *  FROM NUTRIRAG_PROJECT.RAW.CLEANED_INGREDIENTS]\n",
      "2026-01-10 23:58:27,475 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:58:27,493 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:58:27,499 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:58:27,500 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085907215607, 0)\n",
      "2026-01-10 23:58:27,502 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085907215607, 'priority': 0, 'context': {'base64Data': 'COKl94Bw'}}]}\n",
      "2026-01-10 23:58:27,509 - snowflake.connector.connection - DEBUG - sql=[SELECT  *  FROM NUTRIRAG_PROJECT.RAW.CLEANED_INGREDIENTS], sequence_id=[50], is_file_transfer=[False]\n",
      "2026-01-10 23:58:27,512 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:58:27,520 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:58:27,527 - snowflake.connector.network - DEBUG - Request guid: 76ff3eb1-8bc4-4aa5-80e5-500606d24cd4\n",
      "2026-01-10 23:58:27,584 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:58:27,804 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=38d523fc-1940-4cc8-8930-3888a3b9340b&request_guid=76ff3eb1-8bc4-4aa5-80e5-500606d24cd4 HTTP/1.1\" 200 None\n",
      "2026-01-10 23:58:27,808 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:27,810 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:58:27,814 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:58:27,816 - snowflake.connector.network - DEBUG - Query id: 01c1a5c2-0307-74b8-0010-08530086324e\n",
      "2026-01-10 23:58:27,820 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085907766419, 'priority': 0, 'context': 'COKl94Bw'}]}\n",
      "2026-01-10 23:58:27,824 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085907215607, 0)\n",
      "2026-01-10 23:58:27,837 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085907766419, 'priority': 0, 'context': 'COKl94Bw'}\n",
      "2026-01-10 23:58:27,839 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:58:27,842 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:27,872 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:27,875 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:58:27,876 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085907766419, 0)\n",
      "2026-01-10 23:58:27,878 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c2-0307-74b8-0010-08530086324e\n",
      "2026-01-10 23:58:27,880 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:58:27,898 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:27,900 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:58:27,901 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:58:27,903 - snowflake.connector.cursor - INFO - Number of results in first chunk: 0\n",
      "2026-01-10 23:58:27,921 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:58:27,927 - snowflake.connector.cursor - INFO - query: [SELECT \"RECIPE_ID\" AS \"RECIPE_ID\", \"INGREDIENT_FROM_RECIPE_NAME\" AS \"INGREDIENT_...]\n",
      "2026-01-10 23:58:27,930 - snowflake.connector.connection - DEBUG - sequence counter: 51\n",
      "2026-01-10 23:58:27,934 - snowflake.connector.cursor - DEBUG - Request id: a0b0196a-c38a-4656-ad64-1c40a93384f3\n",
      "2026-01-10 23:58:27,935 - snowflake.connector.cursor - DEBUG - running query [SELECT \"RECIPE_ID\" AS \"RECIPE_ID\", \"INGREDIENT_FROM_RECIPE_NAME\" AS \"INGREDIENT_...]\n",
      "2026-01-10 23:58:27,936 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:58:27,941 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:58:27,950 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:58:27,952 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085907766419, 0)\n",
      "2026-01-10 23:58:27,968 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085907766419, 'priority': 0, 'context': {'base64Data': 'COKl94Bw'}}]}\n",
      "2026-01-10 23:58:27,971 - snowflake.connector.connection - DEBUG - sql=[SELECT \"RECIPE_ID\" AS \"RECIPE_ID\", \"INGREDIENT_FROM_RECIPE_NAME\" AS \"INGREDIENT_...], sequence_id=[51], is_file_transfer=[False]\n",
      "2026-01-10 23:58:28,000 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:58:28,002 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:58:28,004 - snowflake.connector.network - DEBUG - Request guid: 85217266-9e96-4c81-8c03-a9139a753263\n",
      "2026-01-10 23:58:28,005 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:58:28,193 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=a0b0196a-c38a-4656-ad64-1c40a93384f3&request_guid=85217266-9e96-4c81-8c03-a9139a753263 HTTP/1.1\" 200 None\n",
      "2026-01-10 23:58:28,199 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:28,201 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:58:28,203 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:58:28,205 - snowflake.connector.network - DEBUG - Query id: 01c1a5c2-0307-7557-0010-085300861b2a\n",
      "2026-01-10 23:58:28,214 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085908156369, 'priority': 0, 'context': 'CN6q94Bw'}]}\n",
      "2026-01-10 23:58:28,218 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085907766419, 0)\n",
      "2026-01-10 23:58:28,236 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085908156369, 'priority': 0, 'context': 'CN6q94Bw'}\n",
      "2026-01-10 23:58:28,238 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:58:28,244 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:28,253 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:28,264 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:58:28,265 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085908156369, 0)\n",
      "2026-01-10 23:58:28,269 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c2-0307-7557-0010-085300861b2a\n",
      "2026-01-10 23:58:28,272 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:58:28,284 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:28,286 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:58:28,293 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:58:28,318 - snowflake.connector.cursor - INFO - Number of results in first chunk: 0\n",
      "2026-01-10 23:58:28,320 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:58:28,321 - snowflake.connector.cursor - INFO - query: [SELECT \"NDB_NO\" AS \"NDB_NO\", \"DESCRIP\" AS \"DESCRIP\", \"ENERGY_KCAL\" AS \"ENERGY_KC...]\n",
      "2026-01-10 23:58:28,324 - snowflake.connector.connection - DEBUG - sequence counter: 52\n",
      "2026-01-10 23:58:28,326 - snowflake.connector.cursor - DEBUG - Request id: 6ac47544-a793-4b91-8ccc-068632b7066b\n",
      "2026-01-10 23:58:28,327 - snowflake.connector.cursor - DEBUG - running query [SELECT \"NDB_NO\" AS \"NDB_NO\", \"DESCRIP\" AS \"DESCRIP\", \"ENERGY_KCAL\" AS \"ENERGY_KC...]\n",
      "2026-01-10 23:58:28,335 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:58:28,338 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:58:28,347 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:58:28,352 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085908156369, 0)\n",
      "2026-01-10 23:58:28,354 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085908156369, 'priority': 0, 'context': {'base64Data': 'CN6q94Bw'}}]}\n",
      "2026-01-10 23:58:28,359 - snowflake.connector.connection - DEBUG - sql=[SELECT \"NDB_NO\" AS \"NDB_NO\", \"DESCRIP\" AS \"DESCRIP\", \"ENERGY_KCAL\" AS \"ENERGY_KC...], sequence_id=[52], is_file_transfer=[False]\n",
      "2026-01-10 23:58:28,361 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:58:28,368 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:58:28,381 - snowflake.connector.network - DEBUG - Request guid: 9a99729b-2eb3-4d82-bebf-13f0aea1ecf0\n",
      "2026-01-10 23:58:28,391 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:58:28,601 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=6ac47544-a793-4b91-8ccc-068632b7066b&request_guid=9a99729b-2eb3-4d82-bebf-13f0aea1ecf0 HTTP/1.1\" 200 None\n",
      "2026-01-10 23:58:28,605 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:28,610 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:58:28,611 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:58:28,614 - snowflake.connector.network - DEBUG - Query id: 01c1a5c2-0307-7294-0010-08530086262e\n",
      "2026-01-10 23:58:28,618 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085908549749, 'priority': 0, 'context': 'CNKU94Bw'}]}\n",
      "2026-01-10 23:58:28,620 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085908156369, 0)\n",
      "2026-01-10 23:58:28,644 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085908549749, 'priority': 0, 'context': 'CNKU94Bw'}\n",
      "2026-01-10 23:58:28,652 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:58:28,654 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:28,659 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:28,669 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:58:28,674 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085908549749, 0)\n",
      "2026-01-10 23:58:28,678 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c2-0307-7294-0010-08530086262e\n",
      "2026-01-10 23:58:28,683 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:58:28,684 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:28,687 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:58:28,690 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:58:28,693 - snowflake.connector.cursor - INFO - Number of results in first chunk: 0\n",
      "2026-01-10 23:58:28,697 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:58:28,700 - snowflake.connector.cursor - INFO - query: [SELECT  *  FROM (( SELECT NULL :: BIGINT AS \"RECIPE_ID\", NULL :: STRING(16777216...]\n",
      "2026-01-10 23:58:28,702 - snowflake.connector.connection - DEBUG - sequence counter: 53\n",
      "2026-01-10 23:58:28,704 - snowflake.connector.cursor - DEBUG - Request id: 1309344d-e437-4abc-b391-6aa2c91d5ceb\n",
      "2026-01-10 23:58:28,706 - snowflake.connector.cursor - DEBUG - running query [SELECT  *  FROM (( SELECT NULL :: BIGINT AS \"RECIPE_ID\", NULL :: STRING(16777216...]\n",
      "2026-01-10 23:58:28,708 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:58:28,710 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:58:28,713 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:58:28,715 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085908549749, 0)\n",
      "2026-01-10 23:58:28,717 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085908549749, 'priority': 0, 'context': {'base64Data': 'CNKU94Bw'}}]}\n",
      "2026-01-10 23:58:28,719 - snowflake.connector.connection - DEBUG - sql=[SELECT  *  FROM (( SELECT NULL :: BIGINT AS \"RECIPE_ID\", NULL :: STRING(16777216...], sequence_id=[53], is_file_transfer=[False]\n",
      "2026-01-10 23:58:28,724 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:58:28,727 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:58:28,735 - snowflake.connector.network - DEBUG - Request guid: ee0fde79-57b4-4afd-9f69-8a0018c26587\n",
      "2026-01-10 23:58:28,740 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:58:28,944 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=1309344d-e437-4abc-b391-6aa2c91d5ceb&request_guid=ee0fde79-57b4-4afd-9f69-8a0018c26587 HTTP/1.1\" 200 None\n",
      "2026-01-10 23:58:28,949 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:28,951 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:58:28,953 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:58:28,956 - snowflake.connector.network - DEBUG - Query id: 01c1a5c2-0307-73b1-0010-085300860a06\n",
      "2026-01-10 23:58:28,959 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085908909575, 'priority': 0, 'context': 'CMad94Bw'}]}\n",
      "2026-01-10 23:58:28,968 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085908549749, 0)\n",
      "2026-01-10 23:58:28,983 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085908909575, 'priority': 0, 'context': 'CMad94Bw'}\n",
      "2026-01-10 23:58:28,985 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:58:28,987 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:28,988 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:29,001 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:58:29,003 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085908909575, 0)\n",
      "2026-01-10 23:58:29,008 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c2-0307-73b1-0010-085300860a06\n",
      "2026-01-10 23:58:29,014 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:58:29,018 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:29,074 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:58:29,085 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:58:29,089 - snowflake.connector.cursor - INFO - Number of results in first chunk: 0\n",
      "2026-01-10 23:58:29,135 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:58:29,144 - snowflake.connector.cursor - INFO - query: [SELECT \"ING_KEY\", \"ENERGY_KCAL\", \"PROTEIN_G\", \"FAT_G\", \"SATURATED_FATS_G\", \"CARB...]\n",
      "2026-01-10 23:58:29,146 - snowflake.connector.connection - DEBUG - sequence counter: 54\n",
      "2026-01-10 23:58:29,147 - snowflake.connector.cursor - DEBUG - Request id: 62d3c841-8f77-4b50-8ff2-bb1adebfc678\n",
      "2026-01-10 23:58:29,149 - snowflake.connector.cursor - DEBUG - running query [SELECT \"ING_KEY\", \"ENERGY_KCAL\", \"PROTEIN_G\", \"FAT_G\", \"SATURATED_FATS_G\", \"CARB...]\n",
      "2026-01-10 23:58:29,150 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:58:29,151 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:58:29,152 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:58:29,153 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085908909575, 0)\n",
      "2026-01-10 23:58:29,155 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085908909575, 'priority': 0, 'context': {'base64Data': 'CMad94Bw'}}]}\n",
      "2026-01-10 23:58:29,158 - snowflake.connector.connection - DEBUG - sql=[SELECT \"ING_KEY\", \"ENERGY_KCAL\", \"PROTEIN_G\", \"FAT_G\", \"SATURATED_FATS_G\", \"CARB...], sequence_id=[54], is_file_transfer=[False]\n",
      "2026-01-10 23:58:29,159 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:58:29,165 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:58:29,172 - snowflake.connector.network - DEBUG - Request guid: 2a3f2883-2a8e-41a8-8e30-f9d1f4723b81\n",
      "2026-01-10 23:58:29,176 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:58:29,376 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=62d3c841-8f77-4b50-8ff2-bb1adebfc678&request_guid=2a3f2883-2a8e-41a8-8e30-f9d1f4723b81 HTTP/1.1\" 200 None\n",
      "2026-01-10 23:58:29,381 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:29,383 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:58:29,385 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:58:29,387 - snowflake.connector.network - DEBUG - Query id: 01c1a5c2-0307-7294-0010-085300862632\n",
      "2026-01-10 23:58:29,400 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085909331804, 'priority': 0, 'context': 'CNKU94Bw'}]}\n",
      "2026-01-10 23:58:29,416 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085908909575, 0)\n",
      "2026-01-10 23:58:29,417 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085909331804, 'priority': 0, 'context': 'CNKU94Bw'}\n",
      "2026-01-10 23:58:29,419 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:58:29,421 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:29,435 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:29,449 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:58:29,451 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085909331804, 0)\n",
      "2026-01-10 23:58:29,455 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c2-0307-7294-0010-085300862632\n",
      "2026-01-10 23:58:29,483 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:58:29,485 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:29,486 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:58:29,487 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:58:29,489 - snowflake.connector.cursor - INFO - Number of results in first chunk: 0\n",
      "2026-01-10 23:58:29,500 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:58:29,505 - snowflake.connector.cursor - INFO - query: [SELECT \"ING_KEY\", \"ENERGY_KCAL\", \"PROTEIN_G\", \"FAT_G\", \"SATURATED_FATS_G\", \"CARB...]\n",
      "2026-01-10 23:58:29,513 - snowflake.connector.connection - DEBUG - sequence counter: 55\n",
      "2026-01-10 23:58:29,519 - snowflake.connector.cursor - DEBUG - Request id: 5d9e4f47-aaf3-41c8-944e-3f591c413441\n",
      "2026-01-10 23:58:29,522 - snowflake.connector.cursor - DEBUG - running query [SELECT \"ING_KEY\", \"ENERGY_KCAL\", \"PROTEIN_G\", \"FAT_G\", \"SATURATED_FATS_G\", \"CARB...]\n",
      "2026-01-10 23:58:29,525 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:58:29,536 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:58:29,539 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:58:29,541 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085909331804, 0)\n",
      "2026-01-10 23:58:29,551 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085909331804, 'priority': 0, 'context': {'base64Data': 'CNKU94Bw'}}]}\n",
      "2026-01-10 23:58:29,558 - snowflake.connector.connection - DEBUG - sql=[SELECT \"ING_KEY\", \"ENERGY_KCAL\", \"PROTEIN_G\", \"FAT_G\", \"SATURATED_FATS_G\", \"CARB...], sequence_id=[55], is_file_transfer=[False]\n",
      "2026-01-10 23:58:29,569 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:58:29,572 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:58:29,581 - snowflake.connector.network - DEBUG - Request guid: 07c0773a-1e00-46c7-8d7b-2442ae2ca184\n",
      "2026-01-10 23:58:29,603 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:58:29,830 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=5d9e4f47-aaf3-41c8-944e-3f591c413441&request_guid=07c0773a-1e00-46c7-8d7b-2442ae2ca184 HTTP/1.1\" 200 None\n",
      "2026-01-10 23:58:29,833 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:29,836 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:58:29,837 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:58:29,841 - snowflake.connector.network - DEBUG - Query id: 01c1a5c2-0307-7294-0010-085300862636\n",
      "2026-01-10 23:58:29,844 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085909789625, 'priority': 0, 'context': 'CNKU94Bw'}]}\n",
      "2026-01-10 23:58:29,871 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085909331804, 0)\n",
      "2026-01-10 23:58:29,872 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085909789625, 'priority': 0, 'context': 'CNKU94Bw'}\n",
      "2026-01-10 23:58:29,878 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:58:29,880 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:29,886 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:58:29,890 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:58:29,896 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085909789625, 0)\n",
      "2026-01-10 23:58:29,904 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5c2-0307-7294-0010-085300862636\n",
      "2026-01-10 23:58:29,905 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:58:29,909 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:58:29,918 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:58:29,925 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:58:29,933 - snowflake.connector.cursor - INFO - Number of results in first chunk: 0\n",
      "2026-01-10 23:58:29,941 - snowflake.snowpark._internal.server_connection - DEBUG - Execute query [queryID: 01c1a5c2-0307-7294-0010-085300862636]  SELECT \"ING_KEY\", \"ENERGY_KCAL\", \"PROTEIN_G\", \"FAT_G\", \"SATURATED_FATS_G\", \"CARB_G\", \"FIBER_G\", \"SUGAR_G\", \"SODIUM_MG\", \"CALCIUM_MG\", \"IRON_MG\", \"MAGNESIUM_MG\", \"POTASSIUM_MG\", \"VITC_MG\" FROM ( SELECT \"ING_KEY\", \"ENERGY_KCAL\", \"PROTEIN_G\", \"FAT_G\", \"SATURATED_FATS_G\", \"CARB_G\", \"FIBER_G\", \"SUGAR_G\", \"SODIUM_MG\", \"CALCIUM_MG\", \"IRON_MG\", \"MAGNESIUM_MG\", \"POTASSIUM_MG\", \"VITC_MG\", \"SCORE_SANTE\", row_number() OVER (PARTITION BY \"ING_KEY\"  ORDER BY \"SCORE_SANTE\" DESC NULLS LAST ) AS \"RN\" FROM ( SELECT  *  FROM (( SELECT \"RECIPE_ID\" AS \"RECIPE_ID\", \"INGREDIENT_FROM_RECIPE_NAME\" AS \"INGREDIENT_FROM_RECIPE_NAME\", \"INGREDIENT_ID\" AS \"INGREDIENT_ID\", \"ING_KEY\" AS \"ING_KEY\" FROM ( SELECT \"RECIPE_ID\", \"INGREDIENT_FROM_RECIPE_NAME\", \"INGREDIENT_ID\", lower(trim(\"INGREDIENT_FROM_RECIPE_NAME\")) AS \"ING_KEY\" FROM NUTRIRAG_PROJECT.RAW.INGREDIENTS_MATCHING WHERE (\"RECIPE_ID\" = 94947 :: INT)) WHERE \"ING_KEY\" IN ('cream cheese')) AS SNOWPARK_LEFT LEFT OUTER JOIN ( SELECT \"NDB_NO\" AS \"NDB_NO\", \"DESCRIP\" AS \"DESCRIP\", \"ENERGY_KCAL\" AS \"ENERGY_KCAL\", \"PROTEIN_G\" AS \"PROTEIN_G\", \"SATURATED_FATS_G\" AS \"SATURATED_FATS_G\", \"FAT_G\" AS \"FAT_G\", \"CARB_G\" AS \"CARB_G\", \"FIBER_G\" AS \"FIBER_G\", \"SUGAR_G\" AS \"SUGAR_G\", \"CALCIUM_MG\" AS \"CALCIUM_MG\", \"IRON_MG\" AS \"IRON_MG\", \"PHOSPHORUS_MG\" AS \"PHOSPHORUS_MG\", \"POTASSIUM_MG\" AS \"POTASSIUM_MG\", \"SODIUM_MG\" AS \"SODIUM_MG\", \"ZINC_MG\" AS \"ZINC_MG\", \"COPPER_MCG\" AS \"COPPER_MCG\", \"MANGANESE_MG\" AS \"MANGANESE_MG\", \"SELENIUM_MCG\" AS \"SELENIUM_MCG\", \"VITC_MG\" AS \"VITC_MG\", \"THIAMIN_MG\" AS \"THIAMIN_MG\", \"RIBOFLAVIN_MG\" AS \"RIBOFLAVIN_MG\", \"NIACIN_MG\" AS \"NIACIN_MG\", \"VITB6_MG\" AS \"VITB6_MG\", \"FOLATE_MCG\" AS \"FOLATE_MCG\", \"VITB12_MCG\" AS \"VITB12_MCG\", \"VITA_MCG\" AS \"VITA_MCG\", \"MAGNESIUM_MG\" AS \"MAGNESIUM_MG\", \"SCORE_SANTE\" AS \"SCORE_SANTE\" FROM NUTRIRAG_PROJECT.RAW.CLEANED_INGREDIENTS) AS SNOWPARK_RIGHT ON (\"INGREDIENT_ID\" = \"NDB_NO\")))) WHERE (\"RN\" = 1 :: INT)\n",
      "2026-01-10 23:58:29,945 - snowflake.connector.result_set - DEBUG - beginning to schedule result batch downloads\n",
      "2026-01-10 23:58:29,960 - root - INFO - Success: Step 4 finished (Original recipe health score computing finished).\n",
      "2026-01-10 23:58:29,987 - root - INFO - Success: Step 5 finished (TransformerResponse successfully built, returning it...).\n"
     ]
    }
   ],
   "source": [
    "output = transform_recipe(session, json.dumps(request))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d1bf6971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recipe': {'id': 94947,\n",
       "  'name': 'crab filled crescent snacks',\n",
       "  'serving_size': 1.0,\n",
       "  'servings': 4.0,\n",
       "  'health_score': 0.0,\n",
       "  'ingredients': ['crabmeat',\n",
       "   'sour cream reduced fat',\n",
       "   'green onions',\n",
       "   'garlic salt',\n",
       "   'refrigerated crescent dinner rolls',\n",
       "   'egg yolk',\n",
       "   'water',\n",
       "   'sesame seeds',\n",
       "   'sweet and sour sauce'],\n",
       "  'quantity_ingredients': ['1', '1', '1', '1', '1', '1', '1', '1', '1'],\n",
       "  'minutes': 70.0,\n",
       "  'steps': ['Heat over to 375 degrees.',\n",
       "   'Spray large cookie sheet with non-stick cooking spray.',\n",
       "   'In small bowl, combine crabmeat, sour cream reduced fat, green onions and garlic salt and mix well.',\n",
       "   'Unroll both cans of dough.',\n",
       "   'Separate into 16 triangles.',\n",
       "   'Cut each triangle in half lengthwise to make 32 triangles.',\n",
       "   'Place 1 teaspoon crab mixture on center of each triangle about 1 inch from short side of triangle.',\n",
       "   'Fold short ends of each triangle over filling.',\n",
       "   'Pinch sides to seal.',\n",
       "   'Roll up.',\n",
       "   'Place on sprayed cookie sheet.',\n",
       "   'In small bowl, combine egg yolk and water and mix well.',\n",
       "   'Brush egg mixture over snacks.',\n",
       "   'Sprinkle with sesame seed.',\n",
       "   'Bake at 375 degrees for 15 to 20 minutes or until golden brown.',\n",
       "   'Serve warm snacks with sweet-and-sour sauce.']},\n",
       " 'original_name': 'crab filled crescent snacks',\n",
       " 'transformed_name': 'crab filled crescent snacks',\n",
       " 'substitutions': None,\n",
       " 'nutrition_before': {'calories': 0.0,\n",
       "  'protein_g': 0.0,\n",
       "  'saturated_fats_g': 0.0,\n",
       "  'fat_g': 0.0,\n",
       "  'carb_g': 0.0,\n",
       "  'fiber_g': 0.0,\n",
       "  'sodium_mg': 0.0,\n",
       "  'sugar_g': 0.0,\n",
       "  'iron_mg': 0.0,\n",
       "  'calcium_mg': 0.0,\n",
       "  'magnesium_mg': 0.0,\n",
       "  'potassium_mg': 0.0,\n",
       "  'vitamin_c_mg': 0.0,\n",
       "  'health_score': 57.0},\n",
       " 'nutrition_after': {'calories': 0.0,\n",
       "  'protein_g': 0.0,\n",
       "  'saturated_fats_g': 0.0,\n",
       "  'fat_g': 0.0,\n",
       "  'carb_g': 0.0,\n",
       "  'fiber_g': 0.0,\n",
       "  'sodium_mg': 0.0,\n",
       "  'sugar_g': 0.0,\n",
       "  'iron_mg': 0.0,\n",
       "  'calcium_mg': 0.0,\n",
       "  'magnesium_mg': 0.0,\n",
       "  'potassium_mg': 0.0,\n",
       "  'vitamin_c_mg': 0.0,\n",
       "  'health_score': 0.0},\n",
       " 'success': True,\n",
       " 'message': 'Using sour cream reduced fat instead of cream cheese may result in a slightly different texture and consistency of the crab mixture, but it should not significantly impact the flavor or cooking process of the dish.'}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2121e4f7",
   "metadata": {},
   "source": [
    "## Get code \n",
    "Reads the code stored in the file_path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7540365a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_code(file_path):\n",
    "    \"\"\"Lit le code Python qui contient la logique (sp_handler, imports, etc.)\"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6f1a97ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "746036ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = \"YOUR_FILE_PATH\"\n",
    "file_path = \"/Users/sushiatomique/Documents/M2/NutriRAG/backend/app/udf/transform_recipe.py\"\n",
    "code = read_code(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23abdf6c",
   "metadata": {},
   "source": [
    "## Register code as Procedure Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "60b4ede4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Déploiement de la Procédure Stockée\n",
    "schema = \"NUTRIRAG_PROJECT.SERVICES\"\n",
    "proc_name = \"TRANSFORM_RECIPE\"\n",
    "full_proc_name = f\"{schema}.{proc_name}\"\n",
    "main_func_name = \"transform_recipe\"\n",
    "args = [\"REQUEST\"]\n",
    "query = f\"\"\"\n",
    "    CREATE OR REPLACE PROCEDURE {full_proc_name}({\" STRING, \".join(args) + \" STRING\"})\n",
    "    RETURNS STRING\n",
    "    LANGUAGE PYTHON\n",
    "    RUNTIME_VERSION = '3.10'\n",
    "    PACKAGES = ('snowflake-snowpark-python', 'filelock', 'pydantic')\n",
    "    EXTERNAL_ACCESS_INTEGRATIONS = (TRAINING_INTERNET_ACCESS)\n",
    "    HANDLER = '{main_func_name}'\n",
    "    EXECUTE AS OWNER\n",
    "    AS\n",
    "    $${code}$$\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16ce72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-10 23:53:45,285 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:53:45,307 - snowflake.connector.cursor - INFO - query: [CREATE OR REPLACE PROCEDURE NUTRIRAG_PROJECT.SERVICES.TRANSFORM_RECIPE(REQUEST S...]\n",
      "2026-01-10 23:53:45,309 - snowflake.connector.connection - DEBUG - sequence counter: 2\n",
      "2026-01-10 23:53:45,311 - snowflake.connector.cursor - DEBUG - Request id: 311aa73e-bda3-449a-884b-2833c095c9ac\n",
      "2026-01-10 23:53:45,317 - snowflake.connector.cursor - DEBUG - running query [CREATE OR REPLACE PROCEDURE NUTRIRAG_PROJECT.SERVICES.TRANSFORM_RECIPE(REQUEST S...]\n",
      "2026-01-10 23:53:45,326 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:53:45,329 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:53:45,331 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:53:45,334 - snowflake.connector.connection - DEBUG - sql=[CREATE OR REPLACE PROCEDURE NUTRIRAG_PROJECT.SERVICES.TRANSFORM_RECIPE(REQUEST S...], sequence_id=[2], is_file_transfer=[False]\n",
      "2026-01-10 23:53:45,341 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:53:45,344 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:53:45,348 - snowflake.connector.network - DEBUG - Request guid: 19301e4c-b4fb-4bc0-8c70-04e68baba368\n",
      "2026-01-10 23:53:45,350 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:53:45,371 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - Resetting dropped connection: sfedu02-oub04122.snowflakecomputing.com\n",
      "2026-01-10 23:53:45,885 - snowflake.connector.ssl_wrap_socket - DEBUG - OCSP Mode: INSECURE, OCSP response cache file name: None\n",
      "2026-01-10 23:53:45,888 - snowflake.connector.ssl_wrap_socket - INFO - THIS CONNECTION IS IN INSECURE MODE. IT MEANS THE CERTIFICATE WILL BE VALIDATED BUT THE CERTIFICATE REVOCATION STATUS WILL NOT BE CHECKED.\n",
      "2026-01-10 23:53:49,399 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=311aa73e-bda3-449a-884b-2833c095c9ac&request_guid=19301e4c-b4fb-4bc0-8c70-04e68baba368 HTTP/1.1\" 200 None\n",
      "2026-01-10 23:53:49,403 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:53:49,404 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:53:49,406 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:53:49,407 - snowflake.connector.network - DEBUG - Query id: 01c1a5bd-0307-74b8-0010-08530086318a\n",
      "2026-01-10 23:53:49,408 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() called: data from server: {'entries': [{'id': 0, 'timestamp': 1768085629272483, 'priority': 0, 'context': 'COKl94Bw'}]}\n",
      "2026-01-10 23:53:49,410 - snowflake.connector._query_context_cache - DEBUG - deserialize {'id': 0, 'timestamp': 1768085629272483, 'priority': 0, 'context': 'COKl94Bw'}\n",
      "2026-01-10 23:53:49,411 - snowflake.connector._query_context_cache - DEBUG - sync_priority_map called priority_map size = 0, new_priority_map size = 1\n",
      "2026-01-10 23:53:49,425 - snowflake.connector._query_context_cache - DEBUG - trim_cache() called. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:53:49,426 - snowflake.connector._query_context_cache - DEBUG - trim_cache() returns. treeSet size is 1 and cache capacity is 5\n",
      "2026-01-10 23:53:49,428 - snowflake.connector._query_context_cache - DEBUG - deserialize_json_dict() returns\n",
      "2026-01-10 23:53:49,429 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085629272483, 0)\n",
      "2026-01-10 23:53:49,453 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5bd-0307-74b8-0010-08530086318a\n",
      "2026-01-10 23:53:49,488 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:53:49,495 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:53:49,504 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:53:49,506 - snowflake.connector.cursor - DEBUG - Query result format: json\n",
      "2026-01-10 23:53:49,510 - snowflake.connector.result_batch - DEBUG - parsing for result batch id: 1\n",
      "2026-01-10 23:53:49,512 - snowflake.connector.cursor - INFO - Number of results in first chunk: 1\n",
      "2026-01-10 23:53:49,516 - snowflake.snowpark._internal.server_connection - DEBUG - Execute query [queryID: 01c1a5bd-0307-74b8-0010-08530086318a] \n",
      "    CREATE OR REPLACE PROCEDURE NUTRIRAG_PROJECT.SERVICES.TRANSFORM_RECIPE(REQUEST STRING)\n",
      "    RETURNS STRING\n",
      "    LANGUAGE PYTHON\n",
      "    RUNTIME_VERSION = '3.10'\n",
      "    PACKAGES = ('snowflake-snowpark-python', 'filelock', 'pydantic')\n",
      "    EXTERNAL_ACCESS_INTEGRATIONS = (TRAINING_INTERNET_ACCESS)\n",
      "    HANDLER = 'transform_recipe'\n",
      "    EXECUTE AS OWNER\n",
      "    AS\n",
      "    $$################################################################################################################\n",
      "\n",
      "#                                        Transform service interface\n",
      "\n",
      "################################################################################################################\n",
      "import json\n",
      "import traceback\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import threading\n",
      "import logging\n",
      "\n",
      "from enum import Enum\n",
      "from typing import Optional, List, Dict, Any, Tuple\n",
      "from pydantic import BaseModel\n",
      "\n",
      "from snowflake.snowpark.functions import col, lower, trim, row_number\n",
      "from snowflake.snowpark.window import Window\n",
      "from snowflake.snowpark import Session\n",
      "\n",
      "\n",
      "class TransformationType(Enum):\n",
      "    ADD = 0\n",
      "    DELETE = 1\n",
      "    SUBSTITUTION = 2\n",
      "\n",
      "\n",
      "class TransformConstraints(BaseModel):\n",
      "    # Constraints for recipe transformation\n",
      "    transformation: TransformationType\n",
      "    no_lactose: bool = False\n",
      "    no_gluten: bool = False\n",
      "    no_nuts: bool = False\n",
      "    vegetarian: bool = False\n",
      "    vegan: bool = False\n",
      "    increase_protein: bool = False\n",
      "    decrease_sugar: bool = False\n",
      "    decrease_protein: bool = False\n",
      "    decrease_carbs: bool = False\n",
      "    decrease_calories: bool = False\n",
      "    decrease_sodium: bool = False\n",
      "    decrease_satfat: bool = False\n",
      "\n",
      "\n",
      "class Recipe(BaseModel):\n",
      "    id: int\n",
      "    name: str\n",
      "    serving_size: float\n",
      "    servings: float\n",
      "    health_score: float\n",
      "    ingredients: List[str]\n",
      "    quantity_ingredients: List[str]\n",
      "    minutes: float\n",
      "    steps: List[str]\n",
      "\n",
      "\n",
      "class TransformRequest(BaseModel):\n",
      "    # Transform request body\n",
      "    recipe: Recipe\n",
      "    ingredients_to_remove: Optional[List[str]] = None\n",
      "    constraints: Optional[TransformConstraints] = None\n",
      "\n",
      "\n",
      "class Substitution(BaseModel):\n",
      "    # Single ingredient substitution\n",
      "    original_ingredient: str\n",
      "    substitute_ingredient: str\n",
      "    original_quantity: Optional[float] = None\n",
      "    substitute_quantity: Optional[float] = None\n",
      "    reason: str = \"\"\n",
      "\n",
      "\n",
      "class NutritionDelta(BaseModel):\n",
      "    # Changes in nutrition values\n",
      "    calories: float = 0.0\n",
      "    protein_g: float = 0.0\n",
      "    saturated_fats_g: float = 0.0\n",
      "    fat_g: float = 0.0\n",
      "    carb_g: float = 0.0\n",
      "    fiber_g: float = 0.0\n",
      "    sodium_mg: float = 0.0\n",
      "    sugar_g: float = 0.0\n",
      "    iron_mg: float = 0.0\n",
      "    calcium_mg: float = 0.0\n",
      "    magnesium_mg: float = 0.0\n",
      "    potassium_mg: float = 0.0\n",
      "    vitamin_c_mg: float = 0.0\n",
      "    health_score: float = 0.0\n",
      "\n",
      "\n",
      "class TransformResponse(BaseModel):\n",
      "    # Transform response\n",
      "    recipe: Recipe\n",
      "    original_name: str\n",
      "    transformed_name: str\n",
      "    substitutions: Optional[List[Substitution]] = None\n",
      "    nutrition_before: Optional[NutritionDelta] = None\n",
      "    nutrition_after: Optional[NutritionDelta] = None\n",
      "    success: bool = True\n",
      "    message: Optional[str] = None\n",
      "\n",
      "\n",
      "\n",
      "################################################################################################################\n",
      "\n",
      "#                                               Utilitaires\n",
      "\n",
      "################################################################################################################\n",
      "\n",
      "\n",
      "def parse_procedure_result(query_result, proc_name) -> Any:\n",
      "    \"\"\"\n",
      "    Parse a procedure result parsed with query result to be usable.\n",
      "    Args:\n",
      "        query_result: query result parsed\n",
      "        proc_name: procedure name\n",
      "\n",
      "    Returns:\n",
      "        output: Any\n",
      "    \"\"\"\n",
      "    value = query_result[0][proc_name]\n",
      "    output = json.loads(value)\n",
      "    return output\n",
      "\n",
      "\n",
      "def parse_query_result(query_result) -> List[Dict[str, float]]:\n",
      "    \"\"\"\n",
      "    Collect query result and return as dict list\n",
      "    Args:\n",
      "        query_result : result of a query call (session.sql(query))\n",
      "\n",
      "    Returns:\n",
      "        List[Dict[str, float]]: formatted output\n",
      "    \"\"\"\n",
      "    collected_result = query_result.collect()\n",
      "    return [row.as_dict() for row in collected_result]\n",
      "\n",
      "\n",
      "def format_output(input: Any) -> str:\n",
      "    \"\"\"\n",
      "    Dumps output in json format to be usable.\n",
      "    Args:\n",
      "        input: Any type of data\n",
      "    Returns:\n",
      "        str: json result of the formatted output\n",
      "    \"\"\"\n",
      "    # Convertir les Decimal en float pour la sérialisation JSON\n",
      "    if (\n",
      "        isinstance(input, list)\n",
      "        and len(input) > 0\n",
      "        and isinstance(input[0], dict)\n",
      "    ):\n",
      "        from decimal import Decimal\n",
      "\n",
      "        for item in input:\n",
      "            for key, value in item.items():\n",
      "                if isinstance(value, Decimal):\n",
      "                    item[key] = float(value)\n",
      "\n",
      "    # Retourner en JSON\n",
      "    return json.dumps(input, indent=2)\n",
      "\n",
      "\n",
      "def to_dict(obj):\n",
      "    \"\"\"Recursively convert an object and its nested objects to dictionaries\"\"\"\n",
      "    if isinstance(obj, (str, int, float, bool, type(None))):\n",
      "        return obj\n",
      "    elif isinstance(obj, list):\n",
      "        return [to_dict(item) for item in obj]\n",
      "    elif isinstance(obj, dict):\n",
      "        return {key: to_dict(value) for key, value in obj.items()}\n",
      "    elif hasattr(obj, \"__dict__\"):\n",
      "        return {key: to_dict(value) for key, value in vars(obj).items()}\n",
      "    else:\n",
      "        return obj\n",
      "\n",
      "\n",
      "################################################################################################################\n",
      "\n",
      "#                                        Transform service logic\n",
      "\n",
      "################################################################################################################\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NUTRIENT_BASIS_GRAMS = 100\n",
      "NUTRITION_COLS = [\n",
      "    \"ENERGY_KCAL\", \"PROTEIN_G\", \"FAT_G\", \"SATURATED_FATS_G\", \"CARB_G\",\n",
      "    \"FIBER_G\", \"SUGAR_G\", \"SODIUM_MG\", \"CALCIUM_MG\", \"IRON_MG\",\n",
      "    \"MAGNESIUM_MG\", \"POTASSIUM_MG\", \"VITC_MG\"\n",
      "]\n",
      "INGREDIENTS_QUANTITY_TABLE_NAME = \"NUTRIRAG_PROJECT.RAW.INGREDIENTS_QUANTITY\"\n",
      "INGREDIENTS_CLUSTERING_TABLE_NAME = \"NUTRIRAG_PROJECT.ENRICHED.INGREDIENTS\"\n",
      "INGREDIENTS_MATCHED_TABLE_NAME = \"NUTRIRAG_PROJECT.RAW.INGREDIENTS_MATCHING\"\n",
      "INGREDIENTS_NUTRIMENTS_TABLE_NAME = \"NUTRIRAG_PROJECT.RAW.CLEANED_INGREDIENTS\"\n",
      "INGREDIENTS_TAGGED_TABLE_NAME = \"NUTRIRAG_PROJECT.CLEANED.INGREDIENTS_TAGGED\"\n",
      "\n",
      "class TransformService:\n",
      "    _pca_data_cache = None\n",
      "    _pca_lock = threading.Lock()\n",
      "    # check if async necessary for the constructor\n",
      "    def __init__(self, session: Optional[Session] = None):\n",
      "        self.session = session\n",
      "        self.matched_ingredients_cache: Dict[str, Optional[Dict]] = {}\n",
      "        self.recipe_qty_cache: Dict[str, List[Tuple[str, Optional[float]]]] = {}\n",
      "        self.recipe_nutrition_cache: Dict[str, Dict[str, Optional[Dict[str, Any]]]] = {}\n",
      "        self.pca_data = None  # ingredient coordinates for clustering \n",
      "        #self.load_pca_data()\n",
      "        self.recipe_tags_cache: Dict[str, Dict[str, Optional[Dict[str, Any]]]] = {}\n",
      "\n",
      "    def _zero_nutrition(self) -> NutritionDelta:\n",
      "        return NutritionDelta(\n",
      "            calories=0.0, protein_g=0.0, fat_g=0.0, saturated_fats_g=0.0,\n",
      "            carb_g=0.0, fiber_g=0.0, sugar_g=0.0, sodium_mg=0.0,\n",
      "            calcium_mg=0.0, iron_mg=0.0, magnesium_mg=0.0, potassium_mg=0.0,\n",
      "            vitamin_c_mg=0.0, health_score=0.0\n",
      "        )\n",
      "\n",
      "    def clean_ingredient_name(self, ingredient_name: str)->str:\n",
      "        return ingredient_name.lower().strip().replace(\"'\", \"''\")\n",
      "    \n",
      "    def get_ingredient_matched(self, ingredient_name_list: List[str]) -> List[Optional[Dict]]:\n",
      "        \"\"\"\n",
      "        Récupère les informations nutritionnelles d'un seul ingrédient depuis la base\n",
      "\n",
      "        Args:\n",
      "            ingredient_name: Nom de l'ingrédient à chercher\n",
      "\n",
      "        Returns:\n",
      "            Dict avec les infos nutritionnelles ou None si pas trouvé\n",
      "        \"\"\"\n",
      "        ingredient_clean_name_list = list(map(self.clean_ingredient_name, ingredient_name_list))\n",
      "        ingredient_matched = []\n",
      "        ingredient_to_match = []\n",
      "        for i, ingr_name in enumerate(ingredient_clean_name_list):\n",
      "            if ingr_name in self.matched_ingredients_cache:\n",
      "                ingredient_matched.append(self.matched_ingredients_cache[ingr_name])\n",
      "            else:\n",
      "                ingredient_to_match.append(ingr_name)\n",
      "        \n",
      "        if len(ingredient_to_match)>0:\n",
      "            # Build the WHERE conditions for each ingredient\n",
      "            conditions = []\n",
      "            for safe_ingredient in ingredient_to_match:\n",
      "                condition = f\"\"\"(LOWER(ci.\"DESCRIP\") LIKE '%{safe_ingredient.lower()}%'\n",
      "                    OR LOWER(im.\"INGREDIENT_FROM_RECIPE_NAME\") LIKE '%{safe_ingredient.lower()}%')\"\"\"\n",
      "                conditions.append(condition)\n",
      "\n",
      "            # Join conditions with OR\n",
      "            where_clause = \" OR \".join(conditions)\n",
      "\n",
      "            query = f\"\"\"\n",
      "            SELECT DISTINCT\n",
      "                \"DESCRIP\",\n",
      "                \"PROTEIN_G\",\n",
      "                \"SATURATED_FATS_G\",\n",
      "                \"FAT_G\",\n",
      "                \"CARB_G\",\n",
      "                \"SODIUM_MG\",\n",
      "                \"FIBER_G\",\n",
      "                \"SUGAR_G\",\n",
      "                \"ENERGY_KCAL\",\n",
      "                \"INGREDIENT_FROM_RECIPE_NAME\" as matched_ingredient\n",
      "            FROM (\n",
      "                SELECT\n",
      "                    ci.\"DESCRIP\",\n",
      "                    ci.\"PROTEIN_G\",\n",
      "                    ci.\"SATURATED_FATS_G\",\n",
      "                    ci.\"FAT_G\",\n",
      "                    ci.\"CARB_G\",\n",
      "                    ci.\"SODIUM_MG\",\n",
      "                    ci.\"FIBER_G\",\n",
      "                    ci.\"SUGAR_G\",\n",
      "                    ci.\"ENERGY_KCAL\",\n",
      "                    ci.\"NDB_NO\",\n",
      "                    im.\"INGREDIENT_FROM_RECIPE_NAME\"\n",
      "                FROM {INGREDIENTS_NUTRIMENTS_TABLE_NAME} ci\n",
      "                FULL OUTER JOIN {INGREDIENTS_MATCHED_TABLE_NAME} im\n",
      "                    ON im.\"INGREDIENT_ID\" = ci.\"NDB_NO\"\n",
      "                WHERE\n",
      "                            {where_clause}\n",
      "            ) AS result\n",
      "            \"\"\"\n",
      "\n",
      "\n",
      "            result_sql = self.session.sql(query)\n",
      "            result = parse_query_result(result_sql)\n",
      "\n",
      "\n",
      "            if result:\n",
      "                for ingredient_key in ingredient_to_match:\n",
      "                    # Prendre le meilleur match (correspondance exacte prioritaire)\n",
      "                    best_match = None\n",
      "                    exact_match = None\n",
      "\n",
      "                    for row in result:\n",
      "                        matched_ingredient = row[\"MATCHED_INGREDIENT\"]\n",
      "                        descrip = row[\"DESCRIP\"]\n",
      "\n",
      "                        # Utiliser safe_float pour toutes les conversions\n",
      "                        nutrition_data = {\n",
      "                            \"name\": descrip,\n",
      "                            \"matched_ingredient\": matched_ingredient,\n",
      "                            \"protein\": float(row[\"PROTEIN_G\"]),\n",
      "                            \"saturated_fats\": float(row[\"SATURATED_FATS_G\"]),\n",
      "                            \"fat\": float(row[\"FAT_G\"]),\n",
      "                            \"carbs\": float(row[\"CARB_G\"]),\n",
      "                            \"sodium\": float(row[\"SODIUM_MG\"]),\n",
      "                            \"fiber\": float(row[\"FIBER_G\"]),\n",
      "                            \"sugar\": float(row[\"SUGAR_G\"]),\n",
      "                            \"calories\": float(row[\"ENERGY_KCAL\"]),\n",
      "                        }\n",
      "                        if matched_ingredient is not None:\n",
      "                            # Correspondance exacte avec l'ingrédient matché\n",
      "                            if matched_ingredient == ingredient_key:\n",
      "                                exact_match = nutrition_data\n",
      "                                break\n",
      "                            # Meilleur match partiel\n",
      "                            elif ingredient_key in matched_ingredient or any(\n",
      "                                word in matched_ingredient\n",
      "                                for word in ingredient_key.split()\n",
      "                            ):\n",
      "                                if best_match is None:\n",
      "                                    best_match = nutrition_data\n",
      "\n",
      "                    result_data = exact_match or best_match\n",
      "\n",
      "                    if result_data:\n",
      "                        # Mettre en cache\n",
      "                        self.matched_ingredients_cache[ingredient_key] = result_data\n",
      "                        ingredient_matched.append(result_data)\n",
      "                    else:\n",
      "                        # Pas trouvé - mettre en cache négatif\n",
      "                        self.matched_ingredients_cache[ingredient_key] = None\n",
      "                        ingredient_matched.append(None)\n",
      "            else:\n",
      "                logging.error(\"Failure: Getting matched ingredient query failed.\")\n",
      "        \n",
      "        if None in ingredient_matched:\n",
      "            logging.warning(\"Failure: Some ingredients doesn't have matched ingredient.\")\n",
      "        return ingredient_matched\n",
      "\n",
      "    def fetch_recipe_quantities(self, recipe_id: str) -> Dict[str, Optional[float]]:\n",
      "            \"\"\"\n",
      "            Returns list of (ingredient_string, qty_g_or_none) from INGREDIENTS_QUANTITY.\n",
      "            Cached per recipe.\n",
      "            \"\"\"\n",
      "            if recipe_id in self.recipe_qty_cache:\n",
      "                return self.recipe_qty_cache[recipe_id]\n",
      "            \n",
      "            sdf = (\n",
      "            self.session.table(INGREDIENTS_QUANTITY_TABLE_NAME)\n",
      "            .filter(col(\"ID\") == recipe_id)\n",
      "            .select(col(\"INGREDIENTS\"), col(\"QTY_G\"))\n",
      "            )\n",
      "\n",
      "            rows = sdf.collect()  # <-- materialize results\n",
      "            out: Dict[str, Optional[float]] = {}\n",
      "\n",
      "            for r in rows:\n",
      "                ing = r[\"INGREDIENTS\"]\n",
      "                qty = r[\"QTY_G\"]\n",
      "                if ing is None:\n",
      "                    continue\n",
      "                out[(ing or \"\").strip().lower()] = float(qty) if qty is not None else None\n",
      "\n",
      "            self.recipe_qty_cache[recipe_id] = out\n",
      "            return out\n",
      "\n",
      "    def fetch_ingredients_nutrition(self, recipe_id: str, ingredients: List[str]) -> Dict[str, Optional[Dict[str, Any]]]:\n",
      "        \"\"\"\n",
      "         Returns mapping:\n",
      "          key = LOWER(TRIM(ingredient_from_recipe_name))\n",
      "          val = dict of nutrition columns per 100g (or None if not found)\n",
      "        Cached per recipe+ingredient key.\n",
      "        \"\"\"\n",
      "        if recipe_id not in self.recipe_nutrition_cache:\n",
      "            self.recipe_nutrition_cache[recipe_id] = {}\n",
      "\n",
      "        keys = [(s or \"\").strip().lower() for s in ingredients]\n",
      "        keys = [k for k in keys if k]\n",
      "        unique_keys = sorted(set(keys))\n",
      "\n",
      "        missing = [k for k in unique_keys if k not in self.recipe_nutrition_cache[recipe_id]]\n",
      "        if not missing:\n",
      "            return self.recipe_nutrition_cache[recipe_id]\n",
      "\n",
      "        # Default missing keys to None so we don't re-query forever\n",
      "        for k in missing:\n",
      "            self.recipe_nutrition_cache[recipe_id][k] = None\n",
      "\n",
      "        im = self.session.table(INGREDIENTS_MATCHED_TABLE_NAME)\n",
      "        ci = self.session.table(INGREDIENTS_NUTRIMENTS_TABLE_NAME)\n",
      "\n",
      "        ing_key_expr = lower(trim(col(\"INGREDIENT_FROM_RECIPE_NAME\")))\n",
      "\n",
      "        joined = (\n",
      "            im.filter(col(\"RECIPE_ID\") == recipe_id)\n",
      "              .with_column(\"ING_KEY\", ing_key_expr)\n",
      "              .filter(col(\"ING_KEY\").isin(missing))\n",
      "              .join(ci, col(\"INGREDIENT_ID\") == col(\"NDB_NO\"), how=\"left\")\n",
      "              .select(\n",
      "                  col(\"ING_KEY\"),\n",
      "                  col(\"ENERGY_KCAL\"),\n",
      "                  col(\"PROTEIN_G\"),\n",
      "                  col(\"FAT_G\"),\n",
      "                  col(\"SATURATED_FATS_G\"),\n",
      "                  col(\"CARB_G\"),\n",
      "                  col(\"FIBER_G\"),\n",
      "                  col(\"SUGAR_G\"),\n",
      "                  col(\"SODIUM_MG\"),\n",
      "                  col(\"CALCIUM_MG\"),\n",
      "                  col(\"IRON_MG\"),\n",
      "                  col(\"MAGNESIUM_MG\"),\n",
      "                  col(\"POTASSIUM_MG\"),\n",
      "                  col(\"VITC_MG\"),\n",
      "                  col(\"SCORE_SANTE\"),\n",
      "              )\n",
      "        )\n",
      "\n",
      "        w = Window.partition_by(col(\"ING_KEY\")).order_by(col(\"SCORE_SANTE\").desc_nulls_last())\n",
      "        ranked = joined.with_column(\"RN\", row_number().over(w)).filter(col(\"RN\") == 1)\n",
      "\n",
      "        rows = ranked.select(\n",
      "            \"ING_KEY\",\n",
      "            \"ENERGY_KCAL\",\n",
      "            \"PROTEIN_G\",\n",
      "            \"FAT_G\",\n",
      "            \"SATURATED_FATS_G\",\n",
      "            \"CARB_G\",\n",
      "            \"FIBER_G\",\n",
      "            \"SUGAR_G\",\n",
      "            \"SODIUM_MG\",\n",
      "            \"CALCIUM_MG\",\n",
      "            \"IRON_MG\",\n",
      "            \"MAGNESIUM_MG\",\n",
      "            \"POTASSIUM_MG\",\n",
      "            \"VITC_MG\",\n",
      "        ).collect()\n",
      "\n",
      "        for r in rows:\n",
      "            ing_key = r[\"ING_KEY\"]\n",
      "            vals = [r[c] for c in NUTRITION_COLS]\n",
      "            self.recipe_nutrition_cache[recipe_id][ing_key] = dict(zip(NUTRITION_COLS, vals))\n",
      "\n",
      "        return self.recipe_nutrition_cache[recipe_id]\n",
      "\n",
      "    def compute_recipe_nutrition_totals(\n",
      "        self,\n",
      "        recipe_id: str,\n",
      "        ingredients: List[str],\n",
      "        serving_size: float,\n",
      "        servings: float,\n",
      "    ) -> NutritionDelta:\n",
      "        \"\"\"\n",
      "        Compute recipe nutrition information for all ingredients\n",
      "        Returns:\n",
      "        NutritionDelta\n",
      "            Total nutrients for the  recipe\n",
      "        \"\"\"\n",
      "        total_weight = (serving_size or 0.0) * (servings or 0.0)\n",
      "        ingredients_quantity = self.fetch_recipe_quantities(recipe_id)\n",
      "        ingredients_nutrition = self.fetch_ingredients_nutrition(recipe_id, ingredients)\n",
      "        \n",
      "        known_weight = 0.0\n",
      "        unknown_count = 0\n",
      "\n",
      "        for _, qty in ingredients_quantity.items():\n",
      "            if qty is None:\n",
      "                unknown_count += 1\n",
      "            else:\n",
      "                known_weight += float(qty)\n",
      "\n",
      "        if unknown_count > 0:\n",
      "            fill_qty = max(total_weight - known_weight, 0.0) / unknown_count * 0.5 # 0.5 to follow group 1 logic appended to db\n",
      "        else:\n",
      "            fill_qty = 0.0\n",
      "        \n",
      "        recipe_nutrition = NutritionDelta(\n",
      "            calories=0.0,\n",
      "            protein_g=0.0,\n",
      "            fat_g=0.0,\n",
      "            saturated_fats_g=0.0,\n",
      "            carb_g=0.0,\n",
      "            fiber_g=0.0,\n",
      "            sugar_g=0.0,\n",
      "            sodium_mg=0.0,\n",
      "            calcium_mg=0.0,\n",
      "            iron_mg=0.0,\n",
      "            magnesium_mg=0.0,\n",
      "            potassium_mg=0.0,\n",
      "            vitamin_c_mg=0.0,\n",
      "            health_score=0.0\n",
      "        )\n",
      "        for name, nutrition in ingredients_nutrition.items():\n",
      "            if nutrition is None:\n",
      "                continue\n",
      "            quantity = ingredients_quantity.get(name)\n",
      "            if quantity is None:\n",
      "                quantity = fill_qty\n",
      "            factor = float(quantity) / NUTRIENT_BASIS_GRAMS\n",
      "\n",
      "            recipe_nutrition.calories += nutrition[\"ENERGY_KCAL\"] * factor\n",
      "            recipe_nutrition.protein_g += nutrition[\"PROTEIN_G\"] * factor\n",
      "            recipe_nutrition.fat_g += nutrition[\"FAT_G\"] * factor\n",
      "            recipe_nutrition.saturated_fats_g += nutrition[\"SATURATED_FATS_G\"] * factor\n",
      "            recipe_nutrition.carb_g += nutrition[\"CARB_G\"] * factor\n",
      "            recipe_nutrition.fiber_g += nutrition[\"FIBER_G\"] * factor\n",
      "            recipe_nutrition.sugar_g += nutrition[\"SUGAR_G\"] * factor\n",
      "            recipe_nutrition.sodium_mg += nutrition[\"SODIUM_MG\"] * factor\n",
      "\n",
      "            recipe_nutrition.calcium_mg += nutrition[\"CALCIUM_MG\"] * factor\n",
      "            recipe_nutrition.iron_mg += nutrition[\"IRON_MG\"] * factor\n",
      "            recipe_nutrition.magnesium_mg += nutrition[\"MAGNESIUM_MG\"] * factor\n",
      "            recipe_nutrition.potassium_mg += nutrition[\"POTASSIUM_MG\"] * factor\n",
      "            recipe_nutrition.vitamin_c_mg += nutrition[\"VITC_MG\"] * factor\n",
      "\n",
      "        return recipe_nutrition\n",
      "    \n",
      "    def scale_nutrition(self, n: NutritionDelta, factor: float) -> NutritionDelta:\n",
      "        \"\"\"\n",
      "        Scales nutrition value for 100g = a portion of the recipe, to represent the score per portion\n",
      "        Separate from total nutrition calculation to send totals for full recipe if asked \n",
      "        \"\"\"\n",
      "        return NutritionDelta(\n",
      "        calories=n.calories * factor,\n",
      "        protein_g=n.protein_g * factor,\n",
      "        fat_g=n.fat_g * factor,\n",
      "        saturated_fats_g=n.saturated_fats_g * factor,\n",
      "        carb_g=n.carb_g * factor,\n",
      "        fiber_g=n.fiber_g * factor,\n",
      "        sugar_g=n.sugar_g * factor,\n",
      "        sodium_mg=n.sodium_mg * factor,\n",
      "        calcium_mg=n.calcium_mg * factor,\n",
      "        iron_mg=n.iron_mg * factor,\n",
      "        magnesium_mg=n.magnesium_mg * factor,\n",
      "        potassium_mg=n.potassium_mg * factor,\n",
      "        vitamin_c_mg=n.vitamin_c_mg * factor,\n",
      "    )\n",
      "\n",
      "    def compute_benefit_score(self, protein_g: float, fiber_g: float) -> float:\n",
      "        \"\"\"\n",
      "        Compute the benefit score of a recipe based on total protein and fiber.\n",
      "        Returns a value in [0, 1].\n",
      "        \"\"\"\n",
      "        protein_ref = 50.0  \n",
      "        fiber_ref   = 30.0\n",
      "\n",
      "        s_protein = min(protein_g / protein_ref, 1.0)\n",
      "        s_fiber   = min((fiber_g or 0.0) / fiber_ref, 1.0)\n",
      "\n",
      "        benefit_score = (s_protein + s_fiber) / 2.0\n",
      "\n",
      "        return benefit_score\n",
      "\n",
      "    def compute_risk_score(\n",
      "        self,\n",
      "        sugar_g: float,\n",
      "        saturated_fats_g: float,\n",
      "        sodium_mg: float,\n",
      "        alpha_sugar: float = 1.2,\n",
      "        alpha_satfat: float = 1.0,\n",
      "        alpha_sodium: float = 1.5,\n",
      "    ) -> float:\n",
      "        \"\"\"\n",
      "        Compute risk score where exceeding nutrient limits creates negative scores proportional to how badly limits are exceeded.\n",
      "        Returns float between -inf and 1.0\n",
      "        \"\"\"\n",
      "\n",
      "        sugar_limit = 50.0     \n",
      "        satfat_limit = 20.0   \n",
      "        sodium_limit = 2000.0\n",
      "\n",
      "        def subscore(x, L, alpha):\n",
      "            x = max(x, 0.0)\n",
      "            if x <= L:\n",
      "                return 1.0 - (x / L)\n",
      "            else:\n",
      "                return -alpha * ((x / L) - 1.0)\n",
      "\n",
      "        h_sugar   = subscore(sugar_g, sugar_limit, alpha_sugar)\n",
      "        h_satfat  = subscore(saturated_fats_g, satfat_limit, alpha_satfat)\n",
      "        h_sodium  = subscore(sodium_mg, sodium_limit, alpha_sodium)\n",
      "\n",
      "        risk_control_score = (h_sugar + h_satfat + h_sodium) / 3.0\n",
      "        return risk_control_score\n",
      "\n",
      "    def compute_micronutrient_density_score(\n",
      "        self,\n",
      "        calcium_mg: float,\n",
      "        iron_mg: float,\n",
      "        magnesium_mg: float,\n",
      "        potassium_mg: float,\n",
      "        vitamin_c_mg: float,\n",
      "    ) -> float:\n",
      "        \"\"\"\n",
      "        Compute a micronutrient density score in [0, 1] based on totals for the recipe.\n",
      "        \"\"\"\n",
      "\n",
      "        calcium_ref   = 1000.0\n",
      "        iron_ref      = 18.0\n",
      "        magnesium_ref = 350.0\n",
      "        potassium_ref = 3500.0\n",
      "        vitamin_c_ref = 90.0\n",
      "\n",
      "        m_ca = min(max(calcium_mg, 0.0)   / calcium_ref,   1.0)\n",
      "        m_fe = min(max(iron_mg, 0.0)      / iron_ref,      1.0)\n",
      "        m_mg = min(max(magnesium_mg, 0.0) / magnesium_ref, 1.0)\n",
      "        m_k  = min(max(potassium_mg, 0.0) / potassium_ref, 1.0)\n",
      "        m_c  = min(max(vitamin_c_mg, 0.0) / vitamin_c_ref,      1.0)\n",
      "\n",
      "        micronutrient_score = (m_ca + m_fe + m_mg + m_k + m_c) / 5.0\n",
      "\n",
      "        return micronutrient_score\n",
      "\n",
      "    def compute_rhi(self, nutrition: NutritionDelta) -> float:\n",
      "        \"\"\"\n",
      "        Compute the Recipe Health Index (RHI) on [0, 100] for a whole recipe.\n",
      "        Uses:\n",
      "          - benefit score (protein + fiber, vs daily references)\n",
      "          - risk score (sugar, saturated fat, sodium vs daily limits, with penalties above limits)\n",
      "          - micronutrient density score (Ca, Fe, Mg, K, Vit C vs daily references)\n",
      "\n",
      "        RHI = max(0, 0.4 * risk + 0.4 * benefit + 0.2 * micro) * 100\n",
      "        \"\"\"\n",
      "\n",
      "        benefit = self.compute_benefit_score(protein_g=nutrition.protein_g, fiber_g=nutrition.fiber_g)\n",
      "        risk = self.compute_risk_score(\n",
      "            sugar_g=nutrition.sugar_g,\n",
      "            saturated_fats_g=nutrition.saturated_fats_g,\n",
      "            sodium_mg=nutrition.sodium_mg,\n",
      "        )\n",
      "        micro = self.compute_micronutrient_density_score(\n",
      "            calcium_mg=nutrition.calcium_mg,\n",
      "            iron_mg=nutrition.iron_mg,\n",
      "            magnesium_mg=nutrition.magnesium_mg,\n",
      "            potassium_mg=nutrition.potassium_mg,\n",
      "            vitamin_c_mg=nutrition.vitamin_c_mg,\n",
      "        )\n",
      "\n",
      "        rhi_raw = 0.4 * risk + 0.4 * benefit + 0.2 * micro\n",
      "\n",
      "        rhi_0_1 = max(0.0, rhi_raw)\n",
      "        rhi = rhi_0_1 * 100.0\n",
      "\n",
      "        return rhi\n",
      "\n",
      "    def ensure_pca_loaded(self):\n",
      "        if TransformService._pca_data_cache is None:\n",
      "            with TransformService._pca_lock:\n",
      "                if TransformService._pca_data_cache is None:\n",
      "                    TransformService._pca_data_cache = self.load_pca_data_from_snowflake()\n",
      "        self.pca_data = TransformService._pca_data_cache\n",
      "    \n",
      "    def load_pca_data(self):\n",
      "        \"\"\"Load PCA data from Snowflake or CSV as fallback\"\"\"\n",
      "        if self.pca_data is None:\n",
      "            try:\n",
      "                # Charger le fichier CSV\n",
      "                csv_path = \"ingredients_with_clusters.csv\"\n",
      "                df = pd.read_csv(csv_path)\n",
      "\n",
      "\n",
      "\n",
      "                # query = f\"\"\"\n",
      "                # SELECT\n",
      "                #     NDB_No,\n",
      "                #     Descrip,\n",
      "                #     ENERGY_KCAL,\n",
      "                #     PROTEIN_G,\n",
      "                #     SATURATED_FATS_G,\n",
      "                #     FAT_G,CARB_G,\n",
      "                #     SODIUM_MG,SUGAR_G,\n",
      "                #     PCA_macro_1,\n",
      "                #     PCA_macro_2,\n",
      "                #     PCA_macro_3,\n",
      "                #     PCA_micro_1,\n",
      "                #     PCA_micro_2,\n",
      "                #     Cluster_macro,\n",
      "                #     Cluster_micro\n",
      "                # FROM {INGREDIENTS_CLUSTERING_TABLE_NAME}\n",
      "                # LIMIT 100;\n",
      "                # \"\"\"\n",
      "\n",
      "                # Parse query result \n",
      "                # result_cluster = self.session.sql(query)\n",
      "                # df = pd.DataFrame(parse_query_result(result_cluster))\n",
      "                # Parse column values to float\n",
      "                # for col in list(df.columns[2:-2]):\n",
      "                #     df[col] = df[col].apply(float)\n",
      "\n",
      "                # Adapter les noms de colonnes pour correspondre au format attendu\n",
      "                self.pca_data = df.rename(\n",
      "                    columns={\n",
      "                        \"NDB_No\": \"NDB_No\",\n",
      "                        \"DESCRIP\": \"Descrip\",\n",
      "                        \"Energy_kcal\": \"ENERGY_KCAL\",\n",
      "                        \"Protein_g\": \"PROTEIN_G\",\n",
      "                        \"Saturated_fats_g\": \"SATURATED_FATS_G\",\n",
      "                        \"Fat_g\": \"FAT_G\",\n",
      "                        \"Carb_g\": \"CARB_G\",\n",
      "                        \"Sodium_mg\": \"SODIUM_MG\",\n",
      "                        \"Sugar_g\": \"SUGAR_G\",\n",
      "                        \"PCA_MACRO_1\": \"PCA_macro_1\",\n",
      "                        \"PCA_MACRO_2\": \"PCA_macro_2\",\n",
      "                        \"PCA_MACRO_3\": \"PCA_macro_3\",\n",
      "                        \"PCA_MICRO_1\": \"PCA_micro_1\",\n",
      "                        \"PCA_MICRO_2\": \"PCA_micro_2\",\n",
      "                        \"Cluster_macro\": \"Cluster_macro\",\n",
      "                        \"Cluster_micro\": \"Cluster_micro\",\n",
      "                    }\n",
      "                )\n",
      "\n",
      "                # Ajouter des colonnes de contraintes par défaut (pas disponibles dans le CSV)\n",
      "                self.pca_data[\"is_lactose\"] = 0\n",
      "                self.pca_data[\"is_gluten\"] = 0\n",
      "                self.pca_data[\"contains_nuts\"] = 0\n",
      "                self.pca_data[\"is_vegetarian\"] = 0\n",
      "                self.pca_data[\"is_vegetable\"] = 0\n",
      "\n",
      "                # Logique simple pour définir quelques contraintes basées sur le nom\n",
      "                for idx, row in self.pca_data.iterrows():\n",
      "                    descrip_lower = str(row[\"Descrip\"]).lower()\n",
      "\n",
      "                    # Détection lactose (produits laitiers)\n",
      "                    if any(\n",
      "                        word in descrip_lower\n",
      "                        for word in [\"milk\", \"cheese\", \"butter\", \"cream\", \"yogurt\"]\n",
      "                    ):\n",
      "                        self.pca_data.at[idx, \"is_lactose\"] = 1\n",
      "\n",
      "                    # Détection gluten (céréales, pain, etc.)\n",
      "                    if any(\n",
      "                        word in descrip_lower\n",
      "                        for word in [\"wheat\", \"bread\", \"flour\", \"pasta\", \"cereal\"]\n",
      "                    ):\n",
      "                        self.pca_data.at[idx, \"is_gluten\"] = 1\n",
      "\n",
      "                    # Détection noix\n",
      "                    if any(\n",
      "                        word in descrip_lower\n",
      "                        for word in [\"nut\", \"almond\", \"peanut\", \"walnut\", \"pecan\"]\n",
      "                    ):\n",
      "                        self.pca_data.at[idx, \"contains_nuts\"] = 1\n",
      "\n",
      "                    # Détection végétarien (pas de viande/poisson)\n",
      "                    if not any(\n",
      "                        word in descrip_lower\n",
      "                        for word in [\n",
      "                            \"beef\",\n",
      "                            \"pork\",\n",
      "                            \"chicken\",\n",
      "                            \"fish\",\n",
      "                            \"meat\",\n",
      "                            \"turkey\",\n",
      "                            \"lamb\",\n",
      "                        ]\n",
      "                    ):\n",
      "                        self.pca_data.at[idx, \"is_vegetarian\"] = 1\n",
      "\n",
      "                    # Détection végétal (fruits, légumes, etc.)\n",
      "                    if any(\n",
      "                        word in descrip_lower\n",
      "                        for word in [\n",
      "                            \"vegetable\",\n",
      "                            \"fruit\",\n",
      "                            \"bean\",\n",
      "                            \"pea\",\n",
      "                            \"lentil\",\n",
      "                            \"spinach\",\n",
      "                            \"carrot\",\n",
      "                            \"tomato\",\n",
      "                        ]\n",
      "                    ):\n",
      "                        self.pca_data.at[idx, \"is_vegetable\"] = 1\n",
      "\n",
      "                logging.info(\"Success: PCA ingredients coordinates successfully loaded.\")\n",
      "\n",
      "\n",
      "            except Exception as e:\n",
      "                logging.error(f\"Failure: PCA ingredients coordinates loading error. Error: {str(e)}. Traceback: {traceback.format_exc()}\")\n",
      "                self.pca_data = None\n",
      "\n",
      "    def get_neighbors_pca(\n",
      "        self,\n",
      "        ingredient_name: str,\n",
      "        constraints: TransformConstraints = None,\n",
      "        micro_weight: float = 0.3,\n",
      "        macro_weight: float = 0.7,\n",
      "        k: int = 5,\n",
      "    ) -> Dict:\n",
      "        \"\"\"\n",
      "        Find the k best substitutes for an ingredient using PCA macro/micro\n",
      "        \n",
      "        Args:\n",
      "            ingredient_name: ingredient to substitute\n",
      "            constraints: transformation constraints\n",
      "            micro_weight: weight of micronutrients \n",
      "            macro_weight: weight of macronutrients\n",
      "            k: number of substitutes to return\n",
      "            \n",
      "        Returns:\n",
      "            Dict with the best substitutes \n",
      "        \"\"\"\n",
      "        if self.pca_data is None:\n",
      "            logging.warning(\"Failure: PCA ingredients coordinates missing.\")\n",
      "            return None\n",
      "            \n",
      "        # Clean ingredient name\n",
      "        ingredient_clean = ingredient_name.lower().strip()\n",
      "\n",
      "        # Search for ingredient in PCA Data \n",
      "        matching_rows = self.pca_data[\n",
      "            self.pca_data[\"Descrip\"]\n",
      "            .str.lower()\n",
      "            .str.contains(ingredient_clean, na=False)\n",
      "        ]\n",
      "\n",
      "        if matching_rows.empty:\n",
      "            logging.warning(f\"Failure:  Ingredient '{ingredient_name}' not found in PCA data\")\n",
      "            return None\n",
      "            \n",
      "        # Take the first match\n",
      "        row = matching_rows.iloc[0]\n",
      "        logging.info(f\"Success: Ingredient found: {ingredient_name} → {row['Descrip']}\")\n",
      "        \n",
      "        # Copy data for filtering based on constraints\n",
      "        df_filtered = self.pca_data.copy()\n",
      "\n",
      "        # Apply constraint filters\n",
      "        if constraints:\n",
      "            CONSTRAINT_TO_COLUMN = {\n",
      "                \"no_lactose\": (\"is_lactose\", 0),\n",
      "                \"no_gluten\": (\"is_gluten\", 0),\n",
      "                \"no_nuts\": (\"contains_nuts\", 0),\n",
      "                \"vegetarian\": (\"is_vegetarian\", 1),\n",
      "                \"vegan\": (\"is_vegetable\", 1),\n",
      "            }\n",
      "\n",
      "            for constraint_name, (\n",
      "                col,\n",
      "                allowed_val,\n",
      "            ) in CONSTRAINT_TO_COLUMN.items():\n",
      "                if getattr(constraints, constraint_name, False):\n",
      "                    # Keep only ingredients that meet the constraint OR the original ingredient\n",
      "                    if col in df_filtered.columns:\n",
      "                        df_filtered = df_filtered[\n",
      "                            (df_filtered[col] == allowed_val)\n",
      "                            | (\n",
      "                                df_filtered[\"Descrip\"].str.lower()\n",
      "                                == ingredient_clean\n",
      "                            )\n",
      "                        ]\n",
      "        \n",
      "        # PCA columns\n",
      "        macro_cols = ['PCA_macro_1', 'PCA_macro_2', 'PCA_macro_3']\n",
      "        micro_cols = ['PCA_micro_1', 'PCA_micro_2']\n",
      "        \n",
      "        # Check that columns exist\n",
      "        available_macro_cols = [col for col in macro_cols if col in df_filtered.columns]\n",
      "        available_micro_cols = [col for col in micro_cols if col in df_filtered.columns]\n",
      "        \n",
      "        if not available_macro_cols and not available_micro_cols:\n",
      "            logging.warning(f\"Failure:  No pca coordinates available in pca dataframe.\")\n",
      "            return None\n",
      "\n",
      "        macro_vec = (\n",
      "            row[available_macro_cols].values\n",
      "            if available_macro_cols\n",
      "            else np.array([])\n",
      "        )\n",
      "        micro_vec = (\n",
      "            row[available_micro_cols].values\n",
      "            if available_micro_cols\n",
      "            else np.array([])\n",
      "        )\n",
      "\n",
      "        def euclidean_distance(a, b):\n",
      "            return np.linalg.norm(a - b) if len(a) > 0 and len(b) > 0 else 0\n",
      "        \n",
      "        # Exclude the original ingredient\n",
      "        df_filtered = df_filtered[df_filtered['Descrip'] != row['Descrip']]\n",
      "        \n",
      "        if df_filtered.empty:\n",
      "            logging.warning(\"Failure: No substitute found after applying constraints\")\n",
      "            return None\n",
      "        \n",
      "        # Calculate global distances (macro + micro combination)\n",
      "        df_filtered = df_filtered.copy()\n",
      "        \n",
      "        # Calculate macro distance\n",
      "        if available_macro_cols:\n",
      "            df_filtered[\"dist_macro\"] = df_filtered[available_macro_cols].apply(\n",
      "                lambda x: euclidean_distance(macro_vec, x.values), axis=1\n",
      "            )\n",
      "        else:\n",
      "            df_filtered['dist_macro'] = 0\n",
      "        \n",
      "        # Calculate micro distance  \n",
      "        if available_micro_cols:\n",
      "            df_filtered[\"dist_micro\"] = df_filtered[available_micro_cols].apply(\n",
      "                lambda x: euclidean_distance(micro_vec, x.values), axis=1\n",
      "            )\n",
      "        else:\n",
      "            df_filtered['dist_micro'] = 0\n",
      "        \n",
      "        # Combined global score\n",
      "        df_filtered['global_score'] = (\n",
      "            macro_weight * df_filtered['dist_macro'] + \n",
      "            micro_weight * df_filtered['dist_micro']\n",
      "        )\n",
      "\n",
      "        # -------------------------\n",
      "        # Filter similarities (not regex after all), 30/12/25\n",
      "        # -------------------------\n",
      "        main_word = ingredient_clean.split()[0] # only the first word for now\n",
      "\n",
      "        def filter_similar_df(df, k):\n",
      "            filtered_rows = []\n",
      "            for _, row_ in df.iterrows():\n",
      "                name_lower = row_['Descrip'].lower()\n",
      "                if not name_lower.startswith(main_word):\n",
      "                    filtered_rows.append(row_)\n",
      "                if len(filtered_rows) >= k:\n",
      "                    break\n",
      "            return pd.DataFrame(filtered_rows)\n",
      "        \n",
      "        # Sort by global score and take the top k\n",
      "        best_substitutes = df_filtered.nsmallest(k, 'global_score')\n",
      "        # Filter ingredients with the same base name\n",
      "        best_substitutes = filter_similar_df(best_substitutes, k)\n",
      "        \n",
      "        result = {\n",
      "            \"input_ingredient\": row['Descrip'],\n",
      "            \"best_substitutes\": []\n",
      "        }\n",
      "        \n",
      "        for _, substitute_row in best_substitutes.iterrows():\n",
      "            result[\"best_substitutes\"].append(\n",
      "                {\n",
      "                    \"name\": substitute_row[\"Descrip\"],\n",
      "                    \"global_score\": substitute_row[\"global_score\"],\n",
      "                    \"macro_distance\": substitute_row[\"dist_macro\"],\n",
      "                    \"micro_distance\": substitute_row[\"dist_micro\"],\n",
      "                    \"nutrition\": {\n",
      "                        \"calories\": substitute_row[\"ENERGY_KCAL\"],\n",
      "                        \"protein\": substitute_row[\"PROTEIN_G\"],\n",
      "                        \"saturated_fat\": substitute_row[\"SATURATED_FATS_G\"],\n",
      "                        \"sodium\": substitute_row[\"SODIUM_MG\"],\n",
      "                        \"sugar\": substitute_row[\"SUGAR_G\"],\n",
      "                    },\n",
      "                }\n",
      "            )\n",
      "\n",
      "        return result\n",
      "    \n",
      "    def get_health_score(self, new_ingredients: List[str], recipe_id : int, serving_size : float, servings :float) -> NutritionDelta:\n",
      "        \"\"\"\n",
      "        Calculates health score for a recipe based on give ingredients\n",
      "        \"\"\"\n",
      "        new_recipe_nutrition = self.compute_recipe_nutrition_totals(\n",
      "                recipe_id=recipe_id,\n",
      "                ingredients=new_ingredients,\n",
      "                serving_size=serving_size,\n",
      "                servings=servings\n",
      "            )\n",
      "        denom = (serving_size or 0) * (servings or 0)\n",
      "        if denom > 0:\n",
      "            scaled_nutrition = self.scale_nutrition(\n",
      "            new_recipe_nutrition,\n",
      "            factor=100.0 / denom\n",
      "            )\n",
      "        else :\n",
      "            scaled_nutrition = new_recipe_nutrition ## fallback servings null\n",
      "        rhi_score = self.compute_rhi(scaled_nutrition)\n",
      "        new_recipe_nutrition.health_score = rhi_score\n",
      "        return new_recipe_nutrition\n",
      "    \n",
      "    def judge_substitute(self, candidates, recipe_ingredients: List[str], recipe_id: int, serving_size: float, servings: float) -> Tuple[str,NutritionDelta]:\n",
      "        \"\"\"\n",
      "        Final ingredient choice between list of candidates\n",
      "\n",
      "        Args:\n",
      "            candidates: list of possible ingredients to substitute with (extracted from get_neighbors_pca() )\n",
      "            recipe_id, serving_size, servings, recipe_ingredients: recipe information\n",
      "        Returns:\n",
      "            ingredient_id\n",
      "        \"\"\"\n",
      "        if not candidates:\n",
      "            logging.warning(\"Failure: No candidatee found.\")\n",
      "            return None, self._zero_nutrition()\n",
      "        best_ing = None\n",
      "        best_nutrition = self._zero_nutrition()\n",
      "        for cand in candidates:\n",
      "            if best_ing is None:\n",
      "                best_ing = cand\n",
      "            else:\n",
      "                candidat_nutrition = self.get_health_score(recipe_ingredients + [cand[\"name\"]], recipe_id, serving_size, servings)\n",
      "                best_current_score = self.get_health_score(recipe_ingredients + [best_ing[\"name\"]], recipe_id, serving_size, servings)\n",
      "                if candidat_nutrition.health_score > best_current_score.health_score:\n",
      "                    best_ing = cand\n",
      "                    best_nutrition = candidat_nutrition    \n",
      "        return best_ing, best_nutrition\n",
      "\n",
      "    def substitute_ingr(self, ingredient: str, contraintes: TransformConstraints, recipe_ingredients: List[str], recipe_id: int, serving_size: float, servings: float) -> Tuple[str, bool, NutritionDelta]:\n",
      "        \"\"\"\n",
      "        Finds a substitute for the given ingredient using PCA in priority\n",
      "        \n",
      "        Args:\n",
      "            ingredient: ingredient to substitute\n",
      "            contraintes: nutritional constraints\n",
      "        \n",
      "        Returns:\n",
      "            Tuple (substituted_ingredient, substitution_performed)\n",
      "        \"\"\"\n",
      "        result = self.get_neighbors_pca(ingredient, contraintes)\n",
      "\n",
      "        if not result or not result.get(\"best_substitutes\"):\n",
      "            return ingredient, False, self._zero_nutrition()\n",
      "\n",
      "        candidates = result[\"best_substitutes\"]\n",
      "        substitute, nutrition = self.judge_substitute(candidates, recipe_ingredients, recipe_id, serving_size, servings)\n",
      "\n",
      "        if substitute:\n",
      "            substitute_name = substitute[\"name\"]\n",
      "            logging.info(f\"Success: Found substitute for {ingredient} → {substitute_name} (PCA score: {substitute['global_score']:.3f})\")\n",
      "            return substitute_name, True, nutrition\n",
      "        \n",
      "        return ingredient, False, self._zero_nutrition()\n",
      "\n",
      "\n",
      "    def fetch_ingredients_tags(self, recipe_id: str, ingredients: List[str]) -> Dict[str, Optional[Dict[str, Any]]]:\n",
      "        \"\"\"\n",
      "        Returns mapping:\n",
      "          key = LOWER(TRIM(ingredient_from_recipe_name))\n",
      "          val = dict of tag columns (or None if not found)\n",
      "        Cached per recipe+ingredient key.\n",
      "        \"\"\"\n",
      "        if recipe_id not in self.recipe_tags_cache:\n",
      "            self.recipe_tags_cache[recipe_id] = {}\n",
      "\n",
      "        keys = [(s or \"\").strip().lower() for s in ingredients]\n",
      "        keys = [k for k in keys if k]\n",
      "        unique_keys = sorted(set(keys))\n",
      "\n",
      "        missing = [k for k in unique_keys if k not in self.recipe_tags_cache[recipe_id]]\n",
      "        if not missing:\n",
      "            return self.recipe_tags_cache[recipe_id]\n",
      "\n",
      "        # Default missing keys to None so we don't re-query forever\n",
      "        for k in missing:\n",
      "            self.recipe_tags_cache[recipe_id][k] = None\n",
      "\n",
      "        im = self.session.table(INGREDIENTS_MATCHED_TABLE_NAME)\n",
      "        it = self.session.table(INGREDIENTS_TAGGED_TABLE_NAME)\n",
      "\n",
      "        ing_key_expr = lower(trim(col(\"INGREDIENT_FROM_RECIPE_NAME\")))\n",
      "\n",
      "        joined = (\n",
      "            im.filter(col(\"RECIPE_ID\") == recipe_id)\n",
      "              .with_column(\"ING_KEY\", ing_key_expr)\n",
      "              .filter(col(\"ING_KEY\").isin(missing))\n",
      "              .join(it, col(\"INGREDIENT_ID\") == col(\"NDB_NO\"), how=\"left\")\n",
      "              .select(\n",
      "                  col(\"ING_KEY\"),\n",
      "                  col(\"NDB_NO\"),\n",
      "                  col(\"DESCRIP\"),\n",
      "                  col(\"FOODON_LABEL\"),\n",
      "                  col(\"IS_DAIRY\"),\n",
      "                  col(\"IS_GLUTEN\"),\n",
      "                  col(\"CONTAINS_NUTS\"),\n",
      "                  col(\"IS_GRAIN\"),\n",
      "                  col(\"IS_SEAFOOD\"),\n",
      "                  col(\"IS_SWEETENER\"),\n",
      "                  col(\"IS_VEGETABLE\"),\n",
      "                  col(\"IS_VEGETARIAN\"),\n",
      "              )\n",
      "        )\n",
      "\n",
      "        # If multiple rows exist per ING_KEY, just take the first one deterministically\n",
      "        w = Window.partition_by(col(\"ING_KEY\")).order_by(col(\"NDB_NO\").asc_nulls_last())\n",
      "        ranked = joined.with_column(\"RN\", row_number().over(w)).filter(col(\"RN\") == 1)\n",
      "\n",
      "        rows = ranked.collect()\n",
      "\n",
      "        for r in rows:\n",
      "            ing_key = r[\"ING_KEY\"]\n",
      "            self.recipe_tags_cache[recipe_id][ing_key] = {\n",
      "                \"NDB_NO\": r[\"NDB_NO\"],\n",
      "                \"DESCRIP\": r[\"DESCRIP\"],\n",
      "                \"FOODON_LABEL\": r[\"FOODON_LABEL\"],\n",
      "                \"IS_DAIRY\": r[\"IS_DAIRY\"],\n",
      "                \"IS_GLUTEN\": r[\"IS_GLUTEN\"],\n",
      "                \"CONTAINS_NUTS\": r[\"CONTAINS_NUTS\"],\n",
      "                \"IS_GRAIN\": r[\"IS_GRAIN\"],\n",
      "                \"IS_SEAFOOD\": r[\"IS_SEAFOOD\"],\n",
      "                \"IS_SWEETENER\": r[\"IS_SWEETENER\"],\n",
      "                \"IS_VEGETABLE\": r[\"IS_VEGETABLE\"],\n",
      "                \"IS_VEGETARIAN\": r[\"IS_VEGETARIAN\"],\n",
      "            }\n",
      "\n",
      "        return self.recipe_tags_cache[recipe_id]\n",
      "\n",
      "\n",
      "    def identify_ingredients_to_remove_by_algo(\n",
      "        self, \n",
      "        recipe: Recipe, \n",
      "        constraints: TransformConstraints\n",
      "    ) -> List[str]:\n",
      "        \"\"\"\n",
      "        Algorithm to identify ingredients to remove based on nutritional constraints.\n",
      "        \n",
      "        Args:\n",
      "            recipe: Recipe object\n",
      "            constraints: TransformConstraints with nutritional goals\n",
      "            \n",
      "        Returns:\n",
      "            List of ingredient names to remove\n",
      "        \"\"\"\n",
      "        ingredients_to_remove = []\n",
      "        \n",
      "        try:\n",
      "            # Fetch nutritional data for all ingredients\n",
      "            ingredients_nutrition = self.fetch_ingredients_nutrition(\n",
      "                recipe.id, \n",
      "                recipe.ingredients\n",
      "            )\n",
      "            ingredients_tags = self.fetch_ingredients_tags(recipe.id, recipe.ingredients)\n",
      "\n",
      "            allergy_constraints = [ 'no_lactose', 'no_gluten', 'no_nuts', 'vegetarian', 'vegan' ]\n",
      "            reduction_constraints = [ 'decrease_sugar', 'decrease_sodium', 'decrease_calories', 'decrease_carbs', 'increase_protein', 'decrease_protein' ]\n",
      "\n",
      "            active_allergy = any(getattr(constraints, c, False) for c in allergy_constraints)\n",
      "            active_reduction = any(getattr(constraints, c, False) for c in reduction_constraints)\n",
      "\n",
      "            max_items = 3 if active_allergy else (1 if active_reduction else 0)\n",
      "\n",
      "            # Define thresholds to identify \"bad\" ingredients\n",
      "            SUGAR_THRESHOLD = 10.0  # g per 100g\n",
      "            SODIUM_THRESHOLD = 500.0  # mg per 100g\n",
      "            SATURATED_FAT_THRESHOLD = 5.0  # g per 100g\n",
      "            CALORIE_THRESHOLD = 300.0  # kcal per 100g\n",
      "            CARB_THRESHOLD = 50.0  # g per 100g\n",
      "            \n",
      "            for ingredient in recipe.ingredients:\n",
      "                ing_key = ingredient.lower().strip()\n",
      "                nutrition = ingredients_nutrition.get(ing_key)\n",
      "                \n",
      "                if nutrition is None:\n",
      "                    continue\n",
      "                \n",
      "                should_remove = False\n",
      "                \n",
      "                # Check reduction constraints\n",
      "                if constraints.decrease_sugar and nutrition.get(\"SUGAR_G\", 0) > SUGAR_THRESHOLD:\n",
      "                    should_remove = True\n",
      "                    #print(f\"_identify_ingredients_to_remove_by_algo: {ingredient} identified for sugar reduction ({nutrition.get('SUGAR_G', 0):.1f}g)\")\n",
      "                \n",
      "                if constraints.decrease_sodium and nutrition.get(\"SODIUM_MG\", 0) > SODIUM_THRESHOLD:\n",
      "                    should_remove = True\n",
      "                    #print(f\"_identify_ingredients_to_remove_by_algo: {ingredient} identified for sodium reduction ({nutrition.get('SODIUM_MG', 0):.1f}mg)\")\n",
      "                \n",
      "                if constraints.decrease_calories and nutrition.get(\"ENERGY_KCAL\", 0) > CALORIE_THRESHOLD:\n",
      "                    should_remove = True\n",
      "                    #print(f\"_identify_ingredients_to_remove_by_algo: {ingredient} identified for calorie reduction ({nutrition.get('ENERGY_KCAL', 0):.1f}kcal)\")\n",
      "                \n",
      "                if constraints.decrease_carbs and nutrition.get(\"CARB_G\", 0) > CARB_THRESHOLD:\n",
      "                    should_remove = True\n",
      "                    #print(f\"_identify_ingredients_to_remove_by_algo: {ingredient} identified for carbohydrate reduction ({nutrition.get('CARB_G', 0):.1f}g)\")\n",
      "                \n",
      "                # Check dietary constraints (via PCA data if available)\n",
      "                tags = ingredients_tags.get(ing_key)\n",
      "                if tags is not None:\n",
      "                    if constraints.no_lactose and tags.get(\"IS_DAIRY\") is True:\n",
      "                        should_remove = True\n",
      "                    if constraints.no_gluten and tags.get(\"IS_GLUTEN\") is True:\n",
      "                        should_remove = True\n",
      "                    if constraints.no_nuts and tags.get(\"CONTAINS_NUTS\") is True:\n",
      "                        should_remove = True\n",
      "                    if constraints.vegetarian and tags.get(\"IS_VEGETARIAN\") is False:\n",
      "                        should_remove = True\n",
      "                    if constraints.vegan and tags.get(\"IS_VEGETABLE\") is False:\n",
      "                        should_remove = True  # proxy as you requested\n",
      "\n",
      "                if should_remove:\n",
      "                    ingredients_to_remove.append(ingredient)\n",
      "                    if max_items and len(ingredients_to_remove) >= max_items:\n",
      "                        break\n",
      "            \n",
      "            # Limit the number of ingredients to remove (max 3 to not destroy the recipe)\n",
      "            if len(ingredients_to_remove) > 3:\n",
      "                print(f\"_identify_ingredients_to_remove_by_algo: Limiting to 3 ingredients out of {len(ingredients_to_remove)} identified\")\n",
      "                ingredients_to_remove = ingredients_to_remove[:3]\n",
      "            \n",
      "            return ingredients_to_remove\n",
      "            \n",
      "        except Exception as e:\n",
      "            print(f\" Error in identifying ingredients to remove: {e}\")\n",
      "            traceback.print_exc()\n",
      "            return []\n",
      "    \n",
      "    def identify_ingredients_to_remove_by_llm(\n",
      "        self, \n",
      "        recipe: Recipe, \n",
      "        constraints: TransformConstraints\n",
      "    ) -> List[str]:\n",
      "        \"\"\"\n",
      "        LLM fallback to identify ingredients to remove if the algorithm fails, based on full recipe and constraints.\n",
      "        If constraint is an allergy or regime specific (vegetarian, vegan) all ingredients to remove are returned\n",
      "        If constraint is a reduction (sugar, sodium, calories, carbs, protein) only one ingredient is returned\n",
      "        \n",
      "        Args:\n",
      "            recipe: Recipe object\n",
      "            constraints: TransformConstraints with nutritional goals\n",
      "            \n",
      "        Returns:\n",
      "            List of ingredient names to remove\n",
      "        \"\"\"\n",
      "        try:\n",
      "            allergy_constraints = [ 'no_lactose', 'no_gluten', 'no_nuts', 'vegetarian', 'vegan' ]\n",
      "            reduction_constraints = [ 'decrease_sugar', 'decrease_sodium', 'decrease_calories', 'decrease_carbs', 'increase_protein', 'decrease_protein' ]\n",
      "            \n",
      "            active_allergy = [c for c in allergy_constraints if getattr(constraints, c, False)]\n",
      "            active_reduction = [c for c in reduction_constraints if getattr(constraints, c, False)]\n",
      "\n",
      "            if not active_allergy and not active_reduction:\n",
      "                return []\n",
      "            \n",
      "            if active_allergy:\n",
      "                mode = \"ALL_VIOLATIONS\"\n",
      "                constraints_text = \", \".join(active_allergy + active_reduction)\n",
      "            else:\n",
      "                max_items = 1\n",
      "                mode = \"ONE_OFFENDER\"\n",
      "                constraints_text = \", \".join(active_reduction)\n",
      "            logging.info(\"boo\")\n",
      "            base_prompt = f\"\"\"\n",
      "            \n",
      "            You are a culinary and nutrition expert analyzing recipe ingredients.\n",
      "\n",
      "                YOUR TASK:\n",
      "                - Analyze the recipe as a whole (name, ingredients, quantities, and steps).\n",
      "                - Identify which ingredients should be REMOVED to meet the constraints.\n",
      "                If constraint are no lactose, no_gluten, no_nuts, vegetarian, vegan, return ingredients that obviously violate these constraints.\n",
      "                - For no lactose: only flag ingredients that are dairy by name. Do NOT flag hidden dairy (bread, crescent rolls, eggs etc.)\n",
      "                - For vegetarian/vegan, only remove ingredients that are clearly non-vegetarian/vegan by name (meat, fish, poultry, eggs, dairy, etc.)\n",
      "                - If constraint are to decrease sugar, sodium, calories, carbs, or protein, return one ingredient that most harms the constraints.\n",
      "\n",
      "                IMPORTANT:\n",
      "                - Only suggest removing ingredients that clearly violate the constraints\n",
      "                - Do NOT suggest removing essential ingredients that define the dish\n",
      "                - Be conservative - better to remove fewer ingredients than too many\n",
      "                - You MUST choose ONLY from the Ingredients list exactly (no synonyms / no variants).\n",
      "                - If no ingredients violate the constraints, respond with NONE.\n",
      "                \n",
      "                STRICT OUTPUT RULES (MANDATORY):\n",
      "                - Output ONLY either:\n",
      "                  (A) NONE\n",
      "                  OR\n",
      "                  (B) a comma-separated list of ingredient strings copied EXACTLY from RECIPE INGREDIENTS.\n",
      "                - NO other words. NO explanations. NO punctuation other than commas.\n",
      "                - NO prefixes like \"Explanation:\" or \"Ingredients:\".\n",
      "                - If nothing should be removed, output EXACTLY: NONE\n",
      "                Example: cheese, butter\n",
      "            \n",
      "                If no ingredients should be removed, output: NONE\n",
      "            \n",
      "            RECIPE: \n",
      "            Name: {recipe.name}\n",
      "            Ingredients: {', '.join(recipe.ingredients)}\n",
      "            Quantities: {recipe.quantity_ingredients}\n",
      "            Steps:\n",
      "            {chr(10).join(recipe.steps)}\n",
      "            \n",
      "            CONSTRAINTS (booleans): {constraints.__dict__}\n",
      "            ANSWER:\n",
      "            DON'T add extra ingredients to remove. Just follow the constraints and be brief.\n",
      "            \"\"\"\n",
      "\n",
      "            prompt_escaped = base_prompt.replace(\"'\", \"''\")\n",
      "            \n",
      "            llm_query = f\"\"\"\n",
      "                SELECT SNOWFLAKE.CORTEX.COMPLETE(\n",
      "                    'mixtral-8x7b',\n",
      "                   '{prompt_escaped}'\n",
      "                ) AS INGREDIENTS_TO_REMOVE\n",
      "            \"\"\"\n",
      "            res = self.session.sql(llm_query).collect()\n",
      "            if not res:\n",
      "                return []\n",
      "\n",
      "            response_text = (res[0][\"INGREDIENTS_TO_REMOVE\"] or \"\").strip()\n",
      "            if not response_text or response_text.upper() == \"NONE\":\n",
      "                print(\"LLM: No ingredients to remove\")\n",
      "                return []\n",
      "                        \n",
      "            # Parse the ingredient list (handle different formats)\n",
      "            ingredients_to_remove = []\n",
      "            \n",
      "            # Clean the response from special characters and numbers\n",
      "            cleaned_response = response_text.replace(\"\\n\", \",\").replace(\";\", \",\")\n",
      "            \n",
      "            for item in cleaned_response.split(\",\"):\n",
      "                # Clean each item\n",
      "                cleaned_item = item.strip()\n",
      "                if not cleaned_item:\n",
      "                    continue\n",
      "                # Remove leading numbers (e.g., \"1. sugar\" -> \"sugar\")\n",
      "                if cleaned_item[0].isdigit():\n",
      "                    cleaned_item = cleaned_item.lstrip(\"0123456789.-) \").strip()\n",
      "                \n",
      "                if len(cleaned_item) > 1:\n",
      "                    # Verify that the ingredient exists in the recipe (fuzzy matching)\n",
      "                    matched = False\n",
      "                    for recipe_ing in recipe.ingredients:\n",
      "                        if cleaned_item.lower() in recipe_ing.lower() or recipe_ing.lower() in cleaned_item.lower():\n",
      "                            if recipe_ing not in ingredients_to_remove:\n",
      "                                ingredients_to_remove.append(recipe_ing)\n",
      "                            matched = True\n",
      "                            break\n",
      "                    \n",
      "                    if not matched:\n",
      "                        print(f\"LLM: Ingredient '{cleaned_item}' not found in recipe\")\n",
      "            \n",
      "                if len(ingredients_to_remove) >= 3:\n",
      "                    break\n",
      "            return ingredients_to_remove\n",
      "            \n",
      "        except Exception as e:\n",
      "            print(f\"LLM error for ingredient identification: {e}\")\n",
      "            traceback.print_exc()\n",
      "            return []\n",
      "\n",
      "    def adapt_recipe_with_llm(self, recipe: Recipe, substitutions: Dict) -> str:\n",
      "        \"\"\"\n",
      "        Adapt the recipe steps with substitutions via LLM\n",
      "        \"\"\"\n",
      "        \n",
      "        # Building the prompt for the LLM\n",
      "        base_prompt = f\"\"\"You are an expert chef specializing in recipe adaptation and ingredient substitution.\n",
      "\n",
      "        ORIGINAL RECIPE:\n",
      "        Name: {recipe.name}\n",
      "        Ingredients: {recipe.ingredients}\n",
      "        Steps: {recipe.steps}\n",
      "\n",
      "        SUBSTITUTIONS TO APPLY:\n",
      "        \"\"\"\n",
      "\n",
      "        for original, substitute in substitutions.items():\n",
      "            base_prompt += f\"- Replace '{original}' with '{substitute}'\\n\"\n",
      "\n",
      "        base_prompt += \"\"\"\n",
      "        YOUR TASK:\n",
      "        Adapt the recipe steps to incorporate these ingredient substitutions while maintaining the dish's quality and integrity.\n",
      "\n",
      "        ADAPTATION GUIDELINES:\n",
      "        1. Modify ONLY the preparation steps that are affected by the substitutions\n",
      "        2. Preserve the original step numbering and structure\n",
      "        3. Adjust cooking times if the substitute cooks faster/slower than the original\n",
      "        4. Adjust temperatures if the substitute requires different heat levels\n",
      "        5. Note any texture or consistency changes that may occur\n",
      "        6. Suggest technique modifications if needed (e.g., mixing methods, prep techniques)\n",
      "        7. Keep instructions clear, concise, and actionable\n",
      "        8. Maintain the same cooking skill level as the original recipe\n",
      "\n",
      "        IMPORTANT CONSIDERATIONS:\n",
      "        - If a substitution significantly impacts flavor, briefly note it in the step\n",
      "        - If multiple steps use the same ingredient, ensure consistency across all adaptations\n",
      "        - Do not add new steps; only modify existing ones\n",
      "        - Do not change unaffected steps\n",
      "\n",
      "        OUTPUT FORMAT:\n",
      "        Provide only the adapted recipe steps in numbered format.\n",
      "\n",
      "        ADAPTED RECIPE STEPS:\"\"\"\n",
      "\n",
      "        try:\n",
      "            # Échapper les guillemets simples pour éviter les erreurs SQL\n",
      "            prompt_escaped = base_prompt.replace(\"'\", \"''\")\n",
      "\n",
      "            # Construire la requête SQL avec le prompt échappé\n",
      "            llm_query = f\"\"\"\n",
      "                SELECT SNOWFLAKE.CORTEX.COMPLETE(\n",
      "                    'mixtral-8x7b',\n",
      "                   '{prompt_escaped}'\n",
      "                ) AS adapted_steps\n",
      "            \"\"\"\n",
      "\n",
      "            llm_response = self.session.sql(llm_query)\n",
      "            logging.info(f\"LLM response: {llm_response}\")\n",
      "            llm_response = parse_query_result(llm_response)\n",
      "            response_text = llm_response[0][\"ADAPTED_STEPS\"].strip()\n",
      "            \n",
      "            # Verification of LLM output format\n",
      "            if not response_text:\n",
      "                print(\"LLM returned an empty response\")\n",
      "                return recipe.steps, []\n",
      "            \n",
      "            parsed_steps = response_text.split(\"\\n\")\n",
      "\n",
      "            new_steps = []\n",
      "            notes = []\n",
      "            \n",
      "            for step in parsed_steps:\n",
      "                step_cleaned = step.strip()\n",
      "                if not step_cleaned:\n",
      "                    continue\n",
      "                \n",
      "                # Check if it's a numbered step (format: \"1.\", \"1)\", or just a digit at the beginning)\n",
      "                if step_cleaned[0].isdigit() or step_cleaned.startswith(\"-\") or step_cleaned.startswith(\"*\"):                    # Clean list formats\n",
      "                    cleaned_step = step_cleaned.lstrip(\"0123456789.-*) \").strip()\n",
      "                    if cleaned_step:\n",
      "                        new_steps.append(cleaned_step)\n",
      "                elif step_cleaned.lower().startswith(\"note\"):\n",
      "                    # Extract the note after \"Note:\"\n",
      "                    note_content = step_cleaned.split(\":\", 1)[-1].strip()\n",
      "                    if note_content:\n",
      "                        notes.append(note_content)\n",
      "            \n",
      "            # Validation: if no steps were extracted, fallback to original steps\n",
      "            if not new_steps:\n",
      "                print(\"LLM: No valid steps extracted, using original steps\")\n",
      "                return recipe.steps, notes\n",
      "            \n",
      "            print(f\"LLM: {len(new_steps)} adapted steps, {len(notes)} notes\")\n",
      "            return new_steps, notes\n",
      "\n",
      "        except Exception as e:\n",
      "            logging.error(f\"Failure:  Error found with recipe adaptation steps with substitution transformation made by LLM. Error: {str(e)}. Traceback: {traceback.format_exc()}\")\n",
      "            # Fallback: simple manual adaptation\n",
      "            adapted_steps = recipe.steps\n",
      "            adapted_steps = [\n",
      "                step.replace(original, substitute)\n",
      "                for original, substitute in substitutions.items()\n",
      "                for step in adapted_steps\n",
      "            ]\n",
      "            return adapted_steps, []\n",
      "\n",
      "    def adapt_recipe_delete(self, recipe: Recipe, ingredients_to_delete: List[str]) -> Tuple[List[str], List[str]]:\n",
      "        \"\"\"\n",
      "        Adapt the recipe steps by deleting ingredients via LLM.\n",
      "        Returns: (new_steps, notes)\n",
      "        \"\"\"\n",
      "\n",
      "        base_prompt = f\"\"\"You are an expert chef specializing in recipe adaptation for ingredient deletion.\n",
      "        ORIGINAL RECIPE:\n",
      "        Name: {recipe.name}\n",
      "        Ingredients: {recipe.ingredients}\n",
      "        Steps: {recipe.steps}\n",
      "\n",
      "        INGREDIENTS TO REMOVE:\n",
      "        \"\"\"\n",
      "\n",
      "        for ing in ingredients_to_delete:\n",
      "            base_prompt += f\"- Remove '{ing}'\\n\"\n",
      "\n",
      "        base_prompt += \"\"\"\n",
      "        YOUR TASK:\n",
      "        Adapt the recipe steps to REMOVE these ingredients while maintaining the dish's quality and integrity.\n",
      "\n",
      "        ADAPTATION GUIDELINES:\n",
      "        1. Modify ONLY the preparation steps that are affected by the deletions\n",
      "        2. Remove all mentions of the deleted ingredients from the steps\n",
      "        2. Preserve the original step numbering and structure\n",
      "        5. Note any texture or consistency changes that may occur\n",
      "        6. Suggest technique modifications if needed (e.g., mixing methods, prep techniques)\n",
      "        7. Keep instructions clear, concise, and actionable\n",
      "        8. Maintain the same cooking skill level as the original recipe\n",
      "\n",
      "        IMPORTANT CONSIDERATIONS:\n",
      "        - If multiple steps use the same deleted ingredient, ensure consistency across all adaptations\n",
      "        - Do not add new steps; only modify or delete existing ones.\n",
      "        - Do not change unaffected steps\n",
      "        - Do NOT add new ingredients no matter what. Even if the recipe does not seem coherent to you.\n",
      "\n",
      "        OUTPUT FORMAT:\n",
      "        Provide only the adapted recipe steps in numbered format.\n",
      "\n",
      "        ADAPTED RECIPE STEPS:\"\"\"\n",
      "\n",
      "        try:\n",
      "            prompt_escaped = base_prompt.replace(\"'\", \"''\")\n",
      "\n",
      "            llm_query = f\"\"\"\n",
      "                SELECT SNOWFLAKE.CORTEX.COMPLETE(\n",
      "                    'mixtral-8x7b',\n",
      "                   '{prompt_escaped}'\n",
      "                ) AS adapted_steps\n",
      "            \"\"\"\n",
      "\n",
      "            llm_response = self.session.sql(llm_query)\n",
      "            llm_response = parse_query_result(llm_response)\n",
      "            response_text = llm_response[0][\"ADAPTED_STEPS\"].strip()\n",
      "            \n",
      "            # Verification of LLM output format\n",
      "            if not response_text:\n",
      "                print(\"LLM returned an empty response -> adapt_recipe_delete\")\n",
      "                return recipe.steps, []\n",
      "            \n",
      "            parsed_steps = response_text.split(\"\\n\")\n",
      "\n",
      "            new_steps: List[str] = []\n",
      "            notes: List[str] = []\n",
      "\n",
      "            for step in parsed_steps:\n",
      "                step_cleaned = step.strip()\n",
      "                if not step_cleaned:\n",
      "                    continue\n",
      "                \n",
      "                # Check if it's a numbered step\n",
      "\n",
      "                if step_cleaned[0].isdigit() or step_cleaned.startswith(\"-\") or step_cleaned.startswith(\"*\"):                    # Clean list formats\n",
      "                    cleaned_step = step_cleaned.lstrip(\"0123456789.-*) \").strip()\n",
      "                    if cleaned_step:\n",
      "                        new_steps.append(cleaned_step)\n",
      "                elif step_cleaned.lower().startswith(\"note\"):\n",
      "                    # Extract the note after \"Note:\"\n",
      "                    note_content = step_cleaned.split(\":\", 1)[-1].strip()\n",
      "                    if note_content:\n",
      "                        notes.append(note_content)\n",
      "            \n",
      "            # Validation: if no steps were extracted, fallback to original steps\n",
      "            if not new_steps:\n",
      "                print(\"LLM: No valid steps extracted, using original steps -> adapt_recipe_delete\")\n",
      "                return recipe.steps, notes\n",
      "            \n",
      "            print(f\"LLM: {len(new_steps)} adapted steps, {len(notes)} notes\")\n",
      "            return new_steps, notes\n",
      "\n",
      "        except Exception as e:\n",
      "            logging.error(f\"Failure:  Error found with recipe adaptation steps for deletion transformation made by LLM. Error: {str(e)}. Traceback: {traceback.format_exc()}\")\n",
      "\n",
      "            # Fallback: naive removal of ingredient words in steps\n",
      "            adapted_steps = list(recipe.steps)\n",
      "            for ing in ingredients_to_delete:\n",
      "                adapted_steps = [step.replace(ing, \"\").strip() for step in adapted_steps]\n",
      "\n",
      "            return adapted_steps, []\n",
      "\n",
      "    def transform(\n",
      "            self,\n",
      "            recipe: Recipe,\n",
      "            ingredients_to_remove: List[str],\n",
      "            constraints: TransformConstraints)-> TransformResponse:\n",
      "        \"\"\"\n",
      "        Transform a recipe based on constraints and ingredients to remove, full pipeline\n",
      "        \"\"\"\n",
      "        success = True\n",
      "\n",
      "        try:\n",
      "            notes = []\n",
      "            # Step 1: Find ingredient to 'transform' depending on constraints if not received\n",
      "            transformation_type = constraints.transformation\n",
      "            if ingredients_to_remove is not None:\n",
      "                ingredients_to_transform = ingredients_to_remove\n",
      "            else:\n",
      "                # Algorithm in priority to identify ingredients\n",
      "                print(\"Step 1a: Identification by algorithm...\")\n",
      "                ingredients_to_transform = self.identify_ingredients_to_remove_by_algo(recipe, constraints)\n",
      "                \n",
      "                # LLM fallback if the algorithm finds nothing\n",
      "                if not ingredients_to_transform:\n",
      "                    print(\"Step 1b: LLM fallback for identification...\")\n",
      "                    ingredients_to_transform = self.identify_ingredients_to_remove_by_llm(recipe, constraints)\n",
      "                \n",
      "                if not ingredients_to_transform:\n",
      "                    print(\"No ingredients to transform identified\")\n",
      "                else:\n",
      "                    print(f\"Ingredients identified: {ingredients_to_transform}\")\n",
      "\n",
      "            logging.info(\"Success: Step 1 finished (Ingredients to remove has been found).\")\n",
      "\n",
      "            # Input for whole pipeline\n",
      "            transformations = {}\n",
      "            transformation_count = 0\n",
      "            new_recipe_score = 0.0\n",
      "            # Ingredients to keep from original recipe\n",
      "            base_ingredients = [ing for ing in recipe.ingredients if ing not in ingredients_to_transform]\n",
      "\n",
      "            new_recipe = Recipe(\n",
      "                id=recipe.id,\n",
      "                name=recipe.name,\n",
      "                serving_size=recipe.serving_size,\n",
      "                servings=recipe.servings,\n",
      "                health_score=new_recipe_score,\n",
      "                ingredients=base_ingredients,\n",
      "                quantity_ingredients=recipe.quantity_ingredients,\n",
      "                minutes=recipe.minutes,\n",
      "                steps=recipe.steps,\n",
      "            )\n",
      "            new_ingredients = recipe.ingredients # default value\n",
      "            new_recipe_nutrition = self._zero_nutrition()\n",
      "\n",
      "\n",
      "            # Pipeline diversion based on transformation type\n",
      "            if transformation_type == TransformationType.SUBSTITUTION:\n",
      "                    \n",
      "\n",
      "                logging.info(\"Substitution: Looking for matched ingredients.\")\n",
      "                # Step 2 : Find substitutes for ingredients to transform, function returns new recipe health score as well.\n",
      "                if self.pca_data is None:\n",
      "                    self.load_pca_data()\n",
      "                    \n",
      "\n",
      "                # Use cache match when available, otherwise query the database to get matched ingredient\n",
      "                ingredients_to_substitute_matched = [ing_dict.get(\"name\") for ing_dict in self.get_ingredient_matched(ingredients_to_transform)]\n",
      "\n",
      "\n",
      "                ingredients_to_substitute_matched\n",
      "\n",
      "                logging.info(\"Substitution: Ingredients matched found.\")\n",
      "                logging.info(f\"Substitution: Matched ingredients {ingredients_to_substitute_matched}, {type(ingredients_to_substitute_matched)}.\")\n",
      "                logging.info(f\"Substitution: Base ingredients {base_ingredients}, {type(base_ingredients)}.\")\n",
      "                logging.info(f\"Substitution: Ingredients to transform {ingredients_to_transform}, {type(ingredients_to_transform)}.\")\n",
      "\n",
      "                working_ingredients = list(base_ingredients)\n",
      "                for original_ing, matched_name in zip(ingredients_to_transform, ingredients_to_substitute_matched):\n",
      "                    logging.info(f\"Substitution: Looking for ({original_ing} matched with {matched_name}) substitute candidat.\")\n",
      "                    substitute, was_substituted, new_recipe_nutrition = self.substitute_ingr(\n",
      "                        matched_name,\n",
      "                        constraints,\n",
      "                        working_ingredients,\n",
      "                        recipe.id,\n",
      "                        recipe.serving_size,\n",
      "                        recipe.servings\n",
      "                    )\n",
      "                    \n",
      "                    \n",
      "                    if was_substituted:\n",
      "                        logging.info(f\"Substitution: Found substitute {substitute} with nutrition {new_recipe_nutrition}.\")\n",
      "                        logging.info(f\"Substitution: Updating the new_recipe (ingredients and health score).\")\n",
      "                        transformations[original_ing] = substitute\n",
      "                        transformation_count += 1\n",
      "\n",
      "                        # Update the working ingredient list for the next iteration\n",
      "                        # (replace original_ing if it still exists, otherwise just append substitute)\n",
      "                        if original_ing in working_ingredients:\n",
      "                            working_ingredients = [substitute if x == original_ing else x for x in working_ingredients]\n",
      "                        else:\n",
      "                            working_ingredients.append(substitute)\n",
      "\n",
      "                        # Apply substitutions to the full recipe ingredient list\n",
      "                        new_ingredients = [transformations.get(ingredient, ingredient) for ingredient in recipe.ingredients]\n",
      "                        new_recipe.ingredients = new_ingredients\n",
      "\n",
      "                        # Trust the nutrition returned by the last substitute_ingr call (now based on updated working_ingredients)\n",
      "                        new_recipe_score = new_recipe_nutrition.health_score\n",
      "                        new_recipe.health_score = new_recipe_score\n",
      "\n",
      "                logging.info(\"Success: Step 2 finished for Substitution (Subtitute ingredients found for eache ingredients to remove).\")\n",
      "\n",
      "\n",
      "                # Step 3 : Adapt recipe step with LLM\n",
      "                if transformations:\n",
      "                    new_recipe.steps, notes = self.adapt_recipe_with_llm(new_recipe, transformations)\n",
      "                logging.info(\"Success: Step 3 finished for Substitution (LLM's adapted new_recipe steps successfully).\")\n",
      "\n",
      "\n",
      "            elif transformation_type == TransformationType.ADD:\n",
      "                # TODO\n",
      "                pass\n",
      "\n",
      "\n",
      "            elif transformation_type == TransformationType.DELETE and ingredients_to_transform:\n",
      "                # Step 2 : Delete ingredients from recipe, calculate health score after deletion\n",
      "                new_recipe_nutrition = self.compute_recipe_nutrition_totals(\n",
      "                recipe_id=recipe.id,\n",
      "                ingredients=base_ingredients,\n",
      "                serving_size=recipe.serving_size,\n",
      "                servings=recipe.servings\n",
      "                )\n",
      "                denom = (recipe.serving_size or 0) * (recipe.servings or 0)\n",
      "                if denom > 0:\n",
      "                    scaled_nutrition = self.scale_nutrition(\n",
      "                    new_recipe_nutrition,\n",
      "                    factor=100.0 / denom\n",
      "                    )\n",
      "                else :\n",
      "                    scaled_nutrition = new_recipe_nutrition ## fallback servings null\n",
      "                new_recipe_score = self.compute_rhi(scaled_nutrition)\n",
      "                new_recipe_nutrition.health_score = new_recipe_score\n",
      "                logging.info(\"Success: Step 2 finished for Deletion (Removed successfully unwanted ingredients and computed new health score).\")\n",
      "                # Step 3 : Adapt recipe step with LLM\n",
      "                new_recipe.steps, notes= self.adapt_recipe_delete(recipe, ingredients_to_transform)\n",
      "                logging.info(\"Success: Step 3 finished for Deletion (LLM's adapted new_recipe steps successfully).\")\n",
      "\n",
      "\n",
      "            # Step 4 : Build output\n",
      "            original_nutrition = self.compute_recipe_nutrition_totals(\n",
      "                recipe_id=recipe.id,\n",
      "                ingredients=recipe.ingredients,\n",
      "                serving_size=recipe.serving_size,\n",
      "                servings=recipe.servings\n",
      "            )\n",
      "            original_nutrition.health_score = recipe.health_score\n",
      "\n",
      "            logging.info(\"Success: Step 4 finished (Original recipe health score computing finished).\")\n",
      "            response = TransformResponse(\n",
      "                recipe=new_recipe,\n",
      "                original_name=recipe.name,\n",
      "                transformed_name=new_recipe.name,\n",
      "                substitutions=None,\n",
      "                nutrition_before=original_nutrition,\n",
      "                nutrition_after=new_recipe_nutrition,\n",
      "                success=success,\n",
      "                message=\"\\n\".join(notes),\n",
      "            )\n",
      "            logging.info(\"Success: Step 5 finished (TransformerResponse successfully built, returning it...).\")\n",
      "            return response\n",
      "\n",
      "        except Exception as e:\n",
      "            logging.error(f\"Failure: Transform function failed. Error: {str(e)}. Traceback: {traceback.format_exc()}\")\n",
      "            success = False\n",
      "            response = TransformResponse(\n",
      "                recipe=recipe,\n",
      "                original_name=recipe.name,\n",
      "                transformed_name=recipe.name,\n",
      "                substitutions=None,\n",
      "                nutrition_before=None,\n",
      "                nutrition_after=None,\n",
      "                success=success,\n",
      "                message=None,\n",
      "            )\n",
      "            logging.error(\"Returning default response with input recipe.\")\n",
      "            return response\n",
      "\n",
      "\n",
      "def transform_recipe(session: Session, request: str) -> str:\n",
      "    \"\"\"\n",
      "    Transform endpoint handler - Snowflake Procedure\n",
      "\n",
      "    Args:\n",
      "        session: Snowflake session to execute queries\n",
      "        request: JSON string with TransformRequest structure\n",
      "\n",
      "    Returns:\n",
      "        JSON string with TransformResponse structure\n",
      "    \"\"\"\n",
      "\n",
      "    # Input loading\n",
      "    loaded_request: dict = json.loads(request)\n",
      "    input_recipe: Recipe = Recipe(**loaded_request[\"recipe\"])\n",
      "    input_ingredients_to_remove: List[str] = loaded_request.get(\n",
      "        \"ingredients_to_remove\"\n",
      "    )\n",
      "    input_constraints: TransformConstraints = TransformConstraints(\n",
      "        **loaded_request.get(\"constraints\", {})\n",
      "    )\n",
      "\n",
      "    service = TransformService(session)\n",
      "    # Call transform service\n",
      "    print(\"call service transform\")\n",
      "    output = service.transform(\n",
      "        input_recipe, input_ingredients_to_remove, input_constraints\n",
      "    )\n",
      "\n",
      "    return format_output(to_dict(output))\n",
      "$$\n",
      "\n",
      "2026-01-10 23:53:49,562 - snowflake.connector.result_set - DEBUG - beginning to schedule result batch downloads\n"
     ]
    }
   ],
   "source": [
    "result = session.sql(query).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a8a9fd",
   "metadata": {},
   "source": [
    "## Call example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fab1405",
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.udf.transform_recipe import (\n",
    "    parse_query_result,\n",
    "    parse_procedure_result,\n",
    ")  # Specific to python only usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "270667f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Configure logging to show ALL messages (DEBUG and above)\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,  # Set to DEBUG to see everything\n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n",
    "    force=True,  # Force reconfiguration if logging was already configured\n",
    ")\n",
    "\n",
    "# Or if you want to see messages in Jupyter Notebook output:\n",
    "logging.getLogger().setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2ba44d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "CALL {proc_name}(\n",
    "    '{json.dumps(request)}'\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "40f4f486",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = session.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "00baec9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-10 23:54:16,144 - snowflake.connector.cursor - DEBUG - executing SQL/command\n",
      "2026-01-10 23:54:16,146 - snowflake.connector.cursor - INFO - query: [CALL NUTRIRAG_PROJECT.SERVICES.TRANSFORM_RECIPE( '{\"recipe\": {\"id\": 94947, \"name...]\n",
      "2026-01-10 23:54:16,149 - snowflake.connector.connection - DEBUG - sequence counter: 3\n",
      "2026-01-10 23:54:16,153 - snowflake.connector.cursor - DEBUG - Request id: 0f531b1b-db29-4dae-8a95-dc472a3e1893\n",
      "2026-01-10 23:54:16,157 - snowflake.connector.cursor - DEBUG - running query [CALL NUTRIRAG_PROJECT.SERVICES.TRANSFORM_RECIPE( '{\"recipe\": {\"id\": 94947, \"name...]\n",
      "2026-01-10 23:54:16,163 - snowflake.connector.cursor - DEBUG - is_file_transfer: True\n",
      "2026-01-10 23:54:16,168 - snowflake.connector.connection - DEBUG - _cmd_query\n",
      "2026-01-10 23:54:16,170 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict() called\n",
      "2026-01-10 23:54:16,172 - snowflake.connector._query_context_cache - DEBUG - Cache Entry: (0, 1768085629272483, 0)\n",
      "2026-01-10 23:54:16,175 - snowflake.connector._query_context_cache - DEBUG - serialize_to_dict(): data to send to server {'entries': [{'id': 0, 'timestamp': 1768085629272483, 'priority': 0, 'context': {'base64Data': 'COKl94Bw'}}]}\n",
      "2026-01-10 23:54:16,177 - snowflake.connector.connection - DEBUG - sql=[CALL NUTRIRAG_PROJECT.SERVICES.TRANSFORM_RECIPE( '{\"recipe\": {\"id\": 94947, \"name...], sequence_id=[3], is_file_transfer=[False]\n",
      "2026-01-10 23:54:16,180 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:54:16,183 - snowflake.connector.network - DEBUG - remaining request timeout: N/A ms, retry cnt: 1\n",
      "2026-01-10 23:54:16,186 - snowflake.connector.network - DEBUG - Request guid: 35743dcf-978f-4ad6-b947-19f396029211\n",
      "2026-01-10 23:54:16,188 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:54:21,450 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - https://sfedu02-oub04122.snowflakecomputing.com:443 \"POST /queries/v1/query-request?requestId=0f531b1b-db29-4dae-8a95-dc472a3e1893&request_guid=35743dcf-978f-4ad6-b947-19f396029211 HTTP/1.1\" 200 None\n",
      "2026-01-10 23:54:21,455 - snowflake.connector.network - DEBUG - SUCCESS\n",
      "2026-01-10 23:54:21,458 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 0/1 active sessions\n",
      "2026-01-10 23:54:21,460 - snowflake.connector.network - DEBUG - ret[code] = None, after post request\n",
      "2026-01-10 23:54:21,461 - snowflake.connector.network - DEBUG - Query id: 01c1a5be-0307-74b8-0010-0853008631ca\n",
      "2026-01-10 23:54:21,463 - snowflake.connector.cursor - DEBUG - sfqid: 01c1a5be-0307-74b8-0010-0853008631ca\n",
      "2026-01-10 23:54:21,464 - snowflake.connector.cursor - INFO - query execution done\n",
      "2026-01-10 23:54:21,479 - snowflake.connector.cursor - DEBUG - SUCCESS\n",
      "2026-01-10 23:54:21,481 - snowflake.connector.cursor - DEBUG - PUT OR GET: False\n",
      "2026-01-10 23:54:21,496 - snowflake.connector.cursor - DEBUG - Query result format: arrow\n",
      "2026-01-10 23:54:21,499 - snowflake.connector.cursor - INFO - Number of results in first chunk: 1\n",
      "2026-01-10 23:54:21,515 - snowflake.snowpark._internal.server_connection - DEBUG - Execute query [queryID: 01c1a5be-0307-74b8-0010-0853008631ca] \n",
      "CALL NUTRIRAG_PROJECT.SERVICES.TRANSFORM_RECIPE(\n",
      "    '{\"recipe\": {\"id\": 94947, \"name\": \"crab filled crescent snacks\", \"serving_size\": 1, \"servings\": 4, \"ingredients\": [\"crabmeat\", \"cream cheese\", \"green onions\", \"garlic salt\", \"refrigerated crescent dinner rolls\", \"egg yolk\", \"water\", \"sesame seeds\", \"sweet and sour sauce\"], \"quantity_ingredients\": [\"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\"], \"minutes\": 70.0, \"steps\": [\"heat over to 375 degrees\", \"spray large cookie sheet with non-stick cooking spray\", \"in small bowl , combine crabmeat , cream cheese , onions and garlic salt and mix well\", \"unroll both cans of dough\", \"separate into 16 triangles\", \"cut each triangle in half lengthwise to make 32 triangles\", \"place 1 teaspoon crab mixture on center of each triangle about 1 inch from short side of triangle\", \"fold short ends of each triangle over filling\", \"pinch sides to seal\", \"roll up\", \"place on sprayed cookie sheet\", \"in small bowl , combine egg yolk and water and mix well\", \"brush egg mixture over snacks\", \"sprinkle with sesame seed\", \"bake at 375 degrees for 15 to 20 minutes or until golden brown\", \"serve warn snacks with sweet-and-sour sauce\"], \"health_score\": 57}, \"ingredients_to_remove\": [\"cream cheese\"], \"constraints\": {\"transformation\": 2, \"no_lactose\": false, \"no_gluten\": false, \"no_nuts\": false, \"vegetarian\": false, \"vegan\": false, \"increase_protein\": false, \"decrease_sugar\": false, \"decrease_protein\": false, \"decrease_carbs\": false, \"decrease_calories\": false, \"decrease_sodium\": false}}'\n",
      ")\n",
      "\n",
      "2026-01-10 23:54:21,531 - snowflake.connector.result_batch - DEBUG - Using nanoarrow as the arrow data converter\n",
      "2026-01-10 23:54:21,547 - snowflake.connector.CArrowIterator - DEBUG - Arrow BatchSize: 1\n",
      "2026-01-10 23:54:21,549 - snowflake.connector.CArrowIterator - DEBUG - Arrow chunk info: batchCount 1, columnCount 1, use_numpy: 0\n",
      "2026-01-10 23:54:21,564 - snowflake.connector.nanoarrow_arrow_iterator - DEBUG - Batches read: 0\n",
      "2026-01-10 23:54:21,596 - snowflake.connector.result_set - DEBUG - beginning to schedule result batch downloads\n",
      "2026-01-10 23:54:21,597 - snowflake.connector.CArrowIterator - DEBUG - Current batch index: 0, rows in current batch: 1\n"
     ]
    }
   ],
   "source": [
    "parsed_query = parse_query_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3fdfa8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_output = parse_procedure_result(parsed_query, proc_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "30b35c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['crabmeat',\n",
       " 'cream cheese',\n",
       " 'green onions',\n",
       " 'garlic salt',\n",
       " 'refrigerated crescent dinner rolls',\n",
       " 'egg yolk',\n",
       " 'water',\n",
       " 'sesame seeds',\n",
       " 'sweet and sour sauce']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request[\"recipe\"][\"ingredients\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2dd1e90e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['crabmeat',\n",
       " 'green onions',\n",
       " 'garlic salt',\n",
       " 'refrigerated crescent dinner rolls',\n",
       " 'egg yolk',\n",
       " 'water',\n",
       " 'sesame seeds',\n",
       " 'sweet and sour sauce']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_output[\"recipe\"][\"ingredients\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c869673",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output = pd.DataFrame(parsed_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cb7fc1",
   "metadata": {},
   "source": [
    "# Close connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb25071f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-10 23:58:55,838 - snowflake.connector.connection - INFO - closed\n",
      "2026-01-10 23:58:55,855 - snowflake.connector.telemetry - DEBUG - Closing telemetry client.\n",
      "2026-01-10 23:58:55,875 - snowflake.connector.telemetry - DEBUG - Sending 1 logs to telemetry. Data is {'logs': [{'message': {'driver_type': 'PythonConnector', 'driver_version': '3.6.0', 'source': 'PythonConnector', 'type': 'client_imported_packages', 'value': \"{'tarfile', 'hmac', 'binascii', 'quopri', 'asn1crypto', 'comm', 'shutil', 'token', 'jupyter_client', 'numbers', 'cryptography', 'pytz', 'queue', 'pydantic_core', 'hashlib', 'textwrap', 'dataclasses', 'tomlkit', 'bz2', 'debugpy', 'pstats', 'pydev_ipython', 'jupyter_core', 'filecmp', 'pwd', 'cProfile', 'decimal', 'http', 'glob', 'email', 'builtins', 'shared', 'zoneinfo', 'faulthandler', 'sqlite3', 'ssl', 'packaging', 'ipykernel', 'urllib', 'argparse', 'grp', 'json', 'runpy', 'weakref', 'selectors', 'heapq', 'threading', 'inspect', 'operator', 'code', 'functools', 'executing', 'parso', 'jwt', 'difflib', 'bisect', 'pydevd_tracing', 'os', 'vscode', 'pydevd_plugins', 'ntpath', 'pure_eval', 'socketserver', 'dateutil', 'asyncio', 'prompt_toolkit', 'locale', 'socket', 'sortedcontainers', 'stack_data', 'copy', 'abc', 'string', 'math', 'pkgutil', 'errno', 'tokenize', 'pdb', 'colorama', 'dotenv', 'linecache', 'psutil', 'subprocess', 'webbrowser', 'tempfile', 'zmq', 'zipimport', 'charset_normalizer', 'traceback', 'decorator', 'pygments', 'pydoc', 'fcntl', 'resource', 'asttokens', 'pandas', 'profile', 'cloudpickle', 'time', 'types', 'cmath', 'traitlets', 'colorsys', 'copyreg', 'shlex', 'gettext', 'six', 'gc', 're', 'typing', 'random', 'logging', 'contextvars', 'OpenSSL', 'curses', 'posixpath', 'collections', 'enum', 'base64', 'opcode', 'struct', 'sysconfig', 'atexit', 'posix', 'xmlrpc', 'fractions', 'jedi', 'site', 'keyword', 'numpy', 'io', 'zlib', 'reprlib', 'uuid', 'codeop', 'html', 'array', 'mimetypes', 'pydevconsole', 'getpass', 'pickle', 'pydevd_file_utils', 'certifi', 'lzma', 'cmd', 'stringprep', 'idna', 'ctypes', 'warnings', 'pathlib', 'select', 'termios', 'zipfile', 'typing_extensions', 'pydoc_data', 'mmap', 'IPython', 'xml', 'cython_runtime', 'fnmatch', 'ast', 'appnope', 'unicodedata', 'wcwidth', 'stat', 'unittest', 'pydantic', 'concurrent', 'bdb', 'getopt', 'timeit', 'codecs', 'secrets', 'pkg_resources', 'csv', 'pydevd', 'platform', 'calendar', 'signal', 'datetime', 'encodings', 'itertools', 'gzip', 'plistlib', 'pprint', 'annotated_types', 'dis', 'sys', 'platformdirs', 'contextlib', 'tornado', 'yaml', 'snowflake', 'ipaddress', 'importlib', 'marshal', 'app', 'pyexpat', 'genericpath'}\"}, 'timestamp': '1768084877211'}]}.\n",
      "2026-01-10 23:58:55,891 - snowflake.connector.network - DEBUG - Session status for SessionPool 'sfedu02-oub04122.snowflakecomputing.com', SessionPool 1/1 active sessions\n",
      "2026-01-10 23:58:55,910 - snowflake.connector.network - DEBUG - remaining request timeout: 5000 ms, retry cnt: 1\n",
      "2026-01-10 23:58:55,914 - snowflake.connector.network - DEBUG - Request guid: 8a11db1f-afb2-4320-a36d-4959bb52daa9\n",
      "2026-01-10 23:58:55,917 - snowflake.connector.network - DEBUG - socket timeout: 60\n",
      "2026-01-10 23:58:55,928 - snowflake.connector.vendored.urllib3.connectionpool - DEBUG - Resetting dropped connection: sfedu02-oub04122.snowflakecomputing.com\n",
      "2026-01-10 23:58:56,395 - snowflake.connector.ssl_wrap_socket - DEBUG - OCSP Mode: INSECURE, OCSP response cache file name: None\n",
      "2026-01-10 23:58:56,398 - snowflake.connector.ssl_wrap_socket - INFO - THIS CONNECTION IS IN INSECURE MODE. IT MEANS THE CERTIFICATE WILL BE VALIDATED BUT THE CERTIFICATE REVOCATION STATUS WILL NOT BE CHECKED.\n"
     ]
    }
   ],
   "source": [
    "sf_client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bc8630",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Nutrirag venv)",
   "language": "python",
   "name": "nutrirag_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
